{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "anaconda-cloud": {},
    "colab": {
      "name": "CSC180 Transfer Learning on CIFAR10",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-BeOChlfOfY"
      },
      "source": [
        "#### *CSC 180  Intelligent Systems (Spring 2021)*\n",
        "\n",
        "#### *Dr. Haiquan Chen, Dept of Computer Scicence*\n",
        "\n",
        "#### *California State University, Sacramento*\n",
        "<hr>\n",
        "\n",
        "## Project 3: Computer Vision using GPU and Transfer Learning\n",
        "### **Team Members:** Quinn Roemer, Logan Hollmer\n",
        "\n",
        "#### **Description:**\n",
        "In this project we were tasked with creating CNN neural networks to classify images in ``CIFAR-10``. This dataset contains an equal number of images from each class. In order to accomplish this goal we were instructed to train custom CNN models as well as models that incorporated transfer learning from VGG16."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rENMVFFibA3H"
      },
      "source": [
        "# Quinn Roemer\n",
        "# SID: 301323594\n",
        "# CSC 180 Intelligent Systems\n",
        "# Assignment #3\n",
        "# Due: April 2, 2021\n",
        "\n",
        "# Logan Hollmer\n",
        "# SID: 301559973\n",
        "# CSC 180 Intelligent Systems\n",
        "# Assignment #3\n",
        "# Due: April 2, 2021\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlFpkRqpfOfa"
      },
      "source": [
        "\n",
        "### Helpful Functions for Tensorflow (Little Gems)\n",
        "\n",
        "The following functions will be used with TensorFlow to help preprocess the data.  They allow you to build the feature vector for a neural network. \n",
        "\n",
        "* Predictors/Inputs \n",
        "    * Fill any missing inputs with the median for that column.  Use **missing_median**.\n",
        "    * Encode textual/categorical values with **encode_text_dummy**.\n",
        "    * Encode numeric values with **encode_numeric_zscore**.\n",
        "* Output\n",
        "    * Discard rows with missing outputs.\n",
        "    * Encode textual/categorical values with **encode_text_index**.\n",
        "    * Do not encode output numeric values.\n",
        "* Produce final feature vectors (x) and expected output (y) with **to_xy**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOddo2bbfOfb"
      },
      "source": [
        "from collections.abc import Sequence\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
        "def encode_text_dummy(df, name):\n",
        "    dummies = pd.get_dummies(df[name])\n",
        "    for x in dummies.columns:\n",
        "        dummy_name = \"{}-{}\".format(name, x)\n",
        "        df[dummy_name] = dummies[x]\n",
        "    df.drop(name, axis=1, inplace=True)\n",
        "\n",
        "\n",
        "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
        "def encode_text_index(df, name):\n",
        "    le = preprocessing.LabelEncoder()\n",
        "    df[name] = le.fit_transform(df[name])\n",
        "    return le.classes_\n",
        "\n",
        "\n",
        "# Encode a numeric column as zscores\n",
        "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
        "    if mean is None:\n",
        "        mean = df[name].mean()\n",
        "\n",
        "    if sd is None:\n",
        "        sd = df[name].std()\n",
        "\n",
        "    df[name] = (df[name] - mean) / sd\n",
        "\n",
        "\n",
        "# Convert all missing values in the specified column to the median\n",
        "def missing_median(df, name):\n",
        "    med = df[name].median()\n",
        "    df[name] = df[name].fillna(med)\n",
        "\n",
        "\n",
        "# Convert all missing values in the specified column to the default\n",
        "def missing_default(df, name, default_value):\n",
        "    df[name] = df[name].fillna(default_value)\n",
        "\n",
        "\n",
        "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
        "def to_xy(df, target):\n",
        "    result = []\n",
        "    for x in df.columns:\n",
        "        if x != target:\n",
        "            result.append(x)\n",
        "    # find out the type of the target column. \n",
        "    target_type = df[target].dtypes\n",
        "    target_type = target_type[0] if isinstance(target_type, Sequence) else target_type\n",
        "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
        "    if target_type in (np.int64, np.int32):\n",
        "        # Classification\n",
        "        dummies = pd.get_dummies(df[target])\n",
        "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
        "    else:\n",
        "        # Regression\n",
        "        return df[result].values.astype(np.float32), df[target].values.astype(np.float32)\n",
        "\n",
        "# Nicely formatted time string\n",
        "def hms_string(sec_elapsed):\n",
        "    h = int(sec_elapsed / (60 * 60))\n",
        "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
        "    s = sec_elapsed % 60\n",
        "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
        "\n",
        "\n",
        "# Regression chart.\n",
        "def chart_regression(pred,y,sort=True):\n",
        "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
        "    if sort:\n",
        "        t.sort_values(by=['y'],inplace=True)\n",
        "    a = plt.plot(t['y'].tolist(),label='expected')\n",
        "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
        "    plt.ylabel('output')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Remove all rows where the specified column is +/- sd standard deviations\n",
        "def remove_outliers(df, name, sd):\n",
        "    drop_rows = df.index[(np.abs(df[name] - df[name].mean()) >= (sd * df[name].std()))]\n",
        "    df.drop(drop_rows, axis=0, inplace=True)\n",
        "\n",
        "\n",
        "# Encode a column to a range between normalized_low and normalized_high.\n",
        "def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1,\n",
        "                         data_low=None, data_high=None):\n",
        "    if data_low is None:\n",
        "        data_low = min(df[name])\n",
        "        data_high = max(df[name])\n",
        "\n",
        "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
        "               * (normalized_high - normalized_low) + normalized_low\n",
        "\n",
        "# Plot a confusion matrix.\n",
        "# cm is the confusion matrix, names are the names of the classes.\n",
        "def plot_confusion_matrix(cm, names, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(names))\n",
        "    plt.xticks(tick_marks, names, rotation=45)\n",
        "    plt.yticks(tick_marks, names)\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.show()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qU8FIYWRVXM1"
      },
      "source": [
        "### Switch and Verify GPU\n",
        "\n",
        "Since this notebook was created on <a href=\"https://colab.research.google.com/drive/1ru6-T555ccm0_hJTeuJqcubnE_RCZEo4?usp=sharing\">Google Colab</a> we need to enable a GPU backend. To do this, change the following setting: *Runtime -> Change Runtime Type -> Hardware Accelerator -> GPU*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1s9pBa09U_zJ",
        "outputId": "58f5833c-12a4-4a9a-d7b0-7c19af8c41a4"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFpkSEEDbTag"
      },
      "source": [
        "*If the above code outputs '/device:GPU:0',  you have switched to a GPU successfully and you are ready to go!*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58AD8DihfjYp"
      },
      "source": [
        "### Mount Google Drive for File Persistence\n",
        "Here I mount my personal Google Drive so we can have file persistence by saving my models in my drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOdjzXWzfv0L",
        "outputId": "3e24bce1-c963-49d2-e359-8747b7bef22c"
      },
      "source": [
        "from google.colab import drive, auth\n",
        "\n",
        "#Authenticate\n",
        "auth.authenticate_user()\n",
        "\n",
        "#Mount drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "Kv39g9StfOff"
      },
      "source": [
        "### Part I: Image classification without transfer learning\n",
        "In this part of the assignment we will create custom CNN models to train on ``CIFAR-10``. However, before we create our models we must perform some data preprocessing.\n",
        "\n",
        "\n",
        "More information about the dataset used can be found <a href=\"https://www.cs.toronto.edu/~kriz/cifar.html\">here</a>."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0495-SoMfOfg"
      },
      "source": [
        "#  Load cifar-10 data and split it to training and test\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "num_classes = 10\n",
        "\n",
        "# The data split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DWyVv_efOfj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3396b2b8-2900-4b2d-dbbb-399efc58883a"
      },
      "source": [
        "# Print out data shape\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('y_train shape:', y_train.shape)\n",
        "print('x_test shape:', x_test.shape)\n",
        "print('y_test shape:', y_test.shape)\n",
        "\n",
        "# Print out the number of samples in each\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "y_train shape: (50000, 1)\n",
            "x_test shape: (10000, 32, 32, 3)\n",
            "y_test shape: (10000, 1)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_Z_IKevu2Ji",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "315493ef-5467-4fde-f139-fdd3190aa218"
      },
      "source": [
        "# Print out a random image in x_train as numpy array\n",
        "x_train[15]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[100, 168, 231],\n",
              "        [100, 168, 229],\n",
              "        [101, 167, 230],\n",
              "        ...,\n",
              "        [ 95, 165, 231],\n",
              "        [ 94, 165, 228],\n",
              "        [ 95, 167, 229]],\n",
              "\n",
              "       [[103, 170, 230],\n",
              "        [103, 168, 228],\n",
              "        [104, 168, 226],\n",
              "        ...,\n",
              "        [ 97, 167, 229],\n",
              "        [ 97, 166, 227],\n",
              "        [ 97, 168, 229]],\n",
              "\n",
              "       [[107, 174, 233],\n",
              "        [106, 172, 230],\n",
              "        [106, 173, 229],\n",
              "        ...,\n",
              "        [100, 170, 230],\n",
              "        [100, 170, 230],\n",
              "        [101, 172, 232]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[165, 178, 177],\n",
              "        [159, 170, 167],\n",
              "        [167, 177, 170],\n",
              "        ...,\n",
              "        [ 75, 117, 154],\n",
              "        [ 75, 120, 157],\n",
              "        [ 72, 120, 158]],\n",
              "\n",
              "       [[158, 174, 172],\n",
              "        [173, 186, 182],\n",
              "        [182, 193, 188],\n",
              "        ...,\n",
              "        [ 76, 119, 154],\n",
              "        [ 75, 119, 153],\n",
              "        [ 77, 121, 154]],\n",
              "\n",
              "       [[161, 176, 174],\n",
              "        [162, 176, 172],\n",
              "        [160, 171, 169],\n",
              "        ...,\n",
              "        [ 98, 137, 167],\n",
              "        [129, 160, 183],\n",
              "        [162, 185, 202]]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbcMvRhqvWAc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "a6a1de06-2418-4a83-9fa8-f34c978c84ec"
      },
      "source": [
        "# Print it out as image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(x_train[15])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f704a4aedd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMwUTdqp0rUJ"
      },
      "source": [
        "# Convert y_train from 2D to 1D \n",
        "y_train = y_train.reshape(50000)\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojvUNZgG0xVe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cba2743-0391-4d06-baa0-158ba4356701"
      },
      "source": [
        "y_train.shape\n",
        "\n",
        "# Expected output: (50000,)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcrolrznfOf2"
      },
      "source": [
        "# Convert y_test from 2D to 1D \n",
        "y_test = y_test.reshape(10000)\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iT3IYTNqfOf6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "285e9be7-285e-41db-88b8-df0e61d59336"
      },
      "source": [
        "y_test.shape\n",
        "\n",
        "# Expected output: (10000,)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-lWtPlHfOf9"
      },
      "source": [
        "# Convert class vectors to one hot format\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFzHf8QefOgC"
      },
      "source": [
        "# Convert data from int to float\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "# Normalize data\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXXjBVW1lDt1"
      },
      "source": [
        "### Custom CNN Models\n",
        "Below you can find the 5 custom models that I defined to train on the dataset. As you can see in the comments below, some of these models were pulled from websites and the last one was completely custom. Throughout these five models you will find all the required layers below, with my custom model incorporating them all. Each model was trained with varying hyper-parameter settings. More about this can be seen below.\n",
        "\n",
        "####  Required Layers:\n",
        "- Conv2D\n",
        "- Activation\n",
        "- MaxPooling2D\n",
        "- Flatten\n",
        "- Dropout\n",
        "- Dense"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grVEwQfQfOgE"
      },
      "source": [
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "\n",
        "#First three models were taken from: https://towardsdatascience.com/the-4-convolutional-neural-network-models-that-can-classify-your-fashion-images-9fe7f3e5399d\n",
        "#Fourth model was taken from: https://medium.com/@ksusorokina/image-classification-with-convolutional-neural-networks-496815db12a8\n",
        "#Fifth model is of my own design\n",
        "\n",
        "#CNN model with 1 CNN layer\n",
        "def cnn1(optimizer='adam', activation='relu'):\n",
        "  cnnModel = Sequential()\n",
        "  cnnModel.add(Conv2D(32, kernel_size=(3, 3), activation=activation, input_shape=(32, 32, 3)))\n",
        "  cnnModel.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  cnnModel.add(Dropout(0.2))  \n",
        "  cnnModel.add(Flatten())  \n",
        "  cnnModel.add(Dense(128, activation=activation))\n",
        "  cnnModel.add(Dense(10, activation='softmax'))\n",
        "  cnnModel.compile(loss=categorical_crossentropy, optimizer=optimizer, metrics=['accuracy'])\n",
        "  return cnnModel\n",
        "\n",
        "#CNN model with 3 CNN layers\n",
        "def cnn2(optimizer='adam', activation='relu'):\n",
        "  cnnModel = Sequential()\n",
        "  cnnModel.add(Conv2D(32, kernel_size=(3, 3), activation=activation, input_shape=(32, 32, 3)))\n",
        "  cnnModel.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  cnnModel.add(Dropout(0.25))\n",
        "  cnnModel.add(Conv2D(64, kernel_size=(3, 3), activation=activation))\n",
        "  cnnModel.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  cnnModel.add(Dropout(0.25))\n",
        "  cnnModel.add(Conv2D(128, kernel_size=(3, 3), activation=activation))\n",
        "  cnnModel.add(Dropout(0.4))\n",
        "  cnnModel.add(Flatten())\n",
        "  cnnModel.add(Dense(128, activation=activation))\n",
        "  cnnModel.add(Dropout(0.3))\n",
        "  cnnModel.add(Dense(10, activation='softmax'))\n",
        "  cnnModel.compile(loss=categorical_crossentropy, optimizer=optimizer, metrics=['accuracy'])\n",
        "  return cnnModel\n",
        "\n",
        "#CNN model with 4 CNN layers\n",
        "def cnn3(optimizer='adam', activation='relu'):\n",
        "  cnnModel = Sequential()\n",
        "  cnnModel.add(Conv2D(32, kernel_size=(3, 3), activation=activation, input_shape=(32, 32, 3)))\n",
        "  cnnModel.add(BatchNormalization())\n",
        "  cnnModel.add(Conv2D(32, kernel_size=(3, 3), activation=activation))\n",
        "  cnnModel.add(BatchNormalization())\n",
        "  cnnModel.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  cnnModel.add(Dropout(0.25))\n",
        "  cnnModel.add(Conv2D(64, kernel_size=(3, 3), activation=activation))\n",
        "  cnnModel.add(BatchNormalization())\n",
        "  cnnModel.add(Dropout(0.25))\n",
        "  cnnModel.add(Conv2D(128, kernel_size=(3, 3), activation=activation))\n",
        "  cnnModel.add(BatchNormalization())\n",
        "  cnnModel.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  cnnModel.add(Dropout(0.25))\n",
        "  cnnModel.add(Flatten())\n",
        "  cnnModel.add(Dense(512, activation=activation))\n",
        "  cnnModel.add(BatchNormalization())\n",
        "  cnnModel.add(Dropout(0.5))\n",
        "  cnnModel.add(Dense(128, activation=activation))\n",
        "  cnnModel.add(BatchNormalization())\n",
        "  cnnModel.add(Dropout(0.5))\n",
        "  cnnModel.add(Dense(10, activation='softmax'))\n",
        "  cnnModel.compile(loss=categorical_crossentropy, optimizer=optimizer, metrics=['accuracy'])\n",
        "  return cnnModel\n",
        "\n",
        "#CNN model with 3  CNN layers and Activation\n",
        "def cnn4(optimizer='adam', activation='relu'):\n",
        "  cnnModel = Sequential()\n",
        "  cnnModel.add(Conv2D(32, kernel_size=(3, 3), input_shape=(32, 32, 3)))\n",
        "  cnnModel.add(Activation(activation))\n",
        "  cnnModel.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  cnnModel.add(Conv2D(32, kernel_size=(3, 3)))\n",
        "  cnnModel.add(Activation(activation))\n",
        "  cnnModel.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  cnnModel.add(Conv2D(64, kernel_size=(3, 3)))\n",
        "  cnnModel.add(Activation(activation))\n",
        "  cnnModel.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  cnnModel.add(Flatten())\n",
        "  cnnModel.add(Dense(64))\n",
        "  cnnModel.add(Activation(activation))\n",
        "  cnnModel.add(Dropout(0.5))\n",
        "  cnnModel.add(Dense(10, activation='softmax'))\n",
        "  cnnModel.compile(loss=categorical_crossentropy, optimizer=optimizer, metrics=['accuracy'])\n",
        "  return cnnModel\n",
        "\n",
        "#CNN model of my own design\n",
        "def cnn5(optimizer='adam', activation='relu'):\n",
        "  cnnModel = Sequential()\n",
        "  cnnModel.add(Conv2D(32, kernel_size=(3, 3), strides=(2, 2), input_shape=(32, 32, 3)))\n",
        "  cnnModel.add(Activation(activation))\n",
        "  cnnModel.add(Conv2D(128, kernel_size=(3, 3), strides=(2, 2)))\n",
        "  cnnModel.add(Activation(activation))\n",
        "  cnnModel.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  cnnModel.add(Flatten())\n",
        "  cnnModel.add(Dense(64))\n",
        "  cnnModel.add(Activation(activation))\n",
        "  cnnModel.add(Dropout(0.5))\n",
        "  cnnModel.add(Dense(10, activation='softmax'))\n",
        "  cnnModel.compile(loss=categorical_crossentropy, optimizer=optimizer, metrics=['accuracy'])\n",
        "  return cnnModel"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FekC4kgffOgG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98174fd5-ee74-4aac-df6a-7bccbc499734"
      },
      "source": [
        "# Print model summary\n",
        "cnn1 = cnn1()\n",
        "cnn1.summary()\n",
        "print('\\n\\n')\n",
        "\n",
        "cnn2 = cnn2()\n",
        "cnn2.summary()\n",
        "print('\\n\\n')\n",
        "\n",
        "cnn3 = cnn3()\n",
        "cnn3.summary()\n",
        "print('\\n\\n')\n",
        "\n",
        "cnn4 = cnn4()\n",
        "cnn4.summary()\n",
        "print('\\n\\n')\n",
        "\n",
        "cnn5 = cnn5()\n",
        "cnn5.summary()\n",
        "\n",
        "#Add to list to easily loop over training\n",
        "modelList = [cnn1, cnn2, cnn3, cnn4, cnn5]"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 30, 30, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 7200)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               921728    \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 923,914\n",
            "Trainable params: 923,914\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 30, 30, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 13, 13, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 4, 4, 128)         73856     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 356,810\n",
            "Trainable params: 356,810\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 30, 30, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 30, 30, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 28, 28, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 28, 28, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 12, 12, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 12, 12, 64)        256       \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 10, 10, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 10, 10, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 5, 5, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 3200)              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 512)               1638912   \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,811,946\n",
            "Trainable params: 1,810,154\n",
            "Non-trainable params: 1,792\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_8 (Conv2D)            (None, 30, 30, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 13, 13, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 6, 6, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 4, 4, 64)          18496     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 4, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 2, 2, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 45,738\n",
            "Trainable params: 45,738\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_11 (Conv2D)           (None, 15, 15, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 7, 7, 128)         36992     \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 3, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 1152)              0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 64)                73792     \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 112,330\n",
            "Trainable params: 112,330\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVNwHr_AmKJi"
      },
      "source": [
        "### Compiling, Earlystopping, and Fitting\n",
        "Below you can see the code used to train my models. Please note, the actual model is compiled in the function defined above. As required, earlystopping and checkpoints are used to help prevent overfitting.\n",
        "<br><br>\n",
        "**Note:** Each model was trained 3 times to help prevent finding local optima. The first section of code just trains models with Relu activation functions and Adam optimizers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUxCqaaZfOgI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12f6f58c-95ca-4222-8beb-836b315f3091"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "#NOTE: Models have already been compiled in the previous step\n",
        "i = 1\n",
        "\n",
        "#Create monitor\n",
        "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=4, verbose=1, mode='auto')\n",
        "\n",
        "#For each model, fit\n",
        "for model in modelList:\n",
        "  print('Training model: ' + str(i))\n",
        "  #Train each 3 times, saving the best\n",
        "  for x in range(0, 3):\n",
        "    print('Training version: ' + str(x))\n",
        "    checkpointer = ModelCheckpoint(filepath='/content/drive/MyDrive/CSC180_Project3/relu_adam/best_weights_' + str(i) + '.hdf5', verbose=0, save_best_only=True)\n",
        "    model.fit(x_train, y_train, validation_data=(x_test, y_test), callbacks=[monitor, checkpointer], verbose=1, epochs=1000)\n",
        "\n",
        "    #Predict and print report\n",
        "    pred = model.predict(x_test)\n",
        "    pred = np.argmax(pred, axis=1)\n",
        "    print('F1 Score: ' + str(f1_score(np.argmax(y_test, axis=1), pred, average='micro')))\n",
        "\n",
        "    #Recreate the model\n",
        "    print('\\nRecreating Default Model: ' + str(i))\n",
        "    if i == 1:\n",
        "      model = cnn1()\n",
        "    elif i == 2:\n",
        "      model = cnn2()\n",
        "    elif i == 3:\n",
        "      model = cnn3()\n",
        "    elif i == 4:\n",
        "      model = cnn4()\n",
        "    else:\n",
        "      model = cnn5()\n",
        "\n",
        "  #Load best weights\n",
        "  model.load_weights('/content/drive/MyDrive/CSC180_Project3/relu_adam/best_weights_' + str(i) + '.hdf5')\n",
        "\n",
        "  #Predict and print report\n",
        "  print('Best Model: ' + str(i))\n",
        "  pred = model.predict(x_test)\n",
        "  pred = np.argmax(pred, axis=1)\n",
        "  print('F1 Score: ' + str(f1_score(np.argmax(y_test, axis=1), pred, average='micro')))\n",
        "  i += 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training model: 1\n",
            "Training version: 0\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6225 - accuracy: 0.7796 - val_loss: 1.0887 - val_accuracy: 0.6614\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.5992 - accuracy: 0.7885 - val_loss: 1.0726 - val_accuracy: 0.6565\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.5665 - accuracy: 0.8010 - val_loss: 1.1326 - val_accuracy: 0.6509\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.5457 - accuracy: 0.8068 - val_loss: 1.1336 - val_accuracy: 0.6497\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.5227 - accuracy: 0.8137 - val_loss: 1.1607 - val_accuracy: 0.6501\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.4979 - accuracy: 0.8238 - val_loss: 1.1949 - val_accuracy: 0.6454\n",
            "Epoch 00006: early stopping\n",
            "F1 Score: 0.6454\n",
            "\n",
            "Recreating Default Model: 1\n",
            "Training version: 1\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6861 - accuracy: 0.3993 - val_loss: 1.2431 - val_accuracy: 0.5682\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.2096 - accuracy: 0.5744 - val_loss: 1.1482 - val_accuracy: 0.5973\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.0938 - accuracy: 0.6147 - val_loss: 1.1462 - val_accuracy: 0.6027\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0044 - accuracy: 0.6477 - val_loss: 1.0477 - val_accuracy: 0.6405\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.9311 - accuracy: 0.6713 - val_loss: 1.0152 - val_accuracy: 0.6523\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.8776 - accuracy: 0.6911 - val_loss: 1.0169 - val_accuracy: 0.6524\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8197 - accuracy: 0.7124 - val_loss: 1.0187 - val_accuracy: 0.6525\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.7797 - accuracy: 0.7253 - val_loss: 1.0257 - val_accuracy: 0.6483\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.7474 - accuracy: 0.7371 - val_loss: 1.0544 - val_accuracy: 0.6473\n",
            "Epoch 00009: early stopping\n",
            "F1 Score: 0.6473\n",
            "\n",
            "Recreating Default Model: 1\n",
            "Training version: 2\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6432 - accuracy: 0.4086 - val_loss: 1.2521 - val_accuracy: 0.5598\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.1994 - accuracy: 0.5801 - val_loss: 1.1438 - val_accuracy: 0.5995\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.0733 - accuracy: 0.6252 - val_loss: 1.1138 - val_accuracy: 0.6090\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.9936 - accuracy: 0.6491 - val_loss: 1.0439 - val_accuracy: 0.6345\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.9198 - accuracy: 0.6789 - val_loss: 1.0593 - val_accuracy: 0.6260\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8675 - accuracy: 0.6921 - val_loss: 1.0219 - val_accuracy: 0.6478\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8210 - accuracy: 0.7083 - val_loss: 1.0426 - val_accuracy: 0.6418\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7867 - accuracy: 0.7204 - val_loss: 1.0262 - val_accuracy: 0.6499\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7456 - accuracy: 0.7360 - val_loss: 1.0444 - val_accuracy: 0.6511\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.7118 - accuracy: 0.7477 - val_loss: 1.0523 - val_accuracy: 0.6562\n",
            "Epoch 00010: early stopping\n",
            "F1 Score: 0.6562\n",
            "\n",
            "Recreating Default Model: 1\n",
            "Best Model: 1\n",
            "F1 Score: 0.6478\n",
            "Training model: 2\n",
            "Training version: 0\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.8493 - accuracy: 0.3147 - val_loss: 1.2904 - val_accuracy: 0.5386\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3494 - accuracy: 0.5180 - val_loss: 1.1460 - val_accuracy: 0.5912\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1934 - accuracy: 0.5787 - val_loss: 1.0795 - val_accuracy: 0.6122\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1087 - accuracy: 0.6117 - val_loss: 0.9527 - val_accuracy: 0.6646\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0492 - accuracy: 0.6313 - val_loss: 0.9245 - val_accuracy: 0.6718\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9971 - accuracy: 0.6489 - val_loss: 0.9829 - val_accuracy: 0.6503\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9751 - accuracy: 0.6562 - val_loss: 0.8616 - val_accuracy: 0.7027\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9461 - accuracy: 0.6692 - val_loss: 0.8859 - val_accuracy: 0.6873\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9173 - accuracy: 0.6758 - val_loss: 0.8788 - val_accuracy: 0.6933\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9091 - accuracy: 0.6826 - val_loss: 0.8721 - val_accuracy: 0.6978\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8895 - accuracy: 0.6860 - val_loss: 0.8007 - val_accuracy: 0.7204\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8689 - accuracy: 0.6930 - val_loss: 0.8309 - val_accuracy: 0.7106\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8529 - accuracy: 0.6980 - val_loss: 0.8614 - val_accuracy: 0.7020\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8448 - accuracy: 0.7081 - val_loss: 0.7883 - val_accuracy: 0.7258\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8360 - accuracy: 0.7075 - val_loss: 0.7817 - val_accuracy: 0.7260\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8209 - accuracy: 0.7078 - val_loss: 0.7471 - val_accuracy: 0.7429\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7956 - accuracy: 0.7186 - val_loss: 0.7709 - val_accuracy: 0.7338\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8109 - accuracy: 0.7140 - val_loss: 0.7668 - val_accuracy: 0.7333\n",
            "Epoch 19/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7966 - accuracy: 0.7211 - val_loss: 0.7290 - val_accuracy: 0.7476\n",
            "Epoch 20/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7849 - accuracy: 0.7258 - val_loss: 0.7429 - val_accuracy: 0.7414\n",
            "Epoch 21/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7763 - accuracy: 0.7322 - val_loss: 0.7742 - val_accuracy: 0.7335\n",
            "Epoch 22/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7689 - accuracy: 0.7327 - val_loss: 0.7440 - val_accuracy: 0.7444\n",
            "Epoch 23/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7682 - accuracy: 0.7326 - val_loss: 0.7438 - val_accuracy: 0.7443\n",
            "Epoch 00023: early stopping\n",
            "F1 Score: 0.7443000000000001\n",
            "\n",
            "Recreating Default Model: 2\n",
            "Training version: 1\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.8458 - accuracy: 0.3111 - val_loss: 1.2829 - val_accuracy: 0.5295\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3430 - accuracy: 0.5218 - val_loss: 1.1469 - val_accuracy: 0.5992\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1967 - accuracy: 0.5734 - val_loss: 1.0652 - val_accuracy: 0.6295\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1130 - accuracy: 0.6098 - val_loss: 0.9378 - val_accuracy: 0.6729\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0471 - accuracy: 0.6297 - val_loss: 0.9092 - val_accuracy: 0.6804\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9945 - accuracy: 0.6490 - val_loss: 0.8963 - val_accuracy: 0.6883\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9728 - accuracy: 0.6563 - val_loss: 0.8541 - val_accuracy: 0.6986\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9351 - accuracy: 0.6701 - val_loss: 0.8536 - val_accuracy: 0.7009\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9019 - accuracy: 0.6794 - val_loss: 0.8507 - val_accuracy: 0.7028\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8855 - accuracy: 0.6908 - val_loss: 0.8026 - val_accuracy: 0.7195\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8728 - accuracy: 0.6922 - val_loss: 0.7835 - val_accuracy: 0.7298\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8503 - accuracy: 0.7020 - val_loss: 0.8165 - val_accuracy: 0.7182\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8476 - accuracy: 0.7020 - val_loss: 0.7855 - val_accuracy: 0.7282\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8407 - accuracy: 0.7066 - val_loss: 0.7439 - val_accuracy: 0.7440\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8162 - accuracy: 0.7162 - val_loss: 0.7750 - val_accuracy: 0.7271\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8042 - accuracy: 0.7156 - val_loss: 0.7948 - val_accuracy: 0.7229\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7978 - accuracy: 0.7181 - val_loss: 0.7902 - val_accuracy: 0.7258\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7894 - accuracy: 0.7176 - val_loss: 0.7505 - val_accuracy: 0.7371\n",
            "Epoch 00018: early stopping\n",
            "F1 Score: 0.7371\n",
            "\n",
            "Recreating Default Model: 2\n",
            "Training version: 2\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.8404 - accuracy: 0.3129 - val_loss: 1.2766 - val_accuracy: 0.5533\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3118 - accuracy: 0.5298 - val_loss: 1.0871 - val_accuracy: 0.6130\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1645 - accuracy: 0.5847 - val_loss: 0.9706 - val_accuracy: 0.6596\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0736 - accuracy: 0.6213 - val_loss: 0.9620 - val_accuracy: 0.6643\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0241 - accuracy: 0.6388 - val_loss: 0.9037 - val_accuracy: 0.6867\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9783 - accuracy: 0.6555 - val_loss: 0.8651 - val_accuracy: 0.7037\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9582 - accuracy: 0.6653 - val_loss: 0.9044 - val_accuracy: 0.6833\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9298 - accuracy: 0.6759 - val_loss: 0.8591 - val_accuracy: 0.7035\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8994 - accuracy: 0.6847 - val_loss: 0.8323 - val_accuracy: 0.7097\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8901 - accuracy: 0.6873 - val_loss: 0.8073 - val_accuracy: 0.7220\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8718 - accuracy: 0.6966 - val_loss: 0.8208 - val_accuracy: 0.7206\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8595 - accuracy: 0.7011 - val_loss: 0.8222 - val_accuracy: 0.7160\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8417 - accuracy: 0.7038 - val_loss: 0.7750 - val_accuracy: 0.7329\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8316 - accuracy: 0.7065 - val_loss: 0.8128 - val_accuracy: 0.7165\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8175 - accuracy: 0.7166 - val_loss: 0.7696 - val_accuracy: 0.7362\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8050 - accuracy: 0.7141 - val_loss: 0.7354 - val_accuracy: 0.7466\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8128 - accuracy: 0.7176 - val_loss: 0.7553 - val_accuracy: 0.7423\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7979 - accuracy: 0.7203 - val_loss: 0.7294 - val_accuracy: 0.7470\n",
            "Epoch 19/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7802 - accuracy: 0.7246 - val_loss: 0.8444 - val_accuracy: 0.7129\n",
            "Epoch 20/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7852 - accuracy: 0.7241 - val_loss: 0.7547 - val_accuracy: 0.7395\n",
            "Epoch 21/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7727 - accuracy: 0.7304 - val_loss: 0.7339 - val_accuracy: 0.7434\n",
            "Epoch 22/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7679 - accuracy: 0.7284 - val_loss: 0.7129 - val_accuracy: 0.7518\n",
            "Epoch 23/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7659 - accuracy: 0.7296 - val_loss: 0.7237 - val_accuracy: 0.7477\n",
            "Epoch 24/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7537 - accuracy: 0.7350 - val_loss: 0.7390 - val_accuracy: 0.7497\n",
            "Epoch 25/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7467 - accuracy: 0.7381 - val_loss: 0.7254 - val_accuracy: 0.7501\n",
            "Epoch 26/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7539 - accuracy: 0.7341 - val_loss: 0.7838 - val_accuracy: 0.7267\n",
            "Epoch 00026: early stopping\n",
            "F1 Score: 0.7267\n",
            "\n",
            "Recreating Default Model: 2\n",
            "Best Model: 2\n",
            "F1 Score: 0.7518\n",
            "Training model: 3\n",
            "Training version: 0\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 10s 5ms/step - loss: 2.0380 - accuracy: 0.3389 - val_loss: 1.4652 - val_accuracy: 0.4771\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2117 - accuracy: 0.5710 - val_loss: 1.0469 - val_accuracy: 0.6215\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0314 - accuracy: 0.6401 - val_loss: 0.8387 - val_accuracy: 0.7058\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.9311 - accuracy: 0.6804 - val_loss: 0.7917 - val_accuracy: 0.7229\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8442 - accuracy: 0.7111 - val_loss: 0.7292 - val_accuracy: 0.7418\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8015 - accuracy: 0.7261 - val_loss: 0.6978 - val_accuracy: 0.7566\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7454 - accuracy: 0.7425 - val_loss: 0.7509 - val_accuracy: 0.7398\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7148 - accuracy: 0.7558 - val_loss: 0.6204 - val_accuracy: 0.7830\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6775 - accuracy: 0.7684 - val_loss: 0.7409 - val_accuracy: 0.7443\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6434 - accuracy: 0.7791 - val_loss: 0.6184 - val_accuracy: 0.7830\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6278 - accuracy: 0.7846 - val_loss: 0.5605 - val_accuracy: 0.8058\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5986 - accuracy: 0.7938 - val_loss: 0.5786 - val_accuracy: 0.8011\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5783 - accuracy: 0.8039 - val_loss: 0.5778 - val_accuracy: 0.8071\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5686 - accuracy: 0.8062 - val_loss: 0.7433 - val_accuracy: 0.7481\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5533 - accuracy: 0.8111 - val_loss: 0.5403 - val_accuracy: 0.8174\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5313 - accuracy: 0.8190 - val_loss: 0.5436 - val_accuracy: 0.8147\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5194 - accuracy: 0.8231 - val_loss: 0.5482 - val_accuracy: 0.8140\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5222 - accuracy: 0.8205 - val_loss: 0.5271 - val_accuracy: 0.8222\n",
            "Epoch 19/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4952 - accuracy: 0.8297 - val_loss: 0.5210 - val_accuracy: 0.8239\n",
            "Epoch 20/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4913 - accuracy: 0.8317 - val_loss: 0.5525 - val_accuracy: 0.8153\n",
            "Epoch 21/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4762 - accuracy: 0.8369 - val_loss: 0.5671 - val_accuracy: 0.8124\n",
            "Epoch 22/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4761 - accuracy: 0.8378 - val_loss: 0.5864 - val_accuracy: 0.8063\n",
            "Epoch 23/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4594 - accuracy: 0.8429 - val_loss: 0.5260 - val_accuracy: 0.8251\n",
            "Epoch 00023: early stopping\n",
            "F1 Score: 0.8251\n",
            "\n",
            "Recreating Default Model: 3\n",
            "Training version: 1\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 2.0977 - accuracy: 0.3290 - val_loss: 1.5938 - val_accuracy: 0.4309\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2317 - accuracy: 0.5612 - val_loss: 1.3390 - val_accuracy: 0.5463\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0398 - accuracy: 0.6350 - val_loss: 0.9855 - val_accuracy: 0.6507\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.9336 - accuracy: 0.6772 - val_loss: 0.9040 - val_accuracy: 0.6848\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8532 - accuracy: 0.7028 - val_loss: 0.8697 - val_accuracy: 0.7001\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8039 - accuracy: 0.7227 - val_loss: 0.6769 - val_accuracy: 0.7664\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7523 - accuracy: 0.7411 - val_loss: 0.6453 - val_accuracy: 0.7783\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7106 - accuracy: 0.7579 - val_loss: 0.6536 - val_accuracy: 0.7697\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6853 - accuracy: 0.7654 - val_loss: 0.6973 - val_accuracy: 0.7591\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6547 - accuracy: 0.7752 - val_loss: 0.6162 - val_accuracy: 0.7864\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6247 - accuracy: 0.7873 - val_loss: 0.6449 - val_accuracy: 0.7811\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5977 - accuracy: 0.7954 - val_loss: 0.5685 - val_accuracy: 0.8044\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5898 - accuracy: 0.8001 - val_loss: 0.7970 - val_accuracy: 0.7352\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5610 - accuracy: 0.8076 - val_loss: 0.6534 - val_accuracy: 0.7758\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5440 - accuracy: 0.8156 - val_loss: 0.5944 - val_accuracy: 0.7932\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5256 - accuracy: 0.8227 - val_loss: 0.5527 - val_accuracy: 0.8115\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5178 - accuracy: 0.8236 - val_loss: 0.5388 - val_accuracy: 0.8183\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5128 - accuracy: 0.8229 - val_loss: 0.5689 - val_accuracy: 0.8105\n",
            "Epoch 19/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4967 - accuracy: 0.8297 - val_loss: 0.5326 - val_accuracy: 0.8188\n",
            "Epoch 20/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4750 - accuracy: 0.8403 - val_loss: 0.5603 - val_accuracy: 0.8114\n",
            "Epoch 21/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4670 - accuracy: 0.8399 - val_loss: 0.5144 - val_accuracy: 0.8237\n",
            "Epoch 22/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4575 - accuracy: 0.8454 - val_loss: 0.5200 - val_accuracy: 0.8273\n",
            "Epoch 23/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4618 - accuracy: 0.8421 - val_loss: 0.5259 - val_accuracy: 0.8261\n",
            "Epoch 24/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4459 - accuracy: 0.8468 - val_loss: 0.5150 - val_accuracy: 0.8283\n",
            "Epoch 25/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4310 - accuracy: 0.8510 - val_loss: 0.5217 - val_accuracy: 0.8239\n",
            "Epoch 00025: early stopping\n",
            "F1 Score: 0.8239000000000001\n",
            "\n",
            "Recreating Default Model: 3\n",
            "Training version: 2\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 10s 5ms/step - loss: 2.0388 - accuracy: 0.3394 - val_loss: 1.7204 - val_accuracy: 0.4254\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2057 - accuracy: 0.5728 - val_loss: 1.1060 - val_accuracy: 0.6141\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0330 - accuracy: 0.6397 - val_loss: 0.9785 - val_accuracy: 0.6574\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.9309 - accuracy: 0.6774 - val_loss: 0.8710 - val_accuracy: 0.6956\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8613 - accuracy: 0.7034 - val_loss: 0.8784 - val_accuracy: 0.6905\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8352 - accuracy: 0.7157 - val_loss: 0.7175 - val_accuracy: 0.7491\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7533 - accuracy: 0.7413 - val_loss: 0.6977 - val_accuracy: 0.7594\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7216 - accuracy: 0.7544 - val_loss: 0.6295 - val_accuracy: 0.7821\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6854 - accuracy: 0.7652 - val_loss: 0.6373 - val_accuracy: 0.7789\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6581 - accuracy: 0.7748 - val_loss: 0.6184 - val_accuracy: 0.7902\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6250 - accuracy: 0.7864 - val_loss: 0.6202 - val_accuracy: 0.7881\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6118 - accuracy: 0.7902 - val_loss: 0.8227 - val_accuracy: 0.7312\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5859 - accuracy: 0.8006 - val_loss: 0.5975 - val_accuracy: 0.7970\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5671 - accuracy: 0.8065 - val_loss: 0.5552 - val_accuracy: 0.8133\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5473 - accuracy: 0.8121 - val_loss: 0.5605 - val_accuracy: 0.8099\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5386 - accuracy: 0.8183 - val_loss: 0.5568 - val_accuracy: 0.8128\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5144 - accuracy: 0.8234 - val_loss: 0.5671 - val_accuracy: 0.8056\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4992 - accuracy: 0.8284 - val_loss: 0.5495 - val_accuracy: 0.8137\n",
            "Epoch 19/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4980 - accuracy: 0.8285 - val_loss: 0.5623 - val_accuracy: 0.8112\n",
            "Epoch 20/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4738 - accuracy: 0.8377 - val_loss: 0.5612 - val_accuracy: 0.8141\n",
            "Epoch 21/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4783 - accuracy: 0.8348 - val_loss: 0.4912 - val_accuracy: 0.8349\n",
            "Epoch 22/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4685 - accuracy: 0.8403 - val_loss: 0.5287 - val_accuracy: 0.8233\n",
            "Epoch 23/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4546 - accuracy: 0.8408 - val_loss: 0.5304 - val_accuracy: 0.8253\n",
            "Epoch 24/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4458 - accuracy: 0.8504 - val_loss: 0.5001 - val_accuracy: 0.8321\n",
            "Epoch 25/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4361 - accuracy: 0.8485 - val_loss: 0.5299 - val_accuracy: 0.8261\n",
            "Epoch 00025: early stopping\n",
            "F1 Score: 0.8261\n",
            "\n",
            "Recreating Default Model: 3\n",
            "Best Model: 3\n",
            "F1 Score: 0.8349000000000001\n",
            "Training model: 4\n",
            "Training version: 0\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.9714 - accuracy: 0.2580 - val_loss: 1.3652 - val_accuracy: 0.5014\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 5s 4ms/step - loss: 1.4751 - accuracy: 0.4678 - val_loss: 1.2601 - val_accuracy: 0.5474\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3416 - accuracy: 0.5226 - val_loss: 1.1825 - val_accuracy: 0.5769\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2485 - accuracy: 0.5567 - val_loss: 1.1271 - val_accuracy: 0.6016\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1860 - accuracy: 0.5840 - val_loss: 1.0822 - val_accuracy: 0.6180\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1415 - accuracy: 0.6008 - val_loss: 1.0944 - val_accuracy: 0.6166\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0782 - accuracy: 0.6194 - val_loss: 1.0153 - val_accuracy: 0.6499\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0637 - accuracy: 0.6304 - val_loss: 1.0130 - val_accuracy: 0.6443\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0223 - accuracy: 0.6433 - val_loss: 1.0030 - val_accuracy: 0.6501\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0095 - accuracy: 0.6486 - val_loss: 0.9830 - val_accuracy: 0.6573\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9850 - accuracy: 0.6578 - val_loss: 0.9725 - val_accuracy: 0.6614\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9700 - accuracy: 0.6611 - val_loss: 0.9599 - val_accuracy: 0.6659\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9503 - accuracy: 0.6690 - val_loss: 0.9476 - val_accuracy: 0.6765\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9130 - accuracy: 0.6811 - val_loss: 0.9878 - val_accuracy: 0.6562\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9209 - accuracy: 0.6787 - val_loss: 0.9143 - val_accuracy: 0.6855\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8990 - accuracy: 0.6850 - val_loss: 0.9247 - val_accuracy: 0.6873\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8873 - accuracy: 0.6928 - val_loss: 0.9255 - val_accuracy: 0.6787\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8786 - accuracy: 0.6954 - val_loss: 0.9126 - val_accuracy: 0.6860\n",
            "Epoch 19/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8637 - accuracy: 0.6988 - val_loss: 0.9197 - val_accuracy: 0.6866\n",
            "Epoch 20/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8451 - accuracy: 0.7056 - val_loss: 0.9465 - val_accuracy: 0.6770\n",
            "Epoch 21/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8419 - accuracy: 0.7046 - val_loss: 0.9005 - val_accuracy: 0.6962\n",
            "Epoch 22/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8392 - accuracy: 0.7071 - val_loss: 0.9005 - val_accuracy: 0.6916\n",
            "Epoch 23/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8170 - accuracy: 0.7090 - val_loss: 0.9117 - val_accuracy: 0.6914\n",
            "Epoch 24/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8102 - accuracy: 0.7191 - val_loss: 0.9070 - val_accuracy: 0.6958\n",
            "Epoch 25/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7999 - accuracy: 0.7219 - val_loss: 0.9263 - val_accuracy: 0.6935\n",
            "Epoch 00025: early stopping\n",
            "F1 Score: 0.6935\n",
            "\n",
            "Recreating Default Model: 4\n",
            "Training version: 1\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.9980 - accuracy: 0.2464 - val_loss: 1.5074 - val_accuracy: 0.4548\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5512 - accuracy: 0.4359 - val_loss: 1.2982 - val_accuracy: 0.5358\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 5s 4ms/step - loss: 1.3921 - accuracy: 0.5024 - val_loss: 1.2069 - val_accuracy: 0.5698\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 5s 4ms/step - loss: 1.2988 - accuracy: 0.5411 - val_loss: 1.1573 - val_accuracy: 0.5915\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2197 - accuracy: 0.5687 - val_loss: 1.1250 - val_accuracy: 0.5991\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1663 - accuracy: 0.5888 - val_loss: 1.1280 - val_accuracy: 0.6067\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1195 - accuracy: 0.6108 - val_loss: 1.0142 - val_accuracy: 0.6444\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0717 - accuracy: 0.6260 - val_loss: 1.0078 - val_accuracy: 0.6468\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 5s 4ms/step - loss: 1.0246 - accuracy: 0.6449 - val_loss: 0.9938 - val_accuracy: 0.6526\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0125 - accuracy: 0.6468 - val_loss: 0.9562 - val_accuracy: 0.6721\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9809 - accuracy: 0.6576 - val_loss: 0.9741 - val_accuracy: 0.6690\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9577 - accuracy: 0.6656 - val_loss: 0.9504 - val_accuracy: 0.6736\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9397 - accuracy: 0.6757 - val_loss: 1.0016 - val_accuracy: 0.6572\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9187 - accuracy: 0.6822 - val_loss: 0.9431 - val_accuracy: 0.6743\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8940 - accuracy: 0.6908 - val_loss: 0.9260 - val_accuracy: 0.6828\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 5s 4ms/step - loss: 0.8836 - accuracy: 0.6924 - val_loss: 0.9235 - val_accuracy: 0.6828\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 5s 4ms/step - loss: 0.8680 - accuracy: 0.6949 - val_loss: 0.9067 - val_accuracy: 0.6861\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8455 - accuracy: 0.7038 - val_loss: 0.8996 - val_accuracy: 0.6909\n",
            "Epoch 19/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8447 - accuracy: 0.7071 - val_loss: 0.9007 - val_accuracy: 0.6879\n",
            "Epoch 20/1000\n",
            "1563/1563 [==============================] - 5s 4ms/step - loss: 0.8273 - accuracy: 0.7133 - val_loss: 0.9133 - val_accuracy: 0.6870\n",
            "Epoch 21/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8294 - accuracy: 0.7076 - val_loss: 0.9203 - val_accuracy: 0.6901\n",
            "Epoch 22/1000\n",
            "1563/1563 [==============================] - 5s 4ms/step - loss: 0.8128 - accuracy: 0.7163 - val_loss: 0.9189 - val_accuracy: 0.6867\n",
            "Epoch 00022: early stopping\n",
            "F1 Score: 0.6867\n",
            "\n",
            "Recreating Default Model: 4\n",
            "Training version: 2\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.9426 - accuracy: 0.2713 - val_loss: 1.4695 - val_accuracy: 0.4654\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.4506 - accuracy: 0.4777 - val_loss: 1.2237 - val_accuracy: 0.5614\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2936 - accuracy: 0.5402 - val_loss: 1.1571 - val_accuracy: 0.5820\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1941 - accuracy: 0.5734 - val_loss: 1.0576 - val_accuracy: 0.6260\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1089 - accuracy: 0.6127 - val_loss: 1.0495 - val_accuracy: 0.6280\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0643 - accuracy: 0.6256 - val_loss: 1.0197 - val_accuracy: 0.6381\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0117 - accuracy: 0.6471 - val_loss: 0.9892 - val_accuracy: 0.6553\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9908 - accuracy: 0.6571 - val_loss: 0.9748 - val_accuracy: 0.6569\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9426 - accuracy: 0.6743 - val_loss: 0.9475 - val_accuracy: 0.6696\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9280 - accuracy: 0.6783 - val_loss: 0.9390 - val_accuracy: 0.6721\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9036 - accuracy: 0.6879 - val_loss: 0.8982 - val_accuracy: 0.6924\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8671 - accuracy: 0.6991 - val_loss: 0.9085 - val_accuracy: 0.6844\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8554 - accuracy: 0.7014 - val_loss: 0.9390 - val_accuracy: 0.6863\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8331 - accuracy: 0.7084 - val_loss: 0.8784 - val_accuracy: 0.6979\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8107 - accuracy: 0.7158 - val_loss: 0.8787 - val_accuracy: 0.6996\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7951 - accuracy: 0.7228 - val_loss: 0.8689 - val_accuracy: 0.7062\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7933 - accuracy: 0.7208 - val_loss: 0.8762 - val_accuracy: 0.7051\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7765 - accuracy: 0.7283 - val_loss: 0.8810 - val_accuracy: 0.7013\n",
            "Epoch 19/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7687 - accuracy: 0.7326 - val_loss: 0.8611 - val_accuracy: 0.7137\n",
            "Epoch 20/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7505 - accuracy: 0.7373 - val_loss: 0.8848 - val_accuracy: 0.7025\n",
            "Epoch 21/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7424 - accuracy: 0.7385 - val_loss: 0.8745 - val_accuracy: 0.7045\n",
            "Epoch 22/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7254 - accuracy: 0.7439 - val_loss: 0.8755 - val_accuracy: 0.7114\n",
            "Epoch 23/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7300 - accuracy: 0.7445 - val_loss: 0.9338 - val_accuracy: 0.6925\n",
            "Epoch 00023: early stopping\n",
            "F1 Score: 0.6925\n",
            "\n",
            "Recreating Default Model: 4\n",
            "Best Model: 4\n",
            "F1 Score: 0.7137\n",
            "Training model: 5\n",
            "Training version: 0\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.9576 - accuracy: 0.2658 - val_loss: 1.5315 - val_accuracy: 0.4515\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5611 - accuracy: 0.4248 - val_loss: 1.3415 - val_accuracy: 0.5222\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4498 - accuracy: 0.4736 - val_loss: 1.2461 - val_accuracy: 0.5624\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3460 - accuracy: 0.5120 - val_loss: 1.2122 - val_accuracy: 0.5752\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3134 - accuracy: 0.5277 - val_loss: 1.1825 - val_accuracy: 0.5890\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2679 - accuracy: 0.5478 - val_loss: 1.1641 - val_accuracy: 0.5919\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2334 - accuracy: 0.5583 - val_loss: 1.1488 - val_accuracy: 0.5936\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2017 - accuracy: 0.5704 - val_loss: 1.1188 - val_accuracy: 0.6091\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1566 - accuracy: 0.5888 - val_loss: 1.0890 - val_accuracy: 0.6247\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1434 - accuracy: 0.5888 - val_loss: 1.0822 - val_accuracy: 0.6198\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1036 - accuracy: 0.6033 - val_loss: 1.0779 - val_accuracy: 0.6277\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0902 - accuracy: 0.6125 - val_loss: 1.0620 - val_accuracy: 0.6311\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0714 - accuracy: 0.6155 - val_loss: 1.0991 - val_accuracy: 0.6196\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0502 - accuracy: 0.6269 - val_loss: 1.0977 - val_accuracy: 0.6288\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0436 - accuracy: 0.6263 - val_loss: 1.0456 - val_accuracy: 0.6377\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0219 - accuracy: 0.6279 - val_loss: 1.0515 - val_accuracy: 0.6373\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0090 - accuracy: 0.6372 - val_loss: 1.0537 - val_accuracy: 0.6420\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9937 - accuracy: 0.6426 - val_loss: 1.0575 - val_accuracy: 0.6361\n",
            "Epoch 19/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9782 - accuracy: 0.6469 - val_loss: 1.0461 - val_accuracy: 0.6459\n",
            "Epoch 00019: early stopping\n",
            "F1 Score: 0.6459\n",
            "\n",
            "Recreating Default Model: 5\n",
            "Training version: 1\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.9929 - accuracy: 0.2494 - val_loss: 1.4628 - val_accuracy: 0.4771\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5736 - accuracy: 0.4213 - val_loss: 1.3097 - val_accuracy: 0.5221\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4465 - accuracy: 0.4728 - val_loss: 1.2721 - val_accuracy: 0.5481\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3690 - accuracy: 0.5016 - val_loss: 1.2033 - val_accuracy: 0.5639\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3273 - accuracy: 0.5202 - val_loss: 1.1910 - val_accuracy: 0.5819\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2777 - accuracy: 0.5393 - val_loss: 1.1404 - val_accuracy: 0.5942\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2295 - accuracy: 0.5499 - val_loss: 1.1496 - val_accuracy: 0.5994\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1995 - accuracy: 0.5696 - val_loss: 1.1528 - val_accuracy: 0.6003\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1680 - accuracy: 0.5799 - val_loss: 1.0914 - val_accuracy: 0.6171\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1517 - accuracy: 0.5853 - val_loss: 1.1106 - val_accuracy: 0.6109\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1254 - accuracy: 0.5978 - val_loss: 1.0778 - val_accuracy: 0.6235\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1098 - accuracy: 0.5976 - val_loss: 1.0806 - val_accuracy: 0.6262\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0811 - accuracy: 0.6073 - val_loss: 1.0765 - val_accuracy: 0.6330\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0352 - accuracy: 0.6254 - val_loss: 1.0609 - val_accuracy: 0.6277\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0157 - accuracy: 0.6291 - val_loss: 1.0447 - val_accuracy: 0.6361\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0024 - accuracy: 0.6375 - val_loss: 1.0592 - val_accuracy: 0.6351\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9891 - accuracy: 0.6426 - val_loss: 1.0485 - val_accuracy: 0.6412\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9693 - accuracy: 0.6504 - val_loss: 1.0636 - val_accuracy: 0.6338\n",
            "Epoch 19/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9586 - accuracy: 0.6512 - val_loss: 1.0343 - val_accuracy: 0.6464\n",
            "Epoch 20/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9527 - accuracy: 0.6528 - val_loss: 1.0593 - val_accuracy: 0.6356\n",
            "Epoch 21/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9319 - accuracy: 0.6603 - val_loss: 1.0470 - val_accuracy: 0.6485\n",
            "Epoch 22/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9186 - accuracy: 0.6676 - val_loss: 1.0550 - val_accuracy: 0.6430\n",
            "Epoch 23/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9000 - accuracy: 0.6719 - val_loss: 1.0667 - val_accuracy: 0.6450\n",
            "Epoch 00023: early stopping\n",
            "F1 Score: 0.645\n",
            "\n",
            "Recreating Default Model: 5\n",
            "Training version: 2\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 6s 3ms/step - loss: 1.9586 - accuracy: 0.2649 - val_loss: 1.4622 - val_accuracy: 0.4727\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5646 - accuracy: 0.4272 - val_loss: 1.3055 - val_accuracy: 0.5279\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4302 - accuracy: 0.4796 - val_loss: 1.2741 - val_accuracy: 0.5497\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3612 - accuracy: 0.5113 - val_loss: 1.1803 - val_accuracy: 0.5885\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3065 - accuracy: 0.5332 - val_loss: 1.1612 - val_accuracy: 0.5837\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2499 - accuracy: 0.5525 - val_loss: 1.1227 - val_accuracy: 0.6130\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2159 - accuracy: 0.5616 - val_loss: 1.1001 - val_accuracy: 0.6105\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1712 - accuracy: 0.5807 - val_loss: 1.0892 - val_accuracy: 0.6211\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1481 - accuracy: 0.5869 - val_loss: 1.0738 - val_accuracy: 0.6247\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1210 - accuracy: 0.5958 - val_loss: 1.0654 - val_accuracy: 0.6313\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0843 - accuracy: 0.6133 - val_loss: 1.0406 - val_accuracy: 0.6369\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0688 - accuracy: 0.6210 - val_loss: 1.0445 - val_accuracy: 0.6375\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0551 - accuracy: 0.6228 - val_loss: 1.0387 - val_accuracy: 0.6425\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0361 - accuracy: 0.6290 - val_loss: 1.0351 - val_accuracy: 0.6367\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0153 - accuracy: 0.6339 - val_loss: 1.0661 - val_accuracy: 0.6285\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0094 - accuracy: 0.6354 - val_loss: 1.0406 - val_accuracy: 0.6429\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9880 - accuracy: 0.6486 - val_loss: 1.0559 - val_accuracy: 0.6322\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9672 - accuracy: 0.6539 - val_loss: 1.0413 - val_accuracy: 0.6383\n",
            "Epoch 00018: early stopping\n",
            "F1 Score: 0.6383\n",
            "\n",
            "Recreating Default Model: 5\n",
            "Best Model: 5\n",
            "F1 Score: 0.6367\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dSPGkTsQWY5"
      },
      "source": [
        "### Hyper-Parameter Tuning\n",
        "In this code block, I take the 5 CNN models that I defined above and try different activation functions and optimizers. All combinations are tried except Relu/Adam as those were trained above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRvWlQF1Qkg0"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "#Create the models, don't need to train relu adam as those we're trained in the previous steps\n",
        "sigAdam1 = cnn1(optimizer='adam', activation='sigmoid')\n",
        "sigAdam2 = cnn2(optimizer='adam', activation='sigmoid')\n",
        "sigAdam3 = cnn3(optimizer='adam', activation='sigmoid')\n",
        "sigAdam4 = cnn4(optimizer='adam', activation='sigmoid')\n",
        "sigAdam5 = cnn5(optimizer='adam', activation='sigmoid')\n",
        "sigAdam = [sigAdam1, sigAdam2, sigAdam3, sigAdam4, sigAdam5]\n",
        "\n",
        "sigSGD1 = cnn1(optimizer='sgd', activation='sigmoid')\n",
        "sigSGD2 = cnn2(optimizer='sgd', activation='sigmoid')\n",
        "sigSGD3 = cnn3(optimizer='sgd', activation='sigmoid')\n",
        "sigSGD4 = cnn4(optimizer='sgd', activation='sigmoid')\n",
        "sigSGD5 = cnn5(optimizer='sgd', activation='sigmoid')\n",
        "sigSGD = [sigSGD1, sigSGD2, sigSGD3, sigSGD4, sigSGD5]\n",
        "\n",
        "tanAdam1 = cnn1(optimizer='adam', activation='tanh')\n",
        "tanAdam2 = cnn2(optimizer='adam', activation='tanh')\n",
        "tanAdam3 = cnn3(optimizer='adam', activation='tanh')\n",
        "tanAdam4 = cnn4(optimizer='adam', activation='tanh')\n",
        "tanAdam5 = cnn5(optimizer='adam', activation='tanh')\n",
        "tanAdam = [tanAdam1, tanAdam2, tanAdam3, tanAdam4, tanAdam5]\n",
        "\n",
        "tanSGD1 = cnn1(optimizer='sgd', activation='tanh')\n",
        "tanSGD2 = cnn2(optimizer='sgd', activation='tanh')\n",
        "tanSGD3 = cnn3(optimizer='sgd', activation='tanh')\n",
        "tanSGD4 = cnn4(optimizer='sgd', activation='tanh')\n",
        "tanSGD5 = cnn5(optimizer='sgd', activation='tanh')\n",
        "tanSGD = [tanSGD1, tanSGD2, tanSGD3, tanSGD4, tanSGD5]\n",
        "\n",
        "reluSGD1 = cnn1(optimizer='sgd', activation='relu')\n",
        "reluSGD2 = cnn2(optimizer='sgd', activation='relu')\n",
        "reluSGD3 = cnn3(optimizer='sgd', activation='relu')\n",
        "reluSGD4 = cnn4(optimizer='sgd', activation='relu')\n",
        "reluSGD5 = cnn5(optimizer='sgd', activation='relu')\n",
        "reluSGD = (reluSGD1, reluSGD2, reluSGD3, reluSGD4, reluSGD5)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNZyCBJIZCbM",
        "outputId": "1e75dd6e-b600-45c2-9207-73934eaf8413"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "#Create monitor\n",
        "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=4, verbose=1, mode='auto')\n",
        "\n",
        "#Fit sigAdam\n",
        "i = 1\n",
        "for model in sigAdam:\n",
        "  print('Training model: ' + str(i) + ' for Sig Adam')\n",
        "  #Train each 3 times, saving the best\n",
        "  for x in range(0, 3):\n",
        "    print('Training version: ' + str(x))\n",
        "    checkpointer = ModelCheckpoint(filepath='/content/drive/MyDrive/CSC180_Project3/sig_adam/best_weights_' + str(i) + '.hdf5', verbose=0, save_best_only=True)\n",
        "    model.fit(x_train, y_train, validation_data=(x_test, y_test), callbacks=[monitor, checkpointer], verbose=1, epochs=1000)\n",
        "\n",
        "    #Predict and print report\n",
        "    pred = model.predict(x_test)\n",
        "    pred = np.argmax(pred, axis=1)\n",
        "    print('F1 Score: ' + str(f1_score(np.argmax(y_test, axis=1), pred, average='micro')))\n",
        "\n",
        "    #Recreate the model\n",
        "    print('\\nRecreating Sig Adam Model: ' + str(i))\n",
        "    if i == 1:\n",
        "      model = cnn1(optimizer='adam', activation='sigmoid')\n",
        "    elif i == 2:\n",
        "      model = cnn2(optimizer='adam', activation='sigmoid')\n",
        "    elif i == 3:\n",
        "      model = cnn3(optimizer='adam', activation='sigmoid')\n",
        "    elif i == 4:\n",
        "      model = cnn4(optimizer='adam', activation='sigmoid')\n",
        "    else:\n",
        "      model = cnn5(optimizer='adam', activation='sigmoid')\n",
        "\n",
        "  #Load best weights\n",
        "  model.load_weights('/content/drive/MyDrive/CSC180_Project3/sig_adam/best_weights_' + str(i) + '.hdf5')\n",
        "\n",
        "  #Predict and print report\n",
        "  print('Best Model: ' + str(i) + ' for Sig Adam')\n",
        "  pred = model.predict(x_test)\n",
        "  pred = np.argmax(pred, axis=1)\n",
        "  print('F1 Score: ' + str(f1_score(np.argmax(y_test, axis=1), pred, average='micro')))\n",
        "  i += 1\n",
        "\n",
        "#Fit sigSGD\n",
        "i = 1\n",
        "for model in sigSGD:\n",
        "  print('Training model: ' + str(i) + ' for Sig SGD')\n",
        "  #Train each 3 times, saving the best\n",
        "  for x in range(0, 3):\n",
        "    print('Training version: ' + str(x))\n",
        "    checkpointer = ModelCheckpoint(filepath='/content/drive/MyDrive/CSC180_Project3/sig_sgd/best_weights_' + str(i) + '.hdf5', verbose=0, save_best_only=True)\n",
        "    model.fit(x_train, y_train, validation_data=(x_test, y_test), callbacks=[monitor, checkpointer], verbose=1, epochs=1000)\n",
        "\n",
        "    #Predict and print report\n",
        "    pred = model.predict(x_test)\n",
        "    pred = np.argmax(pred, axis=1)\n",
        "    print('F1 Score: ' + str(f1_score(np.argmax(y_test, axis=1), pred, average='micro')))\n",
        "\n",
        "    #Recreate the model\n",
        "    print('\\nRecreating Sig SGD Model: ' + str(i))\n",
        "    if i == 1:\n",
        "      model = cnn1(optimizer='sgd', activation='sigmoid')\n",
        "    elif i == 2:\n",
        "      model = cnn2(optimizer='sgd', activation='sigmoid')\n",
        "    elif i == 3:\n",
        "      model = cnn3(optimizer='sgd', activation='sigmoid')\n",
        "    elif i == 4:\n",
        "      model = cnn4(optimizer='sgd', activation='sigmoid')\n",
        "    else:\n",
        "      model = cnn5(optimizer='sgd', activation='sigmoid')\n",
        "\n",
        "  #Load best weights\n",
        "  model.load_weights('/content/drive/MyDrive/CSC180_Project3/sig_sgd/best_weights_' + str(i) + '.hdf5')\n",
        "\n",
        "  #Predict and print report\n",
        "  print('Best Model: ' + str(i) + ' for Sig SGD')\n",
        "  pred = model.predict(x_test)\n",
        "  pred = np.argmax(pred, axis=1)\n",
        "  print('F1 Score: ' + str(f1_score(np.argmax(y_test, axis=1), pred, average='micro')))\n",
        "  i += 1\n",
        "\n",
        "#Fit tanAdam\n",
        "i = 1\n",
        "for model in tanAdam:\n",
        "  print('Training model: ' + str(i) + ' for Tanh Adam')\n",
        "  #Train each 3 times, saving the best\n",
        "  for x in range(0, 3):\n",
        "    print('Training version: ' + str(x))\n",
        "    checkpointer = ModelCheckpoint(filepath='/content/drive/MyDrive/CSC180_Project3/tan_adam/best_weights_' + str(i) + '.hdf5', verbose=0, save_best_only=True)\n",
        "    model.fit(x_train, y_train, validation_data=(x_test, y_test), callbacks=[monitor, checkpointer], verbose=1, epochs=1000)\n",
        "\n",
        "    #Predict and print report\n",
        "    pred = model.predict(x_test)\n",
        "    pred = np.argmax(pred, axis=1)\n",
        "    print('F1 Score: ' + str(f1_score(np.argmax(y_test, axis=1), pred, average='micro')))\n",
        "\n",
        "    #Recreate the model\n",
        "    print('\\nRecreating Tanh Adam Model: ' + str(i))\n",
        "    if i == 1:\n",
        "      model = cnn1(optimizer='adam', activation='tanh')\n",
        "    elif i == 2:\n",
        "      model = cnn2(optimizer='adam', activation='tanh')\n",
        "    elif i == 3:\n",
        "      model = cnn3(optimizer='adam', activation='tanh')\n",
        "    elif i == 4:\n",
        "      model = cnn4(optimizer='adam', activation='tanh')\n",
        "    else:\n",
        "      model = cnn5(optimizer='adam', activation='tanh')\n",
        "\n",
        "  #Load best weights\n",
        "  model.load_weights('/content/drive/MyDrive/CSC180_Project3/tan_adam/best_weights_' + str(i) + '.hdf5')\n",
        "\n",
        "  #Predict and print report\n",
        "  print('Best Model: ' + str(i) + ' for Tanh Adam')\n",
        "  pred = model.predict(x_test)\n",
        "  pred = np.argmax(pred, axis=1)\n",
        "  print('F1 Score: ' + str(f1_score(np.argmax(y_test, axis=1), pred, average='micro')))\n",
        "  i += 1\n",
        "\n",
        "#Fit tanSGD\n",
        "i = 1\n",
        "for model in tanSGD:\n",
        "  print('Training model: ' + str(i) + ' for Tanh SGD')\n",
        "  #Train each 3 times, saving the best\n",
        "  for x in range(0, 3):\n",
        "    print('Training version: ' + str(x))\n",
        "    checkpointer = ModelCheckpoint(filepath='/content/drive/MyDrive/CSC180_Project3/tan_sgd/best_weights_' + str(i) + '.hdf5', verbose=0, save_best_only=True)\n",
        "    model.fit(x_train, y_train, validation_data=(x_test, y_test), callbacks=[monitor, checkpointer], verbose=1, epochs=1000)\n",
        "\n",
        "    #Predict and print report\n",
        "    pred = model.predict(x_test)\n",
        "    pred = np.argmax(pred, axis=1)\n",
        "    print('F1 Score: ' + str(f1_score(np.argmax(y_test, axis=1), pred, average='micro')))\n",
        "\n",
        "    #Recreate the model\n",
        "    print('\\nRecreating Tanh SGD Model: ' + str(i))\n",
        "    if i == 1:\n",
        "      model = cnn1(optimizer='sgd', activation='tanh')\n",
        "    elif i == 2:\n",
        "      model = cnn2(optimizer='sgd', activation='tanh')\n",
        "    elif i == 3:\n",
        "      model = cnn3(optimizer='sgd', activation='tanh')\n",
        "    elif i == 4:\n",
        "      model = cnn4(optimizer='sgd', activation='tanh')\n",
        "    else:\n",
        "      model = cnn5(optimizer='sgd', activation='tanh')\n",
        "\n",
        "  #Load best weights\n",
        "  model.load_weights('/content/drive/MyDrive/CSC180_Project3/tan_sgd/best_weights_' + str(i) + '.hdf5')\n",
        "\n",
        "  #Predict and print report\n",
        "  print('Best Model: ' + str(i) + ' for Tanh SGD')\n",
        "  pred = model.predict(x_test)\n",
        "  pred = np.argmax(pred, axis=1)\n",
        "  print('F1 Score: ' + str(f1_score(np.argmax(y_test, axis=1), pred, average='micro')))\n",
        "  i += 1\n",
        "\n",
        "#Fit relu sgd\n",
        "i = 1\n",
        "for model in reluSGD:\n",
        "  print('Training model: ' + str(i) + ' for Relu SGD')\n",
        "  #Train each 3 times, saving the best\n",
        "  for x in range(0, 3):\n",
        "    print('Training version: ' + str(x))\n",
        "    checkpointer = ModelCheckpoint(filepath='/content/drive/MyDrive/CSC180_Project3/relu_sgd/best_weights_' + str(i) + '.hdf5', verbose=0, save_best_only=True)\n",
        "    model.fit(x_train, y_train, validation_data=(x_test, y_test), callbacks=[monitor, checkpointer], verbose=1, epochs=1000)\n",
        "\n",
        "    #Predict and print report\n",
        "    pred = model.predict(x_test)\n",
        "    pred = np.argmax(pred, axis=1)\n",
        "    print('F1 Score: ' + str(f1_score(np.argmax(y_test, axis=1), pred, average='micro')))\n",
        "\n",
        "    #Recreate the model\n",
        "    print('\\nRecreating Relu SGD Model: ' + str(i))\n",
        "    if i == 1:\n",
        "      model = cnn1(optimizer='sgd', activation='relu')\n",
        "    elif i == 2:\n",
        "      model = cnn2(optimizer='sgd', activation='relu')\n",
        "    elif i == 3:\n",
        "      model = cnn3(optimizer='sgd', activation='relu')\n",
        "    elif i == 4:\n",
        "      model = cnn4(optimizer='sgd', activation='relu')\n",
        "    else:\n",
        "      model = cnn5(optimizer='sgd', activation='relu')\n",
        "\n",
        "  #Load best weights\n",
        "  model.load_weights('/content/drive/MyDrive/CSC180_Project3/relu_sgd/best_weights_' + str(i) + '.hdf5')\n",
        "\n",
        "  #Predict and print report\n",
        "  print('Best Model: ' + str(i) + ' for Relu SGD')\n",
        "  pred = model.predict(x_test)\n",
        "  pred = np.argmax(pred, axis=1)\n",
        "  print('F1 Score: ' + str(f1_score(np.argmax(y_test, axis=1), pred, average='micro')))\n",
        "  i += 1\n",
        "\n",
        "#Training complete!\n",
        "print('Training finished...')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 2.3241 - accuracy: 0.1004 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3030 - accuracy: 0.1019 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3031 - accuracy: 0.1005 - val_loss: 2.3019 - val_accuracy: 0.1000\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.1003 - accuracy: 0.2130 - val_loss: 1.7435 - val_accuracy: 0.3788\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.7613 - accuracy: 0.3658 - val_loss: 1.5900 - val_accuracy: 0.4307\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6367 - accuracy: 0.4077 - val_loss: 1.5085 - val_accuracy: 0.4541\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5544 - accuracy: 0.4358 - val_loss: 1.4400 - val_accuracy: 0.4826\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.4831 - accuracy: 0.4647 - val_loss: 1.3799 - val_accuracy: 0.5045\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.4452 - accuracy: 0.4828 - val_loss: 1.3500 - val_accuracy: 0.5135\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.4050 - accuracy: 0.4922 - val_loss: 1.3399 - val_accuracy: 0.5163\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3722 - accuracy: 0.5061 - val_loss: 1.3026 - val_accuracy: 0.5283\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3507 - accuracy: 0.5134 - val_loss: 1.2634 - val_accuracy: 0.5473\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3232 - accuracy: 0.5231 - val_loss: 1.2368 - val_accuracy: 0.5557\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2930 - accuracy: 0.5360 - val_loss: 1.2135 - val_accuracy: 0.5614\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2719 - accuracy: 0.5426 - val_loss: 1.1984 - val_accuracy: 0.5681\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2368 - accuracy: 0.5573 - val_loss: 1.1690 - val_accuracy: 0.5820\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2286 - accuracy: 0.5602 - val_loss: 1.1654 - val_accuracy: 0.5811\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2058 - accuracy: 0.5731 - val_loss: 1.1506 - val_accuracy: 0.5891\n",
            "Epoch 19/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1791 - accuracy: 0.5770 - val_loss: 1.1627 - val_accuracy: 0.5871\n",
            "Epoch 20/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1637 - accuracy: 0.5825 - val_loss: 1.1360 - val_accuracy: 0.5971\n",
            "Epoch 21/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1503 - accuracy: 0.5842 - val_loss: 1.1098 - val_accuracy: 0.6071\n",
            "Epoch 22/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1322 - accuracy: 0.5958 - val_loss: 1.1033 - val_accuracy: 0.6067\n",
            "Epoch 23/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1207 - accuracy: 0.6025 - val_loss: 1.0896 - val_accuracy: 0.6110\n",
            "Epoch 24/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1032 - accuracy: 0.6098 - val_loss: 1.0794 - val_accuracy: 0.6180\n",
            "Epoch 25/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0848 - accuracy: 0.6157 - val_loss: 1.0784 - val_accuracy: 0.6209\n",
            "Epoch 26/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0835 - accuracy: 0.6115 - val_loss: 1.0551 - val_accuracy: 0.6243\n",
            "Epoch 27/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0603 - accuracy: 0.6244 - val_loss: 1.0566 - val_accuracy: 0.6296\n",
            "Epoch 28/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0687 - accuracy: 0.6193 - val_loss: 1.0364 - val_accuracy: 0.6354\n",
            "Epoch 29/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0452 - accuracy: 0.6319 - val_loss: 1.0456 - val_accuracy: 0.6281\n",
            "Epoch 30/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0336 - accuracy: 0.6352 - val_loss: 1.0307 - val_accuracy: 0.6387\n",
            "Epoch 31/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0155 - accuracy: 0.6397 - val_loss: 1.0214 - val_accuracy: 0.6401\n",
            "Epoch 32/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0188 - accuracy: 0.6339 - val_loss: 1.0076 - val_accuracy: 0.6476\n",
            "Epoch 33/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9956 - accuracy: 0.6468 - val_loss: 1.0042 - val_accuracy: 0.6498\n",
            "Epoch 34/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9973 - accuracy: 0.6453 - val_loss: 1.0023 - val_accuracy: 0.6466\n",
            "Epoch 35/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9797 - accuracy: 0.6511 - val_loss: 0.9976 - val_accuracy: 0.6537\n",
            "Epoch 36/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9659 - accuracy: 0.6589 - val_loss: 1.0168 - val_accuracy: 0.6420\n",
            "Epoch 37/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9688 - accuracy: 0.6539 - val_loss: 0.9995 - val_accuracy: 0.6491\n",
            "Epoch 38/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9603 - accuracy: 0.6600 - val_loss: 0.9928 - val_accuracy: 0.6500\n",
            "Epoch 39/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9613 - accuracy: 0.6535 - val_loss: 0.9880 - val_accuracy: 0.6491\n",
            "Epoch 40/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9316 - accuracy: 0.6685 - val_loss: 0.9850 - val_accuracy: 0.6497\n",
            "Epoch 41/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9279 - accuracy: 0.6721 - val_loss: 0.9717 - val_accuracy: 0.6623\n",
            "Epoch 42/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9277 - accuracy: 0.6654 - val_loss: 0.9552 - val_accuracy: 0.6634\n",
            "Epoch 43/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9277 - accuracy: 0.6706 - val_loss: 0.9731 - val_accuracy: 0.6533\n",
            "Epoch 44/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9116 - accuracy: 0.6762 - val_loss: 0.9639 - val_accuracy: 0.6648\n",
            "Epoch 45/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9117 - accuracy: 0.6733 - val_loss: 0.9505 - val_accuracy: 0.6696\n",
            "Epoch 46/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9156 - accuracy: 0.6724 - val_loss: 0.9709 - val_accuracy: 0.6602\n",
            "Epoch 47/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8822 - accuracy: 0.6817 - val_loss: 0.9592 - val_accuracy: 0.6658\n",
            "Epoch 48/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8844 - accuracy: 0.6845 - val_loss: 0.9440 - val_accuracy: 0.6709\n",
            "Epoch 49/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8804 - accuracy: 0.6852 - val_loss: 0.9585 - val_accuracy: 0.6609\n",
            "Epoch 50/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8722 - accuracy: 0.6859 - val_loss: 0.9456 - val_accuracy: 0.6744\n",
            "Epoch 51/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8726 - accuracy: 0.6889 - val_loss: 0.9473 - val_accuracy: 0.6698\n",
            "Epoch 52/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8597 - accuracy: 0.6924 - val_loss: 0.9371 - val_accuracy: 0.6719\n",
            "Epoch 53/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8704 - accuracy: 0.6897 - val_loss: 0.9217 - val_accuracy: 0.6813\n",
            "Epoch 54/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8466 - accuracy: 0.6988 - val_loss: 0.9297 - val_accuracy: 0.6783\n",
            "Epoch 55/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8440 - accuracy: 0.6987 - val_loss: 0.9204 - val_accuracy: 0.6824\n",
            "Epoch 56/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8392 - accuracy: 0.7005 - val_loss: 0.9098 - val_accuracy: 0.6855\n",
            "Epoch 57/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8352 - accuracy: 0.7000 - val_loss: 0.9061 - val_accuracy: 0.6885\n",
            "Epoch 58/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8234 - accuracy: 0.7042 - val_loss: 0.9084 - val_accuracy: 0.6871\n",
            "Epoch 59/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8243 - accuracy: 0.7041 - val_loss: 0.8920 - val_accuracy: 0.6928\n",
            "Epoch 60/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8216 - accuracy: 0.7061 - val_loss: 0.9198 - val_accuracy: 0.6827\n",
            "Epoch 61/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8160 - accuracy: 0.7087 - val_loss: 0.9098 - val_accuracy: 0.6830\n",
            "Epoch 62/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8196 - accuracy: 0.7052 - val_loss: 0.9023 - val_accuracy: 0.6902\n",
            "Epoch 63/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8128 - accuracy: 0.7082 - val_loss: 0.9024 - val_accuracy: 0.6923\n",
            "Epoch 00063: early stopping\n",
            "F1 Score: 0.6923\n",
            "\n",
            "Recreating Sig Adam Model: 2\n",
            "Training version: 1\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 2.3314 - accuracy: 0.0993 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.2524 - accuracy: 0.1312 - val_loss: 1.8711 - val_accuracy: 0.3282\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.8097 - accuracy: 0.3390 - val_loss: 1.6061 - val_accuracy: 0.4239\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6523 - accuracy: 0.3993 - val_loss: 1.5054 - val_accuracy: 0.4566\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5733 - accuracy: 0.4351 - val_loss: 1.4635 - val_accuracy: 0.4751\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5252 - accuracy: 0.4528 - val_loss: 1.4125 - val_accuracy: 0.4876\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.4755 - accuracy: 0.4685 - val_loss: 1.3710 - val_accuracy: 0.5061\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.4359 - accuracy: 0.4865 - val_loss: 1.3441 - val_accuracy: 0.5165\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.4001 - accuracy: 0.4979 - val_loss: 1.3231 - val_accuracy: 0.5254\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3720 - accuracy: 0.5061 - val_loss: 1.2913 - val_accuracy: 0.5391\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3445 - accuracy: 0.5195 - val_loss: 1.2747 - val_accuracy: 0.5431\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3298 - accuracy: 0.5259 - val_loss: 1.2616 - val_accuracy: 0.5471\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2999 - accuracy: 0.5312 - val_loss: 1.2391 - val_accuracy: 0.5535\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2786 - accuracy: 0.5420 - val_loss: 1.2148 - val_accuracy: 0.5679\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2642 - accuracy: 0.5486 - val_loss: 1.1976 - val_accuracy: 0.5730\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2392 - accuracy: 0.5562 - val_loss: 1.1948 - val_accuracy: 0.5669\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2276 - accuracy: 0.5607 - val_loss: 1.1720 - val_accuracy: 0.5790\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2035 - accuracy: 0.5666 - val_loss: 1.1675 - val_accuracy: 0.5818\n",
            "Epoch 19/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1883 - accuracy: 0.5745 - val_loss: 1.1567 - val_accuracy: 0.5932\n",
            "Epoch 20/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1719 - accuracy: 0.5805 - val_loss: 1.1405 - val_accuracy: 0.5974\n",
            "Epoch 21/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1651 - accuracy: 0.5868 - val_loss: 1.1300 - val_accuracy: 0.5977\n",
            "Epoch 22/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1433 - accuracy: 0.5923 - val_loss: 1.1096 - val_accuracy: 0.6055\n",
            "Epoch 23/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1371 - accuracy: 0.5950 - val_loss: 1.1139 - val_accuracy: 0.6086\n",
            "Epoch 24/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1176 - accuracy: 0.6018 - val_loss: 1.0918 - val_accuracy: 0.6134\n",
            "Epoch 25/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1046 - accuracy: 0.6076 - val_loss: 1.0833 - val_accuracy: 0.6183\n",
            "Epoch 26/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1007 - accuracy: 0.6093 - val_loss: 1.0659 - val_accuracy: 0.6216\n",
            "Epoch 27/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0962 - accuracy: 0.6101 - val_loss: 1.0703 - val_accuracy: 0.6201\n",
            "Epoch 28/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0774 - accuracy: 0.6142 - val_loss: 1.0640 - val_accuracy: 0.6230\n",
            "Epoch 29/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0669 - accuracy: 0.6187 - val_loss: 1.0647 - val_accuracy: 0.6247\n",
            "Epoch 30/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0588 - accuracy: 0.6215 - val_loss: 1.0602 - val_accuracy: 0.6252\n",
            "Epoch 31/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0371 - accuracy: 0.6308 - val_loss: 1.0553 - val_accuracy: 0.6264\n",
            "Epoch 32/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0453 - accuracy: 0.6278 - val_loss: 1.0408 - val_accuracy: 0.6288\n",
            "Epoch 33/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0304 - accuracy: 0.6326 - val_loss: 1.0263 - val_accuracy: 0.6403\n",
            "Epoch 34/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0177 - accuracy: 0.6367 - val_loss: 1.0365 - val_accuracy: 0.6371\n",
            "Epoch 35/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0076 - accuracy: 0.6387 - val_loss: 1.0217 - val_accuracy: 0.6380\n",
            "Epoch 36/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9866 - accuracy: 0.6496 - val_loss: 1.0162 - val_accuracy: 0.6459\n",
            "Epoch 37/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9841 - accuracy: 0.6505 - val_loss: 1.0109 - val_accuracy: 0.6482\n",
            "Epoch 38/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9780 - accuracy: 0.6489 - val_loss: 1.0032 - val_accuracy: 0.6440\n",
            "Epoch 39/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9720 - accuracy: 0.6530 - val_loss: 0.9999 - val_accuracy: 0.6519\n",
            "Epoch 40/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9612 - accuracy: 0.6569 - val_loss: 1.0088 - val_accuracy: 0.6450\n",
            "Epoch 41/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9558 - accuracy: 0.6605 - val_loss: 1.0084 - val_accuracy: 0.6458\n",
            "Epoch 42/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9509 - accuracy: 0.6596 - val_loss: 0.9886 - val_accuracy: 0.6547\n",
            "Epoch 43/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9425 - accuracy: 0.6626 - val_loss: 0.9749 - val_accuracy: 0.6603\n",
            "Epoch 44/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9375 - accuracy: 0.6675 - val_loss: 0.9804 - val_accuracy: 0.6580\n",
            "Epoch 45/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9376 - accuracy: 0.6667 - val_loss: 0.9760 - val_accuracy: 0.6598\n",
            "Epoch 46/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9191 - accuracy: 0.6734 - val_loss: 0.9700 - val_accuracy: 0.6645\n",
            "Epoch 47/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9252 - accuracy: 0.6697 - val_loss: 0.9540 - val_accuracy: 0.6689\n",
            "Epoch 48/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9104 - accuracy: 0.6729 - val_loss: 0.9755 - val_accuracy: 0.6632\n",
            "Epoch 49/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9109 - accuracy: 0.6766 - val_loss: 0.9645 - val_accuracy: 0.6698\n",
            "Epoch 50/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9082 - accuracy: 0.6731 - val_loss: 0.9494 - val_accuracy: 0.6706\n",
            "Epoch 51/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9134 - accuracy: 0.6712 - val_loss: 0.9526 - val_accuracy: 0.6698\n",
            "Epoch 52/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8909 - accuracy: 0.6847 - val_loss: 0.9504 - val_accuracy: 0.6658\n",
            "Epoch 53/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8912 - accuracy: 0.6841 - val_loss: 0.9490 - val_accuracy: 0.6726\n",
            "Epoch 54/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8882 - accuracy: 0.6799 - val_loss: 0.9594 - val_accuracy: 0.6666\n",
            "Epoch 55/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8851 - accuracy: 0.6857 - val_loss: 0.9403 - val_accuracy: 0.6722\n",
            "Epoch 56/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8657 - accuracy: 0.6919 - val_loss: 0.9341 - val_accuracy: 0.6782\n",
            "Epoch 57/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8718 - accuracy: 0.6933 - val_loss: 0.9293 - val_accuracy: 0.6804\n",
            "Epoch 58/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8546 - accuracy: 0.6999 - val_loss: 0.9296 - val_accuracy: 0.6731\n",
            "Epoch 59/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8520 - accuracy: 0.6963 - val_loss: 0.9187 - val_accuracy: 0.6774\n",
            "Epoch 60/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8544 - accuracy: 0.6960 - val_loss: 0.9163 - val_accuracy: 0.6812\n",
            "Epoch 61/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8424 - accuracy: 0.7002 - val_loss: 0.9129 - val_accuracy: 0.6839\n",
            "Epoch 62/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8546 - accuracy: 0.6952 - val_loss: 0.9343 - val_accuracy: 0.6754\n",
            "Epoch 63/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8441 - accuracy: 0.7013 - val_loss: 0.9150 - val_accuracy: 0.6882\n",
            "Epoch 64/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8320 - accuracy: 0.7015 - val_loss: 0.9087 - val_accuracy: 0.6868\n",
            "Epoch 65/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8272 - accuracy: 0.7031 - val_loss: 0.9135 - val_accuracy: 0.6829\n",
            "Epoch 66/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8239 - accuracy: 0.7062 - val_loss: 0.8985 - val_accuracy: 0.6884\n",
            "Epoch 67/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8245 - accuracy: 0.7067 - val_loss: 0.9153 - val_accuracy: 0.6804\n",
            "Epoch 68/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8196 - accuracy: 0.7088 - val_loss: 0.8929 - val_accuracy: 0.6909\n",
            "Epoch 69/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8145 - accuracy: 0.7076 - val_loss: 0.8982 - val_accuracy: 0.6915\n",
            "Epoch 70/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8099 - accuracy: 0.7111 - val_loss: 0.9070 - val_accuracy: 0.6840\n",
            "Epoch 71/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8121 - accuracy: 0.7114 - val_loss: 0.9042 - val_accuracy: 0.6889\n",
            "Epoch 72/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8048 - accuracy: 0.7128 - val_loss: 0.9011 - val_accuracy: 0.6882\n",
            "Epoch 00072: early stopping\n",
            "F1 Score: 0.6882\n",
            "\n",
            "Recreating Sig Adam Model: 2\n",
            "Training version: 2\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 2.3279 - accuracy: 0.0971 - val_loss: 2.3023 - val_accuracy: 0.1068\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.0879 - accuracy: 0.2138 - val_loss: 1.7327 - val_accuracy: 0.3706\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.7476 - accuracy: 0.3620 - val_loss: 1.5591 - val_accuracy: 0.4359\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6313 - accuracy: 0.4090 - val_loss: 1.5063 - val_accuracy: 0.4591\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5476 - accuracy: 0.4447 - val_loss: 1.4503 - val_accuracy: 0.4762\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5052 - accuracy: 0.4603 - val_loss: 1.4057 - val_accuracy: 0.4933\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.4603 - accuracy: 0.4734 - val_loss: 1.3515 - val_accuracy: 0.5112\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.4175 - accuracy: 0.4890 - val_loss: 1.3314 - val_accuracy: 0.5251\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3902 - accuracy: 0.5018 - val_loss: 1.3073 - val_accuracy: 0.5322\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3635 - accuracy: 0.5125 - val_loss: 1.2863 - val_accuracy: 0.5395\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3373 - accuracy: 0.5210 - val_loss: 1.2545 - val_accuracy: 0.5525\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3038 - accuracy: 0.5311 - val_loss: 1.2407 - val_accuracy: 0.5528\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2924 - accuracy: 0.5368 - val_loss: 1.2181 - val_accuracy: 0.5647\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2639 - accuracy: 0.5501 - val_loss: 1.2036 - val_accuracy: 0.5760\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2413 - accuracy: 0.5577 - val_loss: 1.1956 - val_accuracy: 0.5767\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2221 - accuracy: 0.5647 - val_loss: 1.1630 - val_accuracy: 0.5875\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2002 - accuracy: 0.5694 - val_loss: 1.1466 - val_accuracy: 0.5935\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1906 - accuracy: 0.5725 - val_loss: 1.1496 - val_accuracy: 0.5919\n",
            "Epoch 19/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1771 - accuracy: 0.5785 - val_loss: 1.1512 - val_accuracy: 0.5921\n",
            "Epoch 20/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1562 - accuracy: 0.5870 - val_loss: 1.1325 - val_accuracy: 0.5989\n",
            "Epoch 21/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1420 - accuracy: 0.5902 - val_loss: 1.1165 - val_accuracy: 0.6016\n",
            "Epoch 22/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1271 - accuracy: 0.5965 - val_loss: 1.1035 - val_accuracy: 0.6100\n",
            "Epoch 23/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0976 - accuracy: 0.6052 - val_loss: 1.0944 - val_accuracy: 0.6124\n",
            "Epoch 24/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0933 - accuracy: 0.6115 - val_loss: 1.0863 - val_accuracy: 0.6136\n",
            "Epoch 25/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0936 - accuracy: 0.6118 - val_loss: 1.0693 - val_accuracy: 0.6229\n",
            "Epoch 26/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0705 - accuracy: 0.6154 - val_loss: 1.0854 - val_accuracy: 0.6160\n",
            "Epoch 27/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0658 - accuracy: 0.6199 - val_loss: 1.0669 - val_accuracy: 0.6245\n",
            "Epoch 28/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0564 - accuracy: 0.6241 - val_loss: 1.0457 - val_accuracy: 0.6343\n",
            "Epoch 29/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0328 - accuracy: 0.6344 - val_loss: 1.0455 - val_accuracy: 0.6353\n",
            "Epoch 30/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0290 - accuracy: 0.6352 - val_loss: 1.0368 - val_accuracy: 0.6373\n",
            "Epoch 31/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0202 - accuracy: 0.6372 - val_loss: 1.0331 - val_accuracy: 0.6390\n",
            "Epoch 32/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0138 - accuracy: 0.6390 - val_loss: 1.0279 - val_accuracy: 0.6399\n",
            "Epoch 33/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0152 - accuracy: 0.6374 - val_loss: 1.0274 - val_accuracy: 0.6406\n",
            "Epoch 34/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0034 - accuracy: 0.6397 - val_loss: 1.0046 - val_accuracy: 0.6502\n",
            "Epoch 35/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9834 - accuracy: 0.6502 - val_loss: 1.0154 - val_accuracy: 0.6458\n",
            "Epoch 36/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9811 - accuracy: 0.6489 - val_loss: 1.0090 - val_accuracy: 0.6424\n",
            "Epoch 37/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9718 - accuracy: 0.6565 - val_loss: 1.0050 - val_accuracy: 0.6520\n",
            "Epoch 38/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9721 - accuracy: 0.6572 - val_loss: 0.9922 - val_accuracy: 0.6545\n",
            "Epoch 39/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9531 - accuracy: 0.6611 - val_loss: 0.9936 - val_accuracy: 0.6499\n",
            "Epoch 40/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9522 - accuracy: 0.6633 - val_loss: 0.9904 - val_accuracy: 0.6510\n",
            "Epoch 41/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9453 - accuracy: 0.6642 - val_loss: 0.9924 - val_accuracy: 0.6573\n",
            "Epoch 42/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9428 - accuracy: 0.6623 - val_loss: 0.9824 - val_accuracy: 0.6569\n",
            "Epoch 43/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9323 - accuracy: 0.6704 - val_loss: 0.9766 - val_accuracy: 0.6538\n",
            "Epoch 44/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9228 - accuracy: 0.6695 - val_loss: 0.9794 - val_accuracy: 0.6617\n",
            "Epoch 45/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9177 - accuracy: 0.6745 - val_loss: 0.9735 - val_accuracy: 0.6651\n",
            "Epoch 46/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9067 - accuracy: 0.6760 - val_loss: 0.9715 - val_accuracy: 0.6621\n",
            "Epoch 47/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9075 - accuracy: 0.6780 - val_loss: 0.9598 - val_accuracy: 0.6637\n",
            "Epoch 48/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9020 - accuracy: 0.6778 - val_loss: 0.9665 - val_accuracy: 0.6639\n",
            "Epoch 49/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8937 - accuracy: 0.6799 - val_loss: 0.9537 - val_accuracy: 0.6665\n",
            "Epoch 50/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8888 - accuracy: 0.6864 - val_loss: 0.9642 - val_accuracy: 0.6658\n",
            "Epoch 51/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8776 - accuracy: 0.6877 - val_loss: 0.9526 - val_accuracy: 0.6639\n",
            "Epoch 52/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8747 - accuracy: 0.6928 - val_loss: 0.9407 - val_accuracy: 0.6717\n",
            "Epoch 53/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8831 - accuracy: 0.6908 - val_loss: 0.9395 - val_accuracy: 0.6710\n",
            "Epoch 54/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8742 - accuracy: 0.6873 - val_loss: 0.9384 - val_accuracy: 0.6714\n",
            "Epoch 55/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8625 - accuracy: 0.6936 - val_loss: 0.9450 - val_accuracy: 0.6704\n",
            "Epoch 56/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8597 - accuracy: 0.6933 - val_loss: 0.9506 - val_accuracy: 0.6626\n",
            "Epoch 57/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8566 - accuracy: 0.6939 - val_loss: 0.9440 - val_accuracy: 0.6692\n",
            "Epoch 58/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8584 - accuracy: 0.6936 - val_loss: 0.9308 - val_accuracy: 0.6768\n",
            "Epoch 59/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8448 - accuracy: 0.6983 - val_loss: 0.9348 - val_accuracy: 0.6743\n",
            "Epoch 60/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8435 - accuracy: 0.7016 - val_loss: 0.9373 - val_accuracy: 0.6729\n",
            "Epoch 61/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8352 - accuracy: 0.7044 - val_loss: 0.9267 - val_accuracy: 0.6799\n",
            "Epoch 62/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8369 - accuracy: 0.7031 - val_loss: 0.9254 - val_accuracy: 0.6755\n",
            "Epoch 63/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8375 - accuracy: 0.6989 - val_loss: 0.9157 - val_accuracy: 0.6798\n",
            "Epoch 64/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8174 - accuracy: 0.7080 - val_loss: 0.9210 - val_accuracy: 0.6779\n",
            "Epoch 65/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8178 - accuracy: 0.7077 - val_loss: 0.9203 - val_accuracy: 0.6826\n",
            "Epoch 66/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8169 - accuracy: 0.7081 - val_loss: 0.9175 - val_accuracy: 0.6839\n",
            "Epoch 67/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8109 - accuracy: 0.7077 - val_loss: 0.9133 - val_accuracy: 0.6823\n",
            "Epoch 68/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8101 - accuracy: 0.7098 - val_loss: 0.9246 - val_accuracy: 0.6738\n",
            "Epoch 69/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7936 - accuracy: 0.7189 - val_loss: 0.9102 - val_accuracy: 0.6815\n",
            "Epoch 70/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7976 - accuracy: 0.7141 - val_loss: 0.9122 - val_accuracy: 0.6860\n",
            "Epoch 71/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7924 - accuracy: 0.7167 - val_loss: 0.8964 - val_accuracy: 0.6877\n",
            "Epoch 72/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7859 - accuracy: 0.7201 - val_loss: 0.9215 - val_accuracy: 0.6810\n",
            "Epoch 73/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7910 - accuracy: 0.7200 - val_loss: 0.8965 - val_accuracy: 0.6883\n",
            "Epoch 74/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7820 - accuracy: 0.7220 - val_loss: 0.9092 - val_accuracy: 0.6868\n",
            "Epoch 75/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7846 - accuracy: 0.7229 - val_loss: 0.8960 - val_accuracy: 0.6866\n",
            "Epoch 76/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7670 - accuracy: 0.7258 - val_loss: 0.9293 - val_accuracy: 0.6774\n",
            "Epoch 77/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7788 - accuracy: 0.7198 - val_loss: 0.8869 - val_accuracy: 0.6935\n",
            "Epoch 78/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7765 - accuracy: 0.7219 - val_loss: 0.9017 - val_accuracy: 0.6870\n",
            "Epoch 79/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7703 - accuracy: 0.7240 - val_loss: 0.9090 - val_accuracy: 0.6838\n",
            "Epoch 80/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7695 - accuracy: 0.7225 - val_loss: 0.9122 - val_accuracy: 0.6862\n",
            "Epoch 81/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7712 - accuracy: 0.7263 - val_loss: 0.8891 - val_accuracy: 0.6959\n",
            "Epoch 00081: early stopping\n",
            "F1 Score: 0.6959\n",
            "\n",
            "Recreating Sig Adam Model: 2\n",
            "Best Model: 2 for Sig Adam\n",
            "F1 Score: 0.6935\n",
            "Training model: 3 for Sig Adam\n",
            "Training version: 0\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 2.1316 - accuracy: 0.3168 - val_loss: 1.5253 - val_accuracy: 0.5069\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3171 - accuracy: 0.5330 - val_loss: 1.2308 - val_accuracy: 0.5744\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1675 - accuracy: 0.5956 - val_loss: 1.3702 - val_accuracy: 0.5375\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0840 - accuracy: 0.6261 - val_loss: 1.0396 - val_accuracy: 0.6404\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0184 - accuracy: 0.6510 - val_loss: 0.9292 - val_accuracy: 0.6799\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.9762 - accuracy: 0.6651 - val_loss: 0.9848 - val_accuracy: 0.6666\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.9368 - accuracy: 0.6805 - val_loss: 0.8865 - val_accuracy: 0.6968\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.9127 - accuracy: 0.6884 - val_loss: 0.8450 - val_accuracy: 0.7112\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8907 - accuracy: 0.6968 - val_loss: 0.9083 - val_accuracy: 0.6946\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8658 - accuracy: 0.7033 - val_loss: 0.8575 - val_accuracy: 0.7063\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8539 - accuracy: 0.7081 - val_loss: 0.9455 - val_accuracy: 0.6830\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8549 - accuracy: 0.7120 - val_loss: 0.8780 - val_accuracy: 0.7051\n",
            "Epoch 00012: early stopping\n",
            "F1 Score: 0.7051\n",
            "\n",
            "Recreating Sig Adam Model: 3\n",
            "Training version: 1\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 2.0970 - accuracy: 0.3237 - val_loss: 1.3321 - val_accuracy: 0.5248\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3196 - accuracy: 0.5341 - val_loss: 1.2195 - val_accuracy: 0.5662\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1733 - accuracy: 0.5885 - val_loss: 1.0644 - val_accuracy: 0.6187\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0674 - accuracy: 0.6283 - val_loss: 0.9571 - val_accuracy: 0.6678\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0028 - accuracy: 0.6528 - val_loss: 1.0143 - val_accuracy: 0.6516\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.9612 - accuracy: 0.6686 - val_loss: 0.8984 - val_accuracy: 0.6875\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.9357 - accuracy: 0.6794 - val_loss: 0.9043 - val_accuracy: 0.6938\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.9040 - accuracy: 0.6864 - val_loss: 1.1459 - val_accuracy: 0.6176\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8987 - accuracy: 0.6939 - val_loss: 0.9781 - val_accuracy: 0.6734\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8799 - accuracy: 0.6996 - val_loss: 0.8736 - val_accuracy: 0.7023\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8596 - accuracy: 0.7072 - val_loss: 0.7898 - val_accuracy: 0.7315\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8471 - accuracy: 0.7111 - val_loss: 0.9417 - val_accuracy: 0.6935\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8422 - accuracy: 0.7107 - val_loss: 0.8550 - val_accuracy: 0.7155\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.8246 - accuracy: 0.7210 - val_loss: 0.8532 - val_accuracy: 0.7165\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8176 - accuracy: 0.7229 - val_loss: 0.8738 - val_accuracy: 0.7132\n",
            "Epoch 00015: early stopping\n",
            "F1 Score: 0.7132\n",
            "\n",
            "Recreating Sig Adam Model: 3\n",
            "Training version: 2\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 2.1122 - accuracy: 0.3102 - val_loss: 1.6937 - val_accuracy: 0.4181\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3369 - accuracy: 0.5249 - val_loss: 1.4183 - val_accuracy: 0.5257\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1780 - accuracy: 0.5887 - val_loss: 1.2521 - val_accuracy: 0.5767\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0848 - accuracy: 0.6225 - val_loss: 1.2707 - val_accuracy: 0.5624\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0150 - accuracy: 0.6508 - val_loss: 1.1160 - val_accuracy: 0.6135\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.9697 - accuracy: 0.6647 - val_loss: 0.9837 - val_accuracy: 0.6648\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.9437 - accuracy: 0.6762 - val_loss: 0.8657 - val_accuracy: 0.7042\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.9168 - accuracy: 0.6854 - val_loss: 0.8723 - val_accuracy: 0.7011\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8952 - accuracy: 0.6926 - val_loss: 0.8254 - val_accuracy: 0.7195\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8833 - accuracy: 0.7008 - val_loss: 0.9930 - val_accuracy: 0.6715\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8574 - accuracy: 0.7067 - val_loss: 0.8878 - val_accuracy: 0.6967\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8480 - accuracy: 0.7131 - val_loss: 0.8115 - val_accuracy: 0.7237\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8268 - accuracy: 0.7174 - val_loss: 0.7971 - val_accuracy: 0.7353\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8198 - accuracy: 0.7174 - val_loss: 0.7834 - val_accuracy: 0.7347\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8064 - accuracy: 0.7255 - val_loss: 0.8009 - val_accuracy: 0.7323\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8012 - accuracy: 0.7305 - val_loss: 0.9445 - val_accuracy: 0.6945\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7943 - accuracy: 0.7296 - val_loss: 0.9361 - val_accuracy: 0.6937\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8026 - accuracy: 0.7302 - val_loss: 0.8757 - val_accuracy: 0.7080\n",
            "Epoch 00018: early stopping\n",
            "F1 Score: 0.708\n",
            "\n",
            "Recreating Sig Adam Model: 3\n",
            "Best Model: 3 for Sig Adam\n",
            "F1 Score: 0.7347\n",
            "Training model: 4 for Sig Adam\n",
            "Training version: 0\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3198 - accuracy: 0.1028 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3028 - accuracy: 0.0995 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3028 - accuracy: 0.0981 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.2129 - accuracy: 0.1463 - val_loss: 1.8571 - val_accuracy: 0.3141\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.8829 - accuracy: 0.2984 - val_loss: 1.6903 - val_accuracy: 0.3835\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.7451 - accuracy: 0.3535 - val_loss: 1.5952 - val_accuracy: 0.4130\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6620 - accuracy: 0.3908 - val_loss: 1.5631 - val_accuracy: 0.4287\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6144 - accuracy: 0.4114 - val_loss: 1.5052 - val_accuracy: 0.4501\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5808 - accuracy: 0.4204 - val_loss: 1.4751 - val_accuracy: 0.4580\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5483 - accuracy: 0.4356 - val_loss: 1.4445 - val_accuracy: 0.4723\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5184 - accuracy: 0.4494 - val_loss: 1.4278 - val_accuracy: 0.4825\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.4957 - accuracy: 0.4550 - val_loss: 1.3789 - val_accuracy: 0.5003\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.4598 - accuracy: 0.4724 - val_loss: 1.3637 - val_accuracy: 0.5047\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.4393 - accuracy: 0.4781 - val_loss: 1.3341 - val_accuracy: 0.5173\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.4068 - accuracy: 0.4912 - val_loss: 1.3035 - val_accuracy: 0.5297\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3918 - accuracy: 0.4968 - val_loss: 1.3151 - val_accuracy: 0.5233\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3689 - accuracy: 0.5046 - val_loss: 1.2750 - val_accuracy: 0.5403\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3451 - accuracy: 0.5153 - val_loss: 1.2520 - val_accuracy: 0.5527\n",
            "Epoch 19/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3263 - accuracy: 0.5246 - val_loss: 1.2360 - val_accuracy: 0.5550\n",
            "Epoch 20/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3045 - accuracy: 0.5316 - val_loss: 1.2252 - val_accuracy: 0.5593\n",
            "Epoch 21/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2735 - accuracy: 0.5416 - val_loss: 1.2341 - val_accuracy: 0.5576\n",
            "Epoch 22/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2649 - accuracy: 0.5450 - val_loss: 1.1947 - val_accuracy: 0.5795\n",
            "Epoch 23/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2463 - accuracy: 0.5571 - val_loss: 1.1834 - val_accuracy: 0.5792\n",
            "Epoch 24/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2295 - accuracy: 0.5604 - val_loss: 1.1872 - val_accuracy: 0.5752\n",
            "Epoch 25/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2142 - accuracy: 0.5682 - val_loss: 1.1671 - val_accuracy: 0.5866\n",
            "Epoch 26/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1981 - accuracy: 0.5729 - val_loss: 1.1411 - val_accuracy: 0.5996\n",
            "Epoch 27/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1876 - accuracy: 0.5773 - val_loss: 1.1162 - val_accuracy: 0.6058\n",
            "Epoch 28/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1685 - accuracy: 0.5842 - val_loss: 1.1102 - val_accuracy: 0.6054\n",
            "Epoch 29/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1572 - accuracy: 0.5862 - val_loss: 1.1175 - val_accuracy: 0.6075\n",
            "Epoch 30/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1427 - accuracy: 0.5954 - val_loss: 1.1053 - val_accuracy: 0.6015\n",
            "Epoch 31/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1414 - accuracy: 0.5942 - val_loss: 1.1105 - val_accuracy: 0.6014\n",
            "Epoch 32/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1165 - accuracy: 0.6055 - val_loss: 1.0932 - val_accuracy: 0.6118\n",
            "Epoch 33/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1110 - accuracy: 0.6082 - val_loss: 1.0719 - val_accuracy: 0.6237\n",
            "Epoch 34/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0907 - accuracy: 0.6093 - val_loss: 1.0644 - val_accuracy: 0.6264\n",
            "Epoch 35/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0826 - accuracy: 0.6124 - val_loss: 1.0784 - val_accuracy: 0.6208\n",
            "Epoch 36/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0726 - accuracy: 0.6196 - val_loss: 1.0637 - val_accuracy: 0.6234\n",
            "Epoch 37/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0694 - accuracy: 0.6206 - val_loss: 1.0654 - val_accuracy: 0.6219\n",
            "Epoch 38/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0488 - accuracy: 0.6221 - val_loss: 1.0424 - val_accuracy: 0.6342\n",
            "Epoch 39/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0328 - accuracy: 0.6347 - val_loss: 1.0686 - val_accuracy: 0.6218\n",
            "Epoch 40/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0301 - accuracy: 0.6317 - val_loss: 1.0343 - val_accuracy: 0.6338\n",
            "Epoch 41/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0184 - accuracy: 0.6377 - val_loss: 1.0849 - val_accuracy: 0.6181\n",
            "Epoch 42/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0191 - accuracy: 0.6405 - val_loss: 1.0308 - val_accuracy: 0.6375\n",
            "Epoch 43/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0061 - accuracy: 0.6413 - val_loss: 1.0204 - val_accuracy: 0.6385\n",
            "Epoch 44/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9908 - accuracy: 0.6472 - val_loss: 1.0178 - val_accuracy: 0.6440\n",
            "Epoch 45/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9953 - accuracy: 0.6452 - val_loss: 1.0448 - val_accuracy: 0.6322\n",
            "Epoch 46/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9872 - accuracy: 0.6523 - val_loss: 1.0063 - val_accuracy: 0.6501\n",
            "Epoch 47/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9693 - accuracy: 0.6567 - val_loss: 1.0068 - val_accuracy: 0.6492\n",
            "Epoch 48/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9707 - accuracy: 0.6534 - val_loss: 1.0206 - val_accuracy: 0.6407\n",
            "Epoch 49/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9557 - accuracy: 0.6618 - val_loss: 1.0163 - val_accuracy: 0.6450\n",
            "Epoch 50/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9497 - accuracy: 0.6618 - val_loss: 1.0628 - val_accuracy: 0.6355\n",
            "Epoch 00050: early stopping\n",
            "F1 Score: 0.6355\n",
            "\n",
            "Recreating Sig Adam Model: 4\n",
            "Training version: 1\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3234 - accuracy: 0.0969 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3005 - accuracy: 0.1005 - val_loss: 2.0375 - val_accuracy: 0.2324\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.0135 - accuracy: 0.2377 - val_loss: 1.8029 - val_accuracy: 0.3381\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.8156 - accuracy: 0.3272 - val_loss: 1.6699 - val_accuracy: 0.3884\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.7122 - accuracy: 0.3718 - val_loss: 1.6100 - val_accuracy: 0.4150\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6444 - accuracy: 0.3936 - val_loss: 1.5388 - val_accuracy: 0.4383\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5896 - accuracy: 0.4200 - val_loss: 1.5067 - val_accuracy: 0.4473\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5678 - accuracy: 0.4266 - val_loss: 1.4632 - val_accuracy: 0.4659\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5343 - accuracy: 0.4426 - val_loss: 1.4214 - val_accuracy: 0.4773\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5014 - accuracy: 0.4521 - val_loss: 1.4058 - val_accuracy: 0.4868\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.4754 - accuracy: 0.4587 - val_loss: 1.4010 - val_accuracy: 0.4871\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.4430 - accuracy: 0.4757 - val_loss: 1.3497 - val_accuracy: 0.5072\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.4215 - accuracy: 0.4835 - val_loss: 1.3293 - val_accuracy: 0.5143\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.4011 - accuracy: 0.4944 - val_loss: 1.3124 - val_accuracy: 0.5210\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3782 - accuracy: 0.5016 - val_loss: 1.2858 - val_accuracy: 0.5350\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3569 - accuracy: 0.5139 - val_loss: 1.2767 - val_accuracy: 0.5450\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3336 - accuracy: 0.5222 - val_loss: 1.2544 - val_accuracy: 0.5491\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3123 - accuracy: 0.5257 - val_loss: 1.2861 - val_accuracy: 0.5374\n",
            "Epoch 19/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2955 - accuracy: 0.5355 - val_loss: 1.2052 - val_accuracy: 0.5653\n",
            "Epoch 20/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2704 - accuracy: 0.5453 - val_loss: 1.1924 - val_accuracy: 0.5805\n",
            "Epoch 21/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2614 - accuracy: 0.5452 - val_loss: 1.1741 - val_accuracy: 0.5751\n",
            "Epoch 22/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2422 - accuracy: 0.5573 - val_loss: 1.1740 - val_accuracy: 0.5780\n",
            "Epoch 23/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2274 - accuracy: 0.5583 - val_loss: 1.1551 - val_accuracy: 0.5939\n",
            "Epoch 24/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2122 - accuracy: 0.5725 - val_loss: 1.1482 - val_accuracy: 0.5889\n",
            "Epoch 25/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1977 - accuracy: 0.5738 - val_loss: 1.1320 - val_accuracy: 0.5990\n",
            "Epoch 26/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1747 - accuracy: 0.5833 - val_loss: 1.1250 - val_accuracy: 0.5971\n",
            "Epoch 27/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1628 - accuracy: 0.5870 - val_loss: 1.1116 - val_accuracy: 0.6010\n",
            "Epoch 28/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1521 - accuracy: 0.5910 - val_loss: 1.0999 - val_accuracy: 0.6080\n",
            "Epoch 29/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1430 - accuracy: 0.5977 - val_loss: 1.0972 - val_accuracy: 0.6104\n",
            "Epoch 30/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1292 - accuracy: 0.6003 - val_loss: 1.1435 - val_accuracy: 0.5953\n",
            "Epoch 31/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1155 - accuracy: 0.6048 - val_loss: 1.0783 - val_accuracy: 0.6122\n",
            "Epoch 32/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1007 - accuracy: 0.6093 - val_loss: 1.0742 - val_accuracy: 0.6204\n",
            "Epoch 33/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1125 - accuracy: 0.6055 - val_loss: 1.1218 - val_accuracy: 0.6109\n",
            "Epoch 34/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0756 - accuracy: 0.6193 - val_loss: 1.0599 - val_accuracy: 0.6265\n",
            "Epoch 35/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0603 - accuracy: 0.6240 - val_loss: 1.0406 - val_accuracy: 0.6317\n",
            "Epoch 36/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0631 - accuracy: 0.6231 - val_loss: 1.0492 - val_accuracy: 0.6251\n",
            "Epoch 37/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0608 - accuracy: 0.6263 - val_loss: 1.0570 - val_accuracy: 0.6277\n",
            "Epoch 38/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0483 - accuracy: 0.6281 - val_loss: 1.0408 - val_accuracy: 0.6343\n",
            "Epoch 39/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0295 - accuracy: 0.6318 - val_loss: 1.0255 - val_accuracy: 0.6375\n",
            "Epoch 40/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0208 - accuracy: 0.6382 - val_loss: 1.0359 - val_accuracy: 0.6355\n",
            "Epoch 41/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0173 - accuracy: 0.6397 - val_loss: 1.0468 - val_accuracy: 0.6319\n",
            "Epoch 42/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0059 - accuracy: 0.6446 - val_loss: 1.0386 - val_accuracy: 0.6336\n",
            "Epoch 43/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0107 - accuracy: 0.6452 - val_loss: 1.0191 - val_accuracy: 0.6418\n",
            "Epoch 44/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0010 - accuracy: 0.6469 - val_loss: 1.0782 - val_accuracy: 0.6260\n",
            "Epoch 45/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9819 - accuracy: 0.6528 - val_loss: 1.0089 - val_accuracy: 0.6522\n",
            "Epoch 46/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9835 - accuracy: 0.6525 - val_loss: 1.0106 - val_accuracy: 0.6488\n",
            "Epoch 47/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9661 - accuracy: 0.6570 - val_loss: 1.0079 - val_accuracy: 0.6471\n",
            "Epoch 48/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9715 - accuracy: 0.6583 - val_loss: 1.0484 - val_accuracy: 0.6437\n",
            "Epoch 49/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9559 - accuracy: 0.6574 - val_loss: 1.0240 - val_accuracy: 0.6437\n",
            "Epoch 50/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9452 - accuracy: 0.6656 - val_loss: 1.0361 - val_accuracy: 0.6420\n",
            "Epoch 51/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9434 - accuracy: 0.6618 - val_loss: 0.9992 - val_accuracy: 0.6563\n",
            "Epoch 52/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9446 - accuracy: 0.6677 - val_loss: 1.0065 - val_accuracy: 0.6542\n",
            "Epoch 53/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9267 - accuracy: 0.6678 - val_loss: 1.0290 - val_accuracy: 0.6398\n",
            "Epoch 54/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9180 - accuracy: 0.6694 - val_loss: 1.0347 - val_accuracy: 0.6433\n",
            "Epoch 55/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9093 - accuracy: 0.6756 - val_loss: 0.9950 - val_accuracy: 0.6526\n",
            "Epoch 56/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9058 - accuracy: 0.6762 - val_loss: 1.0052 - val_accuracy: 0.6448\n",
            "Epoch 57/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9044 - accuracy: 0.6790 - val_loss: 0.9964 - val_accuracy: 0.6587\n",
            "Epoch 58/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8923 - accuracy: 0.6836 - val_loss: 0.9818 - val_accuracy: 0.6589\n",
            "Epoch 59/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8910 - accuracy: 0.6818 - val_loss: 1.0106 - val_accuracy: 0.6575\n",
            "Epoch 60/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8871 - accuracy: 0.6883 - val_loss: 0.9800 - val_accuracy: 0.6592\n",
            "Epoch 61/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8723 - accuracy: 0.6907 - val_loss: 0.9942 - val_accuracy: 0.6560\n",
            "Epoch 62/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8877 - accuracy: 0.6844 - val_loss: 0.9752 - val_accuracy: 0.6704\n",
            "Epoch 63/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8687 - accuracy: 0.6875 - val_loss: 1.0184 - val_accuracy: 0.6527\n",
            "Epoch 64/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8697 - accuracy: 0.6835 - val_loss: 0.9705 - val_accuracy: 0.6701\n",
            "Epoch 65/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8563 - accuracy: 0.6940 - val_loss: 0.9767 - val_accuracy: 0.6657\n",
            "Epoch 66/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8517 - accuracy: 0.6983 - val_loss: 0.9911 - val_accuracy: 0.6614\n",
            "Epoch 67/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8597 - accuracy: 0.6908 - val_loss: 0.9951 - val_accuracy: 0.6684\n",
            "Epoch 68/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8446 - accuracy: 0.6966 - val_loss: 0.9975 - val_accuracy: 0.6618\n",
            "Epoch 00068: early stopping\n",
            "F1 Score: 0.6618\n",
            "\n",
            "Recreating Sig Adam Model: 4\n",
            "Training version: 2\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3213 - accuracy: 0.0987 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3029 - accuracy: 0.1001 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3018 - accuracy: 0.1044 - val_loss: 2.0428 - val_accuracy: 0.2205\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.0198 - accuracy: 0.2386 - val_loss: 1.7536 - val_accuracy: 0.3497\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.7840 - accuracy: 0.3425 - val_loss: 1.6230 - val_accuracy: 0.4021\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6801 - accuracy: 0.3804 - val_loss: 1.5808 - val_accuracy: 0.4271\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6282 - accuracy: 0.4056 - val_loss: 1.5066 - val_accuracy: 0.4500\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5798 - accuracy: 0.4216 - val_loss: 1.5377 - val_accuracy: 0.4478\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5597 - accuracy: 0.4324 - val_loss: 1.4546 - val_accuracy: 0.4720\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5215 - accuracy: 0.4444 - val_loss: 1.4269 - val_accuracy: 0.4824\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5018 - accuracy: 0.4532 - val_loss: 1.3847 - val_accuracy: 0.4949\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.4730 - accuracy: 0.4628 - val_loss: 1.3806 - val_accuracy: 0.5009\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.4453 - accuracy: 0.4734 - val_loss: 1.3472 - val_accuracy: 0.5109\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.4179 - accuracy: 0.4869 - val_loss: 1.3360 - val_accuracy: 0.5105\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3981 - accuracy: 0.4924 - val_loss: 1.3058 - val_accuracy: 0.5277\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3761 - accuracy: 0.5059 - val_loss: 1.2994 - val_accuracy: 0.5334\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3605 - accuracy: 0.5096 - val_loss: 1.2786 - val_accuracy: 0.5329\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3366 - accuracy: 0.5191 - val_loss: 1.2564 - val_accuracy: 0.5448\n",
            "Epoch 19/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3153 - accuracy: 0.5263 - val_loss: 1.2313 - val_accuracy: 0.5603\n",
            "Epoch 20/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2993 - accuracy: 0.5359 - val_loss: 1.2106 - val_accuracy: 0.5622\n",
            "Epoch 21/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2763 - accuracy: 0.5388 - val_loss: 1.1979 - val_accuracy: 0.5703\n",
            "Epoch 22/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2576 - accuracy: 0.5512 - val_loss: 1.1912 - val_accuracy: 0.5733\n",
            "Epoch 23/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2542 - accuracy: 0.5498 - val_loss: 1.1967 - val_accuracy: 0.5723\n",
            "Epoch 24/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2301 - accuracy: 0.5632 - val_loss: 1.1604 - val_accuracy: 0.5869\n",
            "Epoch 25/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2178 - accuracy: 0.5632 - val_loss: 1.1537 - val_accuracy: 0.5861\n",
            "Epoch 26/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2034 - accuracy: 0.5705 - val_loss: 1.1648 - val_accuracy: 0.5844\n",
            "Epoch 27/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1892 - accuracy: 0.5809 - val_loss: 1.1658 - val_accuracy: 0.5827\n",
            "Epoch 28/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1803 - accuracy: 0.5808 - val_loss: 1.1245 - val_accuracy: 0.6009\n",
            "Epoch 29/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1570 - accuracy: 0.5851 - val_loss: 1.1438 - val_accuracy: 0.5954\n",
            "Epoch 30/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1517 - accuracy: 0.5919 - val_loss: 1.1057 - val_accuracy: 0.6087\n",
            "Epoch 31/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1394 - accuracy: 0.5934 - val_loss: 1.0999 - val_accuracy: 0.6140\n",
            "Epoch 32/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1187 - accuracy: 0.6025 - val_loss: 1.0903 - val_accuracy: 0.6129\n",
            "Epoch 33/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1125 - accuracy: 0.6014 - val_loss: 1.0965 - val_accuracy: 0.6162\n",
            "Epoch 34/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1105 - accuracy: 0.6030 - val_loss: 1.0864 - val_accuracy: 0.6226\n",
            "Epoch 35/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0913 - accuracy: 0.6119 - val_loss: 1.0673 - val_accuracy: 0.6246\n",
            "Epoch 36/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0832 - accuracy: 0.6133 - val_loss: 1.0649 - val_accuracy: 0.6220\n",
            "Epoch 37/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0686 - accuracy: 0.6185 - val_loss: 1.0626 - val_accuracy: 0.6265\n",
            "Epoch 38/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0575 - accuracy: 0.6225 - val_loss: 1.0798 - val_accuracy: 0.6238\n",
            "Epoch 39/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0551 - accuracy: 0.6223 - val_loss: 1.0604 - val_accuracy: 0.6282\n",
            "Epoch 40/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0423 - accuracy: 0.6253 - val_loss: 1.0853 - val_accuracy: 0.6220\n",
            "Epoch 41/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0449 - accuracy: 0.6274 - val_loss: 1.0543 - val_accuracy: 0.6382\n",
            "Epoch 42/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0286 - accuracy: 0.6351 - val_loss: 1.0569 - val_accuracy: 0.6299\n",
            "Epoch 43/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0135 - accuracy: 0.6389 - val_loss: 1.0564 - val_accuracy: 0.6307\n",
            "Epoch 44/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0081 - accuracy: 0.6422 - val_loss: 1.0702 - val_accuracy: 0.6261\n",
            "Epoch 45/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0066 - accuracy: 0.6412 - val_loss: 1.0372 - val_accuracy: 0.6373\n",
            "Epoch 46/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9944 - accuracy: 0.6453 - val_loss: 1.0440 - val_accuracy: 0.6369\n",
            "Epoch 47/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9898 - accuracy: 0.6482 - val_loss: 1.0842 - val_accuracy: 0.6225\n",
            "Epoch 48/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9730 - accuracy: 0.6544 - val_loss: 1.0283 - val_accuracy: 0.6452\n",
            "Epoch 49/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9747 - accuracy: 0.6509 - val_loss: 1.0319 - val_accuracy: 0.6453\n",
            "Epoch 50/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9618 - accuracy: 0.6586 - val_loss: 1.0441 - val_accuracy: 0.6420\n",
            "Epoch 51/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9592 - accuracy: 0.6575 - val_loss: 1.0123 - val_accuracy: 0.6498\n",
            "Epoch 52/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9576 - accuracy: 0.6597 - val_loss: 1.0186 - val_accuracy: 0.6485\n",
            "Epoch 53/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9468 - accuracy: 0.6627 - val_loss: 1.0075 - val_accuracy: 0.6548\n",
            "Epoch 54/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9451 - accuracy: 0.6619 - val_loss: 1.0570 - val_accuracy: 0.6408\n",
            "Epoch 55/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9370 - accuracy: 0.6649 - val_loss: 1.0132 - val_accuracy: 0.6545\n",
            "Epoch 56/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9269 - accuracy: 0.6685 - val_loss: 1.0209 - val_accuracy: 0.6549\n",
            "Epoch 57/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9275 - accuracy: 0.6669 - val_loss: 1.0338 - val_accuracy: 0.6519\n",
            "Epoch 00057: early stopping\n",
            "F1 Score: 0.6519\n",
            "\n",
            "Recreating Sig Adam Model: 4\n",
            "Best Model: 4 for Sig Adam\n",
            "F1 Score: 0.6548\n",
            "Training model: 5 for Sig Adam\n",
            "Training version: 0\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 6s 3ms/step - loss: 2.3160 - accuracy: 0.1017 - val_loss: 2.3023 - val_accuracy: 0.1028\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 2.1833 - accuracy: 0.1693 - val_loss: 1.8152 - val_accuracy: 0.3444\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.8400 - accuracy: 0.3330 - val_loss: 1.6537 - val_accuracy: 0.4022\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7224 - accuracy: 0.3769 - val_loss: 1.6004 - val_accuracy: 0.4278\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6645 - accuracy: 0.3950 - val_loss: 1.5474 - val_accuracy: 0.4435\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6067 - accuracy: 0.4151 - val_loss: 1.4774 - val_accuracy: 0.4667\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5622 - accuracy: 0.4361 - val_loss: 1.4472 - val_accuracy: 0.4813\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5363 - accuracy: 0.4482 - val_loss: 1.4168 - val_accuracy: 0.4930\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5101 - accuracy: 0.4549 - val_loss: 1.3838 - val_accuracy: 0.5017\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4846 - accuracy: 0.4618 - val_loss: 1.3622 - val_accuracy: 0.5115\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4616 - accuracy: 0.4696 - val_loss: 1.3595 - val_accuracy: 0.5147\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4323 - accuracy: 0.4811 - val_loss: 1.3258 - val_accuracy: 0.5278\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4021 - accuracy: 0.4969 - val_loss: 1.3254 - val_accuracy: 0.5248\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3910 - accuracy: 0.5001 - val_loss: 1.2850 - val_accuracy: 0.5425\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3631 - accuracy: 0.5074 - val_loss: 1.2792 - val_accuracy: 0.5455\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3341 - accuracy: 0.5197 - val_loss: 1.2574 - val_accuracy: 0.5526\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3182 - accuracy: 0.5186 - val_loss: 1.2535 - val_accuracy: 0.5575\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2969 - accuracy: 0.5310 - val_loss: 1.2301 - val_accuracy: 0.5650\n",
            "Epoch 19/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2901 - accuracy: 0.5353 - val_loss: 1.2103 - val_accuracy: 0.5717\n",
            "Epoch 20/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2585 - accuracy: 0.5442 - val_loss: 1.2072 - val_accuracy: 0.5712\n",
            "Epoch 21/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2549 - accuracy: 0.5468 - val_loss: 1.2190 - val_accuracy: 0.5674\n",
            "Epoch 22/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2370 - accuracy: 0.5543 - val_loss: 1.1985 - val_accuracy: 0.5784\n",
            "Epoch 23/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2215 - accuracy: 0.5602 - val_loss: 1.1678 - val_accuracy: 0.5817\n",
            "Epoch 24/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2065 - accuracy: 0.5654 - val_loss: 1.1562 - val_accuracy: 0.5879\n",
            "Epoch 25/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1940 - accuracy: 0.5690 - val_loss: 1.1532 - val_accuracy: 0.5882\n",
            "Epoch 26/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1769 - accuracy: 0.5728 - val_loss: 1.1439 - val_accuracy: 0.5950\n",
            "Epoch 27/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1624 - accuracy: 0.5783 - val_loss: 1.1369 - val_accuracy: 0.5997\n",
            "Epoch 28/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1532 - accuracy: 0.5820 - val_loss: 1.1310 - val_accuracy: 0.5999\n",
            "Epoch 29/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1402 - accuracy: 0.5922 - val_loss: 1.1262 - val_accuracy: 0.6026\n",
            "Epoch 30/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1223 - accuracy: 0.5954 - val_loss: 1.1187 - val_accuracy: 0.6020\n",
            "Epoch 31/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1190 - accuracy: 0.5942 - val_loss: 1.1198 - val_accuracy: 0.6078\n",
            "Epoch 32/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1231 - accuracy: 0.5930 - val_loss: 1.1133 - val_accuracy: 0.6063\n",
            "Epoch 33/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1056 - accuracy: 0.5981 - val_loss: 1.1100 - val_accuracy: 0.6080\n",
            "Epoch 34/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0937 - accuracy: 0.6037 - val_loss: 1.1190 - val_accuracy: 0.6112\n",
            "Epoch 35/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0809 - accuracy: 0.6079 - val_loss: 1.1029 - val_accuracy: 0.6117\n",
            "Epoch 36/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0658 - accuracy: 0.6140 - val_loss: 1.1051 - val_accuracy: 0.6098\n",
            "Epoch 37/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0662 - accuracy: 0.6131 - val_loss: 1.1141 - val_accuracy: 0.6072\n",
            "Epoch 38/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0605 - accuracy: 0.6139 - val_loss: 1.0974 - val_accuracy: 0.6172\n",
            "Epoch 39/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0456 - accuracy: 0.6232 - val_loss: 1.0943 - val_accuracy: 0.6186\n",
            "Epoch 40/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0367 - accuracy: 0.6263 - val_loss: 1.1020 - val_accuracy: 0.6104\n",
            "Epoch 41/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0365 - accuracy: 0.6243 - val_loss: 1.0948 - val_accuracy: 0.6131\n",
            "Epoch 42/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0296 - accuracy: 0.6312 - val_loss: 1.0910 - val_accuracy: 0.6180\n",
            "Epoch 43/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0147 - accuracy: 0.6311 - val_loss: 1.0874 - val_accuracy: 0.6225\n",
            "Epoch 44/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9989 - accuracy: 0.6356 - val_loss: 1.0857 - val_accuracy: 0.6199\n",
            "Epoch 45/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9969 - accuracy: 0.6372 - val_loss: 1.0759 - val_accuracy: 0.6290\n",
            "Epoch 46/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9954 - accuracy: 0.6366 - val_loss: 1.0991 - val_accuracy: 0.6175\n",
            "Epoch 47/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9939 - accuracy: 0.6388 - val_loss: 1.1025 - val_accuracy: 0.6148\n",
            "Epoch 48/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9911 - accuracy: 0.6394 - val_loss: 1.0991 - val_accuracy: 0.6180\n",
            "Epoch 49/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9856 - accuracy: 0.6412 - val_loss: 1.0966 - val_accuracy: 0.6186\n",
            "Epoch 00049: early stopping\n",
            "F1 Score: 0.6186\n",
            "\n",
            "Recreating Sig Adam Model: 5\n",
            "Training version: 1\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 6s 3ms/step - loss: 2.3150 - accuracy: 0.1003 - val_loss: 2.3074 - val_accuracy: 0.1000\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 2.0964 - accuracy: 0.2114 - val_loss: 1.7951 - val_accuracy: 0.3617\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.8045 - accuracy: 0.3418 - val_loss: 1.6632 - val_accuracy: 0.4042\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7160 - accuracy: 0.3778 - val_loss: 1.5589 - val_accuracy: 0.4356\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6500 - accuracy: 0.4016 - val_loss: 1.5281 - val_accuracy: 0.4507\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5993 - accuracy: 0.4212 - val_loss: 1.5072 - val_accuracy: 0.4605\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5518 - accuracy: 0.4361 - val_loss: 1.4385 - val_accuracy: 0.4861\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5367 - accuracy: 0.4427 - val_loss: 1.4232 - val_accuracy: 0.4904\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4977 - accuracy: 0.4610 - val_loss: 1.3930 - val_accuracy: 0.5017\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4842 - accuracy: 0.4625 - val_loss: 1.3799 - val_accuracy: 0.5079\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4523 - accuracy: 0.4768 - val_loss: 1.3690 - val_accuracy: 0.5071\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4363 - accuracy: 0.4815 - val_loss: 1.3295 - val_accuracy: 0.5219\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4145 - accuracy: 0.4905 - val_loss: 1.3048 - val_accuracy: 0.5290\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3904 - accuracy: 0.4984 - val_loss: 1.3042 - val_accuracy: 0.5354\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3817 - accuracy: 0.5004 - val_loss: 1.2802 - val_accuracy: 0.5449\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3562 - accuracy: 0.5062 - val_loss: 1.2543 - val_accuracy: 0.5511\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3334 - accuracy: 0.5150 - val_loss: 1.2519 - val_accuracy: 0.5528\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3075 - accuracy: 0.5320 - val_loss: 1.2321 - val_accuracy: 0.5607\n",
            "Epoch 19/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2989 - accuracy: 0.5325 - val_loss: 1.2476 - val_accuracy: 0.5583\n",
            "Epoch 20/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2745 - accuracy: 0.5409 - val_loss: 1.2133 - val_accuracy: 0.5682\n",
            "Epoch 21/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2612 - accuracy: 0.5456 - val_loss: 1.1971 - val_accuracy: 0.5745\n",
            "Epoch 22/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2430 - accuracy: 0.5519 - val_loss: 1.1793 - val_accuracy: 0.5810\n",
            "Epoch 23/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2312 - accuracy: 0.5549 - val_loss: 1.1731 - val_accuracy: 0.5827\n",
            "Epoch 24/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2111 - accuracy: 0.5617 - val_loss: 1.1672 - val_accuracy: 0.5896\n",
            "Epoch 25/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2019 - accuracy: 0.5646 - val_loss: 1.1487 - val_accuracy: 0.5928\n",
            "Epoch 26/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2022 - accuracy: 0.5675 - val_loss: 1.1597 - val_accuracy: 0.5847\n",
            "Epoch 27/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1772 - accuracy: 0.5784 - val_loss: 1.1399 - val_accuracy: 0.5932\n",
            "Epoch 28/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1727 - accuracy: 0.5751 - val_loss: 1.1669 - val_accuracy: 0.5882\n",
            "Epoch 29/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1564 - accuracy: 0.5840 - val_loss: 1.1430 - val_accuracy: 0.6007\n",
            "Epoch 30/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1590 - accuracy: 0.5803 - val_loss: 1.1339 - val_accuracy: 0.5972\n",
            "Epoch 31/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1430 - accuracy: 0.5877 - val_loss: 1.1352 - val_accuracy: 0.5955\n",
            "Epoch 32/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1220 - accuracy: 0.5988 - val_loss: 1.1271 - val_accuracy: 0.6014\n",
            "Epoch 33/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1183 - accuracy: 0.5978 - val_loss: 1.1267 - val_accuracy: 0.6014\n",
            "Epoch 34/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1167 - accuracy: 0.5980 - val_loss: 1.1206 - val_accuracy: 0.6050\n",
            "Epoch 35/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0996 - accuracy: 0.6021 - val_loss: 1.1467 - val_accuracy: 0.5967\n",
            "Epoch 36/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0982 - accuracy: 0.6037 - val_loss: 1.1253 - val_accuracy: 0.6051\n",
            "Epoch 37/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0859 - accuracy: 0.6095 - val_loss: 1.1233 - val_accuracy: 0.6053\n",
            "Epoch 38/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0730 - accuracy: 0.6130 - val_loss: 1.0997 - val_accuracy: 0.6149\n",
            "Epoch 39/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0683 - accuracy: 0.6130 - val_loss: 1.1205 - val_accuracy: 0.6106\n",
            "Epoch 40/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0644 - accuracy: 0.6154 - val_loss: 1.0995 - val_accuracy: 0.6168\n",
            "Epoch 41/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0448 - accuracy: 0.6222 - val_loss: 1.1108 - val_accuracy: 0.6134\n",
            "Epoch 42/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0384 - accuracy: 0.6235 - val_loss: 1.1046 - val_accuracy: 0.6128\n",
            "Epoch 43/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0332 - accuracy: 0.6242 - val_loss: 1.0964 - val_accuracy: 0.6174\n",
            "Epoch 44/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0257 - accuracy: 0.6254 - val_loss: 1.1067 - val_accuracy: 0.6086\n",
            "Epoch 45/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0267 - accuracy: 0.6286 - val_loss: 1.0856 - val_accuracy: 0.6227\n",
            "Epoch 46/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0146 - accuracy: 0.6290 - val_loss: 1.1018 - val_accuracy: 0.6163\n",
            "Epoch 47/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0003 - accuracy: 0.6323 - val_loss: 1.1125 - val_accuracy: 0.6104\n",
            "Epoch 48/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9977 - accuracy: 0.6349 - val_loss: 1.0997 - val_accuracy: 0.6140\n",
            "Epoch 49/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9785 - accuracy: 0.6420 - val_loss: 1.0844 - val_accuracy: 0.6226\n",
            "Epoch 50/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9786 - accuracy: 0.6443 - val_loss: 1.1040 - val_accuracy: 0.6239\n",
            "Epoch 51/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9733 - accuracy: 0.6448 - val_loss: 1.0966 - val_accuracy: 0.6182\n",
            "Epoch 52/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9701 - accuracy: 0.6454 - val_loss: 1.1078 - val_accuracy: 0.6188\n",
            "Epoch 53/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9659 - accuracy: 0.6483 - val_loss: 1.1098 - val_accuracy: 0.6084\n",
            "Epoch 00053: early stopping\n",
            "F1 Score: 0.6084\n",
            "\n",
            "Recreating Sig Adam Model: 5\n",
            "Training version: 2\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 6s 3ms/step - loss: 2.3147 - accuracy: 0.1006 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 2.2542 - accuracy: 0.1304 - val_loss: 1.8590 - val_accuracy: 0.3280\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.8589 - accuracy: 0.3182 - val_loss: 1.6565 - val_accuracy: 0.4023\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7284 - accuracy: 0.3729 - val_loss: 1.5910 - val_accuracy: 0.4256\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6719 - accuracy: 0.3930 - val_loss: 1.5739 - val_accuracy: 0.4364\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6098 - accuracy: 0.4189 - val_loss: 1.4734 - val_accuracy: 0.4668\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5739 - accuracy: 0.4307 - val_loss: 1.4623 - val_accuracy: 0.4782\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5350 - accuracy: 0.4376 - val_loss: 1.4212 - val_accuracy: 0.4895\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5006 - accuracy: 0.4579 - val_loss: 1.3759 - val_accuracy: 0.5028\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4727 - accuracy: 0.4692 - val_loss: 1.3717 - val_accuracy: 0.5068\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4494 - accuracy: 0.4792 - val_loss: 1.3428 - val_accuracy: 0.5228\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4296 - accuracy: 0.4809 - val_loss: 1.3230 - val_accuracy: 0.5254\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4025 - accuracy: 0.4956 - val_loss: 1.3086 - val_accuracy: 0.5311\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3858 - accuracy: 0.5014 - val_loss: 1.2975 - val_accuracy: 0.5316\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3645 - accuracy: 0.5101 - val_loss: 1.2685 - val_accuracy: 0.5508\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3522 - accuracy: 0.5150 - val_loss: 1.2638 - val_accuracy: 0.5451\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3307 - accuracy: 0.5216 - val_loss: 1.2468 - val_accuracy: 0.5599\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3144 - accuracy: 0.5247 - val_loss: 1.2296 - val_accuracy: 0.5645\n",
            "Epoch 19/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3015 - accuracy: 0.5326 - val_loss: 1.2208 - val_accuracy: 0.5715\n",
            "Epoch 20/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2713 - accuracy: 0.5406 - val_loss: 1.2100 - val_accuracy: 0.5711\n",
            "Epoch 21/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2638 - accuracy: 0.5455 - val_loss: 1.2215 - val_accuracy: 0.5756\n",
            "Epoch 22/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2473 - accuracy: 0.5496 - val_loss: 1.1993 - val_accuracy: 0.5780\n",
            "Epoch 23/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2341 - accuracy: 0.5595 - val_loss: 1.1841 - val_accuracy: 0.5852\n",
            "Epoch 24/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2239 - accuracy: 0.5590 - val_loss: 1.1784 - val_accuracy: 0.5844\n",
            "Epoch 25/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2117 - accuracy: 0.5635 - val_loss: 1.1612 - val_accuracy: 0.5890\n",
            "Epoch 26/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2038 - accuracy: 0.5658 - val_loss: 1.1611 - val_accuracy: 0.5878\n",
            "Epoch 27/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1904 - accuracy: 0.5709 - val_loss: 1.1534 - val_accuracy: 0.5952\n",
            "Epoch 28/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1623 - accuracy: 0.5859 - val_loss: 1.1592 - val_accuracy: 0.5957\n",
            "Epoch 29/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1619 - accuracy: 0.5847 - val_loss: 1.1307 - val_accuracy: 0.6039\n",
            "Epoch 30/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1511 - accuracy: 0.5844 - val_loss: 1.1394 - val_accuracy: 0.5973\n",
            "Epoch 31/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1379 - accuracy: 0.5860 - val_loss: 1.1414 - val_accuracy: 0.5929\n",
            "Epoch 32/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1301 - accuracy: 0.5934 - val_loss: 1.1246 - val_accuracy: 0.6079\n",
            "Epoch 33/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1177 - accuracy: 0.6003 - val_loss: 1.1150 - val_accuracy: 0.6086\n",
            "Epoch 34/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1015 - accuracy: 0.6020 - val_loss: 1.1152 - val_accuracy: 0.6098\n",
            "Epoch 35/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1011 - accuracy: 0.6027 - val_loss: 1.1106 - val_accuracy: 0.6064\n",
            "Epoch 36/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0986 - accuracy: 0.6016 - val_loss: 1.0975 - val_accuracy: 0.6080\n",
            "Epoch 37/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0789 - accuracy: 0.6072 - val_loss: 1.1051 - val_accuracy: 0.6114\n",
            "Epoch 38/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0805 - accuracy: 0.6109 - val_loss: 1.1031 - val_accuracy: 0.6161\n",
            "Epoch 39/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0734 - accuracy: 0.6093 - val_loss: 1.1080 - val_accuracy: 0.6090\n",
            "Epoch 40/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0579 - accuracy: 0.6171 - val_loss: 1.0962 - val_accuracy: 0.6144\n",
            "Epoch 41/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0497 - accuracy: 0.6187 - val_loss: 1.0965 - val_accuracy: 0.6168\n",
            "Epoch 42/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0371 - accuracy: 0.6241 - val_loss: 1.0921 - val_accuracy: 0.6177\n",
            "Epoch 43/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0397 - accuracy: 0.6194 - val_loss: 1.0950 - val_accuracy: 0.6210\n",
            "Epoch 44/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0378 - accuracy: 0.6232 - val_loss: 1.1142 - val_accuracy: 0.6126\n",
            "Epoch 45/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0251 - accuracy: 0.6296 - val_loss: 1.1172 - val_accuracy: 0.6095\n",
            "Epoch 46/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0230 - accuracy: 0.6277 - val_loss: 1.0917 - val_accuracy: 0.6160\n",
            "Epoch 47/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0133 - accuracy: 0.6338 - val_loss: 1.1051 - val_accuracy: 0.6200\n",
            "Epoch 48/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0056 - accuracy: 0.6340 - val_loss: 1.0970 - val_accuracy: 0.6166\n",
            "Epoch 49/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9876 - accuracy: 0.6421 - val_loss: 1.1036 - val_accuracy: 0.6166\n",
            "Epoch 50/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9739 - accuracy: 0.6436 - val_loss: 1.1027 - val_accuracy: 0.6211\n",
            "Epoch 00050: early stopping\n",
            "F1 Score: 0.6211\n",
            "\n",
            "Recreating Sig Adam Model: 5\n",
            "Best Model: 5 for Sig Adam\n",
            "F1 Score: 0.616\n",
            "Training model: 1 for Sig SGD\n",
            "Training version: 0\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 2.3110 - accuracy: 0.1098 - val_loss: 2.2435 - val_accuracy: 0.1671\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 2.2164 - accuracy: 0.1798 - val_loss: 2.1023 - val_accuracy: 0.2393\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 2.0931 - accuracy: 0.2350 - val_loss: 2.0232 - val_accuracy: 0.2640\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 2.0118 - accuracy: 0.2690 - val_loss: 1.9616 - val_accuracy: 0.2809\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.9640 - accuracy: 0.2927 - val_loss: 1.9289 - val_accuracy: 0.3134\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.9277 - accuracy: 0.3109 - val_loss: 1.8973 - val_accuracy: 0.3203\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.9010 - accuracy: 0.3194 - val_loss: 1.8671 - val_accuracy: 0.3369\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.8712 - accuracy: 0.3374 - val_loss: 1.8456 - val_accuracy: 0.3450\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.8589 - accuracy: 0.3384 - val_loss: 1.8140 - val_accuracy: 0.3632\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.8264 - accuracy: 0.3536 - val_loss: 1.8115 - val_accuracy: 0.3538\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.8023 - accuracy: 0.3626 - val_loss: 1.7629 - val_accuracy: 0.3798\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7759 - accuracy: 0.3696 - val_loss: 1.7569 - val_accuracy: 0.3754\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7592 - accuracy: 0.3743 - val_loss: 1.7192 - val_accuracy: 0.3894\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7381 - accuracy: 0.3844 - val_loss: 1.7069 - val_accuracy: 0.4025\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7226 - accuracy: 0.3885 - val_loss: 1.7012 - val_accuracy: 0.3987\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7035 - accuracy: 0.3955 - val_loss: 1.6840 - val_accuracy: 0.3959\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6885 - accuracy: 0.4005 - val_loss: 1.6594 - val_accuracy: 0.4129\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6691 - accuracy: 0.4097 - val_loss: 1.6389 - val_accuracy: 0.4175\n",
            "Epoch 19/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6571 - accuracy: 0.4118 - val_loss: 1.6198 - val_accuracy: 0.4256\n",
            "Epoch 20/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6346 - accuracy: 0.4204 - val_loss: 1.5970 - val_accuracy: 0.4363\n",
            "Epoch 21/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6221 - accuracy: 0.4259 - val_loss: 1.5881 - val_accuracy: 0.4354\n",
            "Epoch 22/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6105 - accuracy: 0.4284 - val_loss: 1.5793 - val_accuracy: 0.4345\n",
            "Epoch 23/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5939 - accuracy: 0.4339 - val_loss: 1.5565 - val_accuracy: 0.4462\n",
            "Epoch 24/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5767 - accuracy: 0.4419 - val_loss: 1.5496 - val_accuracy: 0.4517\n",
            "Epoch 25/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5639 - accuracy: 0.4434 - val_loss: 1.5244 - val_accuracy: 0.4584\n",
            "Epoch 26/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5568 - accuracy: 0.4481 - val_loss: 1.5135 - val_accuracy: 0.4609\n",
            "Epoch 27/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5301 - accuracy: 0.4586 - val_loss: 1.5073 - val_accuracy: 0.4614\n",
            "Epoch 28/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5338 - accuracy: 0.4532 - val_loss: 1.5287 - val_accuracy: 0.4535\n",
            "Epoch 29/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5005 - accuracy: 0.4669 - val_loss: 1.4738 - val_accuracy: 0.4748\n",
            "Epoch 30/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4930 - accuracy: 0.4714 - val_loss: 1.4589 - val_accuracy: 0.4818\n",
            "Epoch 31/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4828 - accuracy: 0.4714 - val_loss: 1.4527 - val_accuracy: 0.4819\n",
            "Epoch 32/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4701 - accuracy: 0.4725 - val_loss: 1.4432 - val_accuracy: 0.4869\n",
            "Epoch 33/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4581 - accuracy: 0.4847 - val_loss: 1.4328 - val_accuracy: 0.4911\n",
            "Epoch 34/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4349 - accuracy: 0.4886 - val_loss: 1.4234 - val_accuracy: 0.4847\n",
            "Epoch 35/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4320 - accuracy: 0.4878 - val_loss: 1.4135 - val_accuracy: 0.4944\n",
            "Epoch 36/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4259 - accuracy: 0.4883 - val_loss: 1.3951 - val_accuracy: 0.5045\n",
            "Epoch 37/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4063 - accuracy: 0.4978 - val_loss: 1.3941 - val_accuracy: 0.4967\n",
            "Epoch 38/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4028 - accuracy: 0.4975 - val_loss: 1.3734 - val_accuracy: 0.5115\n",
            "Epoch 39/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3883 - accuracy: 0.5036 - val_loss: 1.3684 - val_accuracy: 0.5128\n",
            "Epoch 40/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3678 - accuracy: 0.5129 - val_loss: 1.3636 - val_accuracy: 0.5130\n",
            "Epoch 41/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3647 - accuracy: 0.5130 - val_loss: 1.3611 - val_accuracy: 0.5130\n",
            "Epoch 42/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3586 - accuracy: 0.5179 - val_loss: 1.3400 - val_accuracy: 0.5194\n",
            "Epoch 43/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3416 - accuracy: 0.5238 - val_loss: 1.3448 - val_accuracy: 0.5207\n",
            "Epoch 44/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3358 - accuracy: 0.5215 - val_loss: 1.3160 - val_accuracy: 0.5268\n",
            "Epoch 45/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3375 - accuracy: 0.5259 - val_loss: 1.3121 - val_accuracy: 0.5287\n",
            "Epoch 46/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3287 - accuracy: 0.5276 - val_loss: 1.3134 - val_accuracy: 0.5306\n",
            "Epoch 47/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3072 - accuracy: 0.5336 - val_loss: 1.2993 - val_accuracy: 0.5316\n",
            "Epoch 48/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3048 - accuracy: 0.5330 - val_loss: 1.2962 - val_accuracy: 0.5353\n",
            "Epoch 49/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2948 - accuracy: 0.5404 - val_loss: 1.2879 - val_accuracy: 0.5368\n",
            "Epoch 50/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2814 - accuracy: 0.5447 - val_loss: 1.2829 - val_accuracy: 0.5401\n",
            "Epoch 51/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2744 - accuracy: 0.5471 - val_loss: 1.2793 - val_accuracy: 0.5381\n",
            "Epoch 52/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2671 - accuracy: 0.5489 - val_loss: 1.2535 - val_accuracy: 0.5516\n",
            "Epoch 53/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2581 - accuracy: 0.5521 - val_loss: 1.2595 - val_accuracy: 0.5465\n",
            "Epoch 54/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2490 - accuracy: 0.5580 - val_loss: 1.2502 - val_accuracy: 0.5519\n",
            "Epoch 55/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2352 - accuracy: 0.5624 - val_loss: 1.2389 - val_accuracy: 0.5577\n",
            "Epoch 56/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2235 - accuracy: 0.5650 - val_loss: 1.2298 - val_accuracy: 0.5582\n",
            "Epoch 57/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2233 - accuracy: 0.5662 - val_loss: 1.2320 - val_accuracy: 0.5588\n",
            "Epoch 58/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2141 - accuracy: 0.5710 - val_loss: 1.2170 - val_accuracy: 0.5649\n",
            "Epoch 59/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2014 - accuracy: 0.5724 - val_loss: 1.2147 - val_accuracy: 0.5652\n",
            "Epoch 60/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2041 - accuracy: 0.5774 - val_loss: 1.2109 - val_accuracy: 0.5656\n",
            "Epoch 61/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1919 - accuracy: 0.5773 - val_loss: 1.2019 - val_accuracy: 0.5713\n",
            "Epoch 62/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1812 - accuracy: 0.5817 - val_loss: 1.2243 - val_accuracy: 0.5612\n",
            "Epoch 63/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1715 - accuracy: 0.5833 - val_loss: 1.1900 - val_accuracy: 0.5741\n",
            "Epoch 64/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1772 - accuracy: 0.5830 - val_loss: 1.1965 - val_accuracy: 0.5713\n",
            "Epoch 65/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1651 - accuracy: 0.5891 - val_loss: 1.1845 - val_accuracy: 0.5736\n",
            "Epoch 66/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1622 - accuracy: 0.5882 - val_loss: 1.1742 - val_accuracy: 0.5816\n",
            "Epoch 67/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1487 - accuracy: 0.5941 - val_loss: 1.1807 - val_accuracy: 0.5803\n",
            "Epoch 68/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1460 - accuracy: 0.5959 - val_loss: 1.1842 - val_accuracy: 0.5782\n",
            "Epoch 69/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1425 - accuracy: 0.5990 - val_loss: 1.1671 - val_accuracy: 0.5838\n",
            "Epoch 70/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1314 - accuracy: 0.6000 - val_loss: 1.1723 - val_accuracy: 0.5789\n",
            "Epoch 71/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1200 - accuracy: 0.6042 - val_loss: 1.1650 - val_accuracy: 0.5838\n",
            "Epoch 72/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1256 - accuracy: 0.6010 - val_loss: 1.1582 - val_accuracy: 0.5866\n",
            "Epoch 73/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1212 - accuracy: 0.6055 - val_loss: 1.1701 - val_accuracy: 0.5815\n",
            "Epoch 74/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1163 - accuracy: 0.6076 - val_loss: 1.1677 - val_accuracy: 0.5870\n",
            "Epoch 75/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1064 - accuracy: 0.6088 - val_loss: 1.1450 - val_accuracy: 0.5960\n",
            "Epoch 76/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0999 - accuracy: 0.6152 - val_loss: 1.1577 - val_accuracy: 0.5886\n",
            "Epoch 77/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0913 - accuracy: 0.6194 - val_loss: 1.1418 - val_accuracy: 0.5944\n",
            "Epoch 78/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0909 - accuracy: 0.6195 - val_loss: 1.1331 - val_accuracy: 0.5983\n",
            "Epoch 79/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0845 - accuracy: 0.6192 - val_loss: 1.1432 - val_accuracy: 0.5950\n",
            "Epoch 80/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0804 - accuracy: 0.6194 - val_loss: 1.1274 - val_accuracy: 0.6033\n",
            "Epoch 81/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0722 - accuracy: 0.6237 - val_loss: 1.1290 - val_accuracy: 0.5966\n",
            "Epoch 82/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0711 - accuracy: 0.6214 - val_loss: 1.1236 - val_accuracy: 0.6025\n",
            "Epoch 83/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0604 - accuracy: 0.6269 - val_loss: 1.1315 - val_accuracy: 0.5961\n",
            "Epoch 84/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0520 - accuracy: 0.6322 - val_loss: 1.1182 - val_accuracy: 0.6023\n",
            "Epoch 85/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0502 - accuracy: 0.6309 - val_loss: 1.1202 - val_accuracy: 0.6003\n",
            "Epoch 86/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0470 - accuracy: 0.6352 - val_loss: 1.1132 - val_accuracy: 0.6069\n",
            "Epoch 87/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0456 - accuracy: 0.6343 - val_loss: 1.1121 - val_accuracy: 0.6094\n",
            "Epoch 88/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0342 - accuracy: 0.6359 - val_loss: 1.1068 - val_accuracy: 0.6097\n",
            "Epoch 89/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0326 - accuracy: 0.6372 - val_loss: 1.1037 - val_accuracy: 0.6080\n",
            "Epoch 90/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0266 - accuracy: 0.6358 - val_loss: 1.1053 - val_accuracy: 0.6087\n",
            "Epoch 91/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0162 - accuracy: 0.6442 - val_loss: 1.1004 - val_accuracy: 0.6113\n",
            "Epoch 92/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0229 - accuracy: 0.6436 - val_loss: 1.1015 - val_accuracy: 0.6100\n",
            "Epoch 93/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0105 - accuracy: 0.6475 - val_loss: 1.0906 - val_accuracy: 0.6139\n",
            "Epoch 94/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0112 - accuracy: 0.6470 - val_loss: 1.1073 - val_accuracy: 0.6032\n",
            "Epoch 95/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0021 - accuracy: 0.6478 - val_loss: 1.1316 - val_accuracy: 0.5955\n",
            "Epoch 96/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0036 - accuracy: 0.6499 - val_loss: 1.0884 - val_accuracy: 0.6184\n",
            "Epoch 97/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9942 - accuracy: 0.6509 - val_loss: 1.0892 - val_accuracy: 0.6136\n",
            "Epoch 98/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9832 - accuracy: 0.6570 - val_loss: 1.0850 - val_accuracy: 0.6155\n",
            "Epoch 99/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9830 - accuracy: 0.6581 - val_loss: 1.0829 - val_accuracy: 0.6205\n",
            "Epoch 100/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9831 - accuracy: 0.6565 - val_loss: 1.0856 - val_accuracy: 0.6183\n",
            "Epoch 101/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9815 - accuracy: 0.6568 - val_loss: 1.0770 - val_accuracy: 0.6184\n",
            "Epoch 102/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9700 - accuracy: 0.6619 - val_loss: 1.0718 - val_accuracy: 0.6210\n",
            "Epoch 103/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9676 - accuracy: 0.6624 - val_loss: 1.0709 - val_accuracy: 0.6226\n",
            "Epoch 104/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9676 - accuracy: 0.6616 - val_loss: 1.0712 - val_accuracy: 0.6233\n",
            "Epoch 105/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9642 - accuracy: 0.6644 - val_loss: 1.0668 - val_accuracy: 0.6253\n",
            "Epoch 106/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9529 - accuracy: 0.6664 - val_loss: 1.0682 - val_accuracy: 0.6244\n",
            "Epoch 107/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9493 - accuracy: 0.6685 - val_loss: 1.0662 - val_accuracy: 0.6250\n",
            "Epoch 108/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9524 - accuracy: 0.6647 - val_loss: 1.0740 - val_accuracy: 0.6170\n",
            "Epoch 109/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9340 - accuracy: 0.6722 - val_loss: 1.0605 - val_accuracy: 0.6271\n",
            "Epoch 110/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9345 - accuracy: 0.6722 - val_loss: 1.0714 - val_accuracy: 0.6270\n",
            "Epoch 111/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9338 - accuracy: 0.6753 - val_loss: 1.0753 - val_accuracy: 0.6165\n",
            "Epoch 112/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9302 - accuracy: 0.6751 - val_loss: 1.0684 - val_accuracy: 0.6237\n",
            "Epoch 113/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9270 - accuracy: 0.6767 - val_loss: 1.0600 - val_accuracy: 0.6251\n",
            "Epoch 114/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9153 - accuracy: 0.6815 - val_loss: 1.0565 - val_accuracy: 0.6265\n",
            "Epoch 115/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9136 - accuracy: 0.6832 - val_loss: 1.0562 - val_accuracy: 0.6252\n",
            "Epoch 116/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9072 - accuracy: 0.6833 - val_loss: 1.0567 - val_accuracy: 0.6260\n",
            "Epoch 117/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9074 - accuracy: 0.6824 - val_loss: 1.0502 - val_accuracy: 0.6320\n",
            "Epoch 118/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9041 - accuracy: 0.6806 - val_loss: 1.0517 - val_accuracy: 0.6326\n",
            "Epoch 119/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9006 - accuracy: 0.6831 - val_loss: 1.0496 - val_accuracy: 0.6277\n",
            "Epoch 120/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9003 - accuracy: 0.6862 - val_loss: 1.0482 - val_accuracy: 0.6304\n",
            "Epoch 121/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8903 - accuracy: 0.6910 - val_loss: 1.0568 - val_accuracy: 0.6284\n",
            "Epoch 122/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8902 - accuracy: 0.6879 - val_loss: 1.0584 - val_accuracy: 0.6280\n",
            "Epoch 123/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8753 - accuracy: 0.6959 - val_loss: 1.0453 - val_accuracy: 0.6284\n",
            "Epoch 124/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8903 - accuracy: 0.6914 - val_loss: 1.0495 - val_accuracy: 0.6298\n",
            "Epoch 125/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8718 - accuracy: 0.7015 - val_loss: 1.0388 - val_accuracy: 0.6358\n",
            "Epoch 126/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8738 - accuracy: 0.6938 - val_loss: 1.0406 - val_accuracy: 0.6347\n",
            "Epoch 127/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8702 - accuracy: 0.6979 - val_loss: 1.0338 - val_accuracy: 0.6342\n",
            "Epoch 128/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8596 - accuracy: 0.7010 - val_loss: 1.0422 - val_accuracy: 0.6317\n",
            "Epoch 129/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8658 - accuracy: 0.6989 - val_loss: 1.0321 - val_accuracy: 0.6398\n",
            "Epoch 130/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8544 - accuracy: 0.7015 - val_loss: 1.0407 - val_accuracy: 0.6346\n",
            "Epoch 131/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8540 - accuracy: 0.7022 - val_loss: 1.0419 - val_accuracy: 0.6348\n",
            "Epoch 132/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8520 - accuracy: 0.7027 - val_loss: 1.0377 - val_accuracy: 0.6317\n",
            "Epoch 133/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8332 - accuracy: 0.7105 - val_loss: 1.0320 - val_accuracy: 0.6350\n",
            "Epoch 00133: early stopping\n",
            "F1 Score: 0.635\n",
            "\n",
            "Recreating Sig SGD Model: 1\n",
            "Training version: 1\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 2.3035 - accuracy: 0.1183 - val_loss: 2.1874 - val_accuracy: 0.2206\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 2.1650 - accuracy: 0.2021 - val_loss: 2.0559 - val_accuracy: 0.2716\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 2.0548 - accuracy: 0.2556 - val_loss: 1.9756 - val_accuracy: 0.2951\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.9757 - accuracy: 0.2873 - val_loss: 1.9283 - val_accuracy: 0.3064\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.9337 - accuracy: 0.3086 - val_loss: 1.9063 - val_accuracy: 0.3287\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.9013 - accuracy: 0.3239 - val_loss: 1.8786 - val_accuracy: 0.3305\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.8710 - accuracy: 0.3376 - val_loss: 1.8563 - val_accuracy: 0.3548\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.8542 - accuracy: 0.3456 - val_loss: 1.8262 - val_accuracy: 0.3558\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.8271 - accuracy: 0.3534 - val_loss: 1.7988 - val_accuracy: 0.3719\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.8076 - accuracy: 0.3626 - val_loss: 1.7821 - val_accuracy: 0.3786\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7892 - accuracy: 0.3677 - val_loss: 1.7541 - val_accuracy: 0.3828\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7597 - accuracy: 0.3800 - val_loss: 1.7463 - val_accuracy: 0.3853\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7469 - accuracy: 0.3860 - val_loss: 1.7114 - val_accuracy: 0.3989\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7209 - accuracy: 0.3924 - val_loss: 1.7079 - val_accuracy: 0.3902\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7023 - accuracy: 0.3973 - val_loss: 1.6716 - val_accuracy: 0.4116\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6923 - accuracy: 0.4006 - val_loss: 1.6538 - val_accuracy: 0.4190\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6739 - accuracy: 0.4055 - val_loss: 1.6407 - val_accuracy: 0.4196\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6505 - accuracy: 0.4178 - val_loss: 1.6261 - val_accuracy: 0.4292\n",
            "Epoch 19/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6438 - accuracy: 0.4168 - val_loss: 1.6117 - val_accuracy: 0.4240\n",
            "Epoch 20/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6348 - accuracy: 0.4233 - val_loss: 1.5997 - val_accuracy: 0.4362\n",
            "Epoch 21/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6199 - accuracy: 0.4259 - val_loss: 1.5828 - val_accuracy: 0.4418\n",
            "Epoch 22/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6013 - accuracy: 0.4338 - val_loss: 1.5690 - val_accuracy: 0.4491\n",
            "Epoch 23/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5819 - accuracy: 0.4380 - val_loss: 1.5543 - val_accuracy: 0.4526\n",
            "Epoch 24/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5692 - accuracy: 0.4450 - val_loss: 1.5422 - val_accuracy: 0.4580\n",
            "Epoch 25/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5576 - accuracy: 0.4490 - val_loss: 1.5309 - val_accuracy: 0.4599\n",
            "Epoch 26/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5357 - accuracy: 0.4550 - val_loss: 1.5075 - val_accuracy: 0.4689\n",
            "Epoch 27/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5207 - accuracy: 0.4589 - val_loss: 1.5071 - val_accuracy: 0.4648\n",
            "Epoch 28/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5067 - accuracy: 0.4669 - val_loss: 1.4864 - val_accuracy: 0.4724\n",
            "Epoch 29/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4876 - accuracy: 0.4706 - val_loss: 1.4711 - val_accuracy: 0.4836\n",
            "Epoch 30/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4797 - accuracy: 0.4742 - val_loss: 1.4523 - val_accuracy: 0.4865\n",
            "Epoch 31/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4721 - accuracy: 0.4767 - val_loss: 1.4480 - val_accuracy: 0.4857\n",
            "Epoch 32/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4558 - accuracy: 0.4838 - val_loss: 1.4313 - val_accuracy: 0.5007\n",
            "Epoch 33/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4421 - accuracy: 0.4871 - val_loss: 1.4364 - val_accuracy: 0.4863\n",
            "Epoch 34/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4337 - accuracy: 0.4878 - val_loss: 1.4048 - val_accuracy: 0.5010\n",
            "Epoch 35/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4192 - accuracy: 0.4965 - val_loss: 1.3894 - val_accuracy: 0.5069\n",
            "Epoch 36/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3974 - accuracy: 0.5012 - val_loss: 1.3818 - val_accuracy: 0.5155\n",
            "Epoch 37/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3901 - accuracy: 0.5078 - val_loss: 1.3785 - val_accuracy: 0.5099\n",
            "Epoch 38/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3875 - accuracy: 0.5075 - val_loss: 1.3631 - val_accuracy: 0.5152\n",
            "Epoch 39/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3699 - accuracy: 0.5119 - val_loss: 1.3531 - val_accuracy: 0.5169\n",
            "Epoch 40/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3624 - accuracy: 0.5172 - val_loss: 1.3463 - val_accuracy: 0.5214\n",
            "Epoch 41/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3459 - accuracy: 0.5225 - val_loss: 1.3436 - val_accuracy: 0.5226\n",
            "Epoch 42/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3393 - accuracy: 0.5285 - val_loss: 1.3415 - val_accuracy: 0.5183\n",
            "Epoch 43/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3301 - accuracy: 0.5249 - val_loss: 1.3300 - val_accuracy: 0.5224\n",
            "Epoch 44/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3237 - accuracy: 0.5297 - val_loss: 1.3100 - val_accuracy: 0.5312\n",
            "Epoch 45/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3061 - accuracy: 0.5361 - val_loss: 1.3094 - val_accuracy: 0.5373\n",
            "Epoch 46/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3024 - accuracy: 0.5371 - val_loss: 1.2974 - val_accuracy: 0.5372\n",
            "Epoch 47/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2896 - accuracy: 0.5441 - val_loss: 1.2864 - val_accuracy: 0.5431\n",
            "Epoch 48/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2823 - accuracy: 0.5428 - val_loss: 1.2863 - val_accuracy: 0.5418\n",
            "Epoch 49/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2821 - accuracy: 0.5450 - val_loss: 1.2726 - val_accuracy: 0.5473\n",
            "Epoch 50/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2767 - accuracy: 0.5470 - val_loss: 1.2734 - val_accuracy: 0.5438\n",
            "Epoch 51/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2660 - accuracy: 0.5504 - val_loss: 1.2613 - val_accuracy: 0.5497\n",
            "Epoch 52/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2530 - accuracy: 0.5561 - val_loss: 1.2583 - val_accuracy: 0.5542\n",
            "Epoch 53/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2472 - accuracy: 0.5571 - val_loss: 1.2548 - val_accuracy: 0.5544\n",
            "Epoch 54/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2502 - accuracy: 0.5570 - val_loss: 1.2514 - val_accuracy: 0.5496\n",
            "Epoch 55/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2378 - accuracy: 0.5611 - val_loss: 1.2386 - val_accuracy: 0.5588\n",
            "Epoch 56/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2197 - accuracy: 0.5683 - val_loss: 1.2467 - val_accuracy: 0.5560\n",
            "Epoch 57/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2195 - accuracy: 0.5687 - val_loss: 1.2232 - val_accuracy: 0.5666\n",
            "Epoch 58/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2153 - accuracy: 0.5708 - val_loss: 1.2321 - val_accuracy: 0.5582\n",
            "Epoch 59/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2034 - accuracy: 0.5743 - val_loss: 1.2110 - val_accuracy: 0.5687\n",
            "Epoch 60/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1945 - accuracy: 0.5766 - val_loss: 1.2143 - val_accuracy: 0.5665\n",
            "Epoch 61/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1882 - accuracy: 0.5791 - val_loss: 1.2094 - val_accuracy: 0.5667\n",
            "Epoch 62/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1789 - accuracy: 0.5848 - val_loss: 1.1993 - val_accuracy: 0.5732\n",
            "Epoch 63/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1772 - accuracy: 0.5808 - val_loss: 1.1965 - val_accuracy: 0.5754\n",
            "Epoch 64/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1781 - accuracy: 0.5838 - val_loss: 1.1945 - val_accuracy: 0.5708\n",
            "Epoch 65/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1555 - accuracy: 0.5934 - val_loss: 1.1836 - val_accuracy: 0.5784\n",
            "Epoch 66/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1562 - accuracy: 0.5914 - val_loss: 1.2002 - val_accuracy: 0.5707\n",
            "Epoch 67/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1542 - accuracy: 0.5951 - val_loss: 1.1798 - val_accuracy: 0.5794\n",
            "Epoch 68/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1487 - accuracy: 0.5959 - val_loss: 1.1857 - val_accuracy: 0.5741\n",
            "Epoch 69/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1525 - accuracy: 0.5925 - val_loss: 1.1681 - val_accuracy: 0.5848\n",
            "Epoch 70/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1349 - accuracy: 0.6014 - val_loss: 1.1677 - val_accuracy: 0.5867\n",
            "Epoch 71/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1252 - accuracy: 0.6031 - val_loss: 1.1600 - val_accuracy: 0.5866\n",
            "Epoch 72/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1191 - accuracy: 0.6044 - val_loss: 1.1722 - val_accuracy: 0.5813\n",
            "Epoch 73/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1102 - accuracy: 0.6095 - val_loss: 1.1573 - val_accuracy: 0.5916\n",
            "Epoch 74/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1079 - accuracy: 0.6108 - val_loss: 1.1493 - val_accuracy: 0.5907\n",
            "Epoch 75/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1025 - accuracy: 0.6123 - val_loss: 1.1430 - val_accuracy: 0.5954\n",
            "Epoch 76/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0981 - accuracy: 0.6163 - val_loss: 1.1416 - val_accuracy: 0.5970\n",
            "Epoch 77/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0920 - accuracy: 0.6200 - val_loss: 1.1423 - val_accuracy: 0.6005\n",
            "Epoch 78/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0955 - accuracy: 0.6165 - val_loss: 1.1343 - val_accuracy: 0.5960\n",
            "Epoch 79/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0782 - accuracy: 0.6215 - val_loss: 1.1343 - val_accuracy: 0.5939\n",
            "Epoch 80/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0766 - accuracy: 0.6213 - val_loss: 1.1240 - val_accuracy: 0.6050\n",
            "Epoch 81/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0767 - accuracy: 0.6206 - val_loss: 1.1300 - val_accuracy: 0.5969\n",
            "Epoch 82/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0707 - accuracy: 0.6243 - val_loss: 1.1318 - val_accuracy: 0.5987\n",
            "Epoch 83/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0592 - accuracy: 0.6286 - val_loss: 1.1206 - val_accuracy: 0.6047\n",
            "Epoch 84/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0590 - accuracy: 0.6286 - val_loss: 1.1257 - val_accuracy: 0.6039\n",
            "Epoch 85/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0509 - accuracy: 0.6318 - val_loss: 1.1196 - val_accuracy: 0.6061\n",
            "Epoch 86/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0497 - accuracy: 0.6329 - val_loss: 1.1127 - val_accuracy: 0.6077\n",
            "Epoch 87/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0390 - accuracy: 0.6366 - val_loss: 1.1110 - val_accuracy: 0.6050\n",
            "Epoch 88/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0333 - accuracy: 0.6387 - val_loss: 1.1134 - val_accuracy: 0.6061\n",
            "Epoch 89/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0279 - accuracy: 0.6410 - val_loss: 1.1080 - val_accuracy: 0.6046\n",
            "Epoch 90/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0313 - accuracy: 0.6356 - val_loss: 1.1142 - val_accuracy: 0.6076\n",
            "Epoch 91/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0202 - accuracy: 0.6457 - val_loss: 1.1016 - val_accuracy: 0.6137\n",
            "Epoch 92/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0179 - accuracy: 0.6442 - val_loss: 1.0998 - val_accuracy: 0.6089\n",
            "Epoch 93/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0119 - accuracy: 0.6445 - val_loss: 1.0986 - val_accuracy: 0.6099\n",
            "Epoch 94/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0109 - accuracy: 0.6451 - val_loss: 1.1002 - val_accuracy: 0.6140\n",
            "Epoch 95/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0175 - accuracy: 0.6447 - val_loss: 1.0910 - val_accuracy: 0.6154\n",
            "Epoch 96/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0044 - accuracy: 0.6514 - val_loss: 1.0932 - val_accuracy: 0.6133\n",
            "Epoch 97/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9980 - accuracy: 0.6528 - val_loss: 1.0895 - val_accuracy: 0.6161\n",
            "Epoch 98/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0066 - accuracy: 0.6444 - val_loss: 1.0832 - val_accuracy: 0.6187\n",
            "Epoch 99/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9806 - accuracy: 0.6579 - val_loss: 1.0847 - val_accuracy: 0.6195\n",
            "Epoch 100/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9781 - accuracy: 0.6606 - val_loss: 1.0780 - val_accuracy: 0.6212\n",
            "Epoch 101/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9812 - accuracy: 0.6574 - val_loss: 1.0816 - val_accuracy: 0.6182\n",
            "Epoch 102/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9807 - accuracy: 0.6585 - val_loss: 1.0754 - val_accuracy: 0.6182\n",
            "Epoch 103/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9665 - accuracy: 0.6621 - val_loss: 1.0755 - val_accuracy: 0.6201\n",
            "Epoch 104/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9686 - accuracy: 0.6609 - val_loss: 1.0749 - val_accuracy: 0.6207\n",
            "Epoch 105/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9639 - accuracy: 0.6640 - val_loss: 1.0733 - val_accuracy: 0.6228\n",
            "Epoch 106/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9576 - accuracy: 0.6682 - val_loss: 1.0735 - val_accuracy: 0.6202\n",
            "Epoch 107/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9558 - accuracy: 0.6696 - val_loss: 1.0742 - val_accuracy: 0.6183\n",
            "Epoch 108/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9517 - accuracy: 0.6672 - val_loss: 1.0650 - val_accuracy: 0.6242\n",
            "Epoch 109/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9518 - accuracy: 0.6648 - val_loss: 1.0691 - val_accuracy: 0.6210\n",
            "Epoch 110/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9506 - accuracy: 0.6672 - val_loss: 1.0658 - val_accuracy: 0.6220\n",
            "Epoch 111/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9359 - accuracy: 0.6743 - val_loss: 1.0737 - val_accuracy: 0.6203\n",
            "Epoch 112/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9387 - accuracy: 0.6735 - val_loss: 1.0623 - val_accuracy: 0.6256\n",
            "Epoch 113/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9286 - accuracy: 0.6780 - val_loss: 1.0620 - val_accuracy: 0.6257\n",
            "Epoch 114/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9321 - accuracy: 0.6744 - val_loss: 1.0693 - val_accuracy: 0.6203\n",
            "Epoch 115/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9139 - accuracy: 0.6814 - val_loss: 1.0592 - val_accuracy: 0.6219\n",
            "Epoch 116/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9268 - accuracy: 0.6778 - val_loss: 1.0573 - val_accuracy: 0.6245\n",
            "Epoch 117/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9138 - accuracy: 0.6823 - val_loss: 1.0579 - val_accuracy: 0.6319\n",
            "Epoch 118/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9102 - accuracy: 0.6811 - val_loss: 1.0701 - val_accuracy: 0.6200\n",
            "Epoch 119/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8939 - accuracy: 0.6876 - val_loss: 1.0465 - val_accuracy: 0.6302\n",
            "Epoch 120/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8948 - accuracy: 0.6900 - val_loss: 1.0530 - val_accuracy: 0.6328\n",
            "Epoch 121/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8914 - accuracy: 0.6910 - val_loss: 1.0473 - val_accuracy: 0.6328\n",
            "Epoch 122/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9002 - accuracy: 0.6863 - val_loss: 1.0434 - val_accuracy: 0.6301\n",
            "Epoch 123/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8910 - accuracy: 0.6879 - val_loss: 1.0427 - val_accuracy: 0.6355\n",
            "Epoch 124/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8819 - accuracy: 0.6961 - val_loss: 1.0505 - val_accuracy: 0.6286\n",
            "Epoch 125/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8823 - accuracy: 0.6917 - val_loss: 1.0416 - val_accuracy: 0.6333\n",
            "Epoch 126/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8744 - accuracy: 0.6924 - val_loss: 1.0370 - val_accuracy: 0.6360\n",
            "Epoch 127/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8753 - accuracy: 0.6940 - val_loss: 1.0379 - val_accuracy: 0.6330\n",
            "Epoch 128/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8739 - accuracy: 0.6972 - val_loss: 1.0443 - val_accuracy: 0.6360\n",
            "Epoch 129/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8635 - accuracy: 0.6978 - val_loss: 1.0465 - val_accuracy: 0.6283\n",
            "Epoch 130/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8609 - accuracy: 0.7009 - val_loss: 1.0470 - val_accuracy: 0.6339\n",
            "Epoch 00130: early stopping\n",
            "F1 Score: 0.6339\n",
            "\n",
            "Recreating Sig SGD Model: 1\n",
            "Training version: 2\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 2.3089 - accuracy: 0.1112 - val_loss: 2.2278 - val_accuracy: 0.1759\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 2.1963 - accuracy: 0.1931 - val_loss: 2.0832 - val_accuracy: 0.2559\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 2.0671 - accuracy: 0.2497 - val_loss: 2.0029 - val_accuracy: 0.2845\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.9895 - accuracy: 0.2794 - val_loss: 1.9337 - val_accuracy: 0.3109\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.9459 - accuracy: 0.3006 - val_loss: 1.9004 - val_accuracy: 0.3271\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.9107 - accuracy: 0.3163 - val_loss: 1.8712 - val_accuracy: 0.3436\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.8877 - accuracy: 0.3296 - val_loss: 1.8563 - val_accuracy: 0.3433\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.8578 - accuracy: 0.3424 - val_loss: 1.8272 - val_accuracy: 0.3543\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.8353 - accuracy: 0.3481 - val_loss: 1.8406 - val_accuracy: 0.3403\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.8112 - accuracy: 0.3588 - val_loss: 1.7919 - val_accuracy: 0.3607\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7903 - accuracy: 0.3682 - val_loss: 1.7650 - val_accuracy: 0.3742\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7630 - accuracy: 0.3750 - val_loss: 1.7285 - val_accuracy: 0.3978\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7490 - accuracy: 0.3834 - val_loss: 1.7192 - val_accuracy: 0.3937\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7320 - accuracy: 0.3882 - val_loss: 1.6994 - val_accuracy: 0.3966\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7139 - accuracy: 0.3920 - val_loss: 1.6868 - val_accuracy: 0.4012\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6909 - accuracy: 0.4018 - val_loss: 1.6667 - val_accuracy: 0.4112\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6731 - accuracy: 0.4071 - val_loss: 1.6365 - val_accuracy: 0.4245\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6558 - accuracy: 0.4100 - val_loss: 1.6326 - val_accuracy: 0.4213\n",
            "Epoch 19/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6448 - accuracy: 0.4154 - val_loss: 1.6263 - val_accuracy: 0.4226\n",
            "Epoch 20/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6364 - accuracy: 0.4193 - val_loss: 1.6050 - val_accuracy: 0.4278\n",
            "Epoch 21/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6117 - accuracy: 0.4304 - val_loss: 1.5800 - val_accuracy: 0.4443\n",
            "Epoch 22/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5964 - accuracy: 0.4355 - val_loss: 1.5575 - val_accuracy: 0.4532\n",
            "Epoch 23/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5847 - accuracy: 0.4400 - val_loss: 1.5466 - val_accuracy: 0.4538\n",
            "Epoch 24/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5735 - accuracy: 0.4432 - val_loss: 1.5402 - val_accuracy: 0.4502\n",
            "Epoch 25/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5509 - accuracy: 0.4503 - val_loss: 1.5320 - val_accuracy: 0.4563\n",
            "Epoch 26/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5402 - accuracy: 0.4504 - val_loss: 1.5057 - val_accuracy: 0.4725\n",
            "Epoch 27/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5174 - accuracy: 0.4653 - val_loss: 1.4826 - val_accuracy: 0.4800\n",
            "Epoch 28/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5055 - accuracy: 0.4650 - val_loss: 1.4833 - val_accuracy: 0.4788\n",
            "Epoch 29/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4963 - accuracy: 0.4670 - val_loss: 1.4624 - val_accuracy: 0.4828\n",
            "Epoch 30/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4826 - accuracy: 0.4732 - val_loss: 1.4499 - val_accuracy: 0.4873\n",
            "Epoch 31/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4590 - accuracy: 0.4810 - val_loss: 1.4293 - val_accuracy: 0.4961\n",
            "Epoch 32/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4536 - accuracy: 0.4812 - val_loss: 1.4374 - val_accuracy: 0.4885\n",
            "Epoch 33/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4339 - accuracy: 0.4926 - val_loss: 1.4097 - val_accuracy: 0.4971\n",
            "Epoch 34/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4271 - accuracy: 0.4956 - val_loss: 1.3899 - val_accuracy: 0.5123\n",
            "Epoch 35/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4147 - accuracy: 0.4964 - val_loss: 1.3984 - val_accuracy: 0.5033\n",
            "Epoch 36/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3906 - accuracy: 0.5110 - val_loss: 1.3704 - val_accuracy: 0.5145\n",
            "Epoch 37/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3949 - accuracy: 0.5006 - val_loss: 1.3828 - val_accuracy: 0.5141\n",
            "Epoch 38/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3668 - accuracy: 0.5168 - val_loss: 1.3571 - val_accuracy: 0.5186\n",
            "Epoch 39/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3510 - accuracy: 0.5217 - val_loss: 1.3418 - val_accuracy: 0.5238\n",
            "Epoch 40/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3514 - accuracy: 0.5199 - val_loss: 1.3314 - val_accuracy: 0.5253\n",
            "Epoch 41/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3386 - accuracy: 0.5224 - val_loss: 1.3142 - val_accuracy: 0.5317\n",
            "Epoch 42/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3309 - accuracy: 0.5275 - val_loss: 1.3184 - val_accuracy: 0.5284\n",
            "Epoch 43/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3148 - accuracy: 0.5329 - val_loss: 1.2982 - val_accuracy: 0.5390\n",
            "Epoch 44/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3087 - accuracy: 0.5330 - val_loss: 1.3048 - val_accuracy: 0.5313\n",
            "Epoch 45/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2945 - accuracy: 0.5411 - val_loss: 1.2893 - val_accuracy: 0.5412\n",
            "Epoch 46/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2960 - accuracy: 0.5403 - val_loss: 1.2842 - val_accuracy: 0.5394\n",
            "Epoch 47/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2900 - accuracy: 0.5394 - val_loss: 1.2747 - val_accuracy: 0.5469\n",
            "Epoch 48/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2775 - accuracy: 0.5410 - val_loss: 1.2710 - val_accuracy: 0.5442\n",
            "Epoch 49/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2689 - accuracy: 0.5490 - val_loss: 1.2558 - val_accuracy: 0.5530\n",
            "Epoch 50/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2579 - accuracy: 0.5519 - val_loss: 1.2630 - val_accuracy: 0.5487\n",
            "Epoch 51/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2400 - accuracy: 0.5625 - val_loss: 1.2556 - val_accuracy: 0.5557\n",
            "Epoch 52/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2496 - accuracy: 0.5531 - val_loss: 1.2469 - val_accuracy: 0.5571\n",
            "Epoch 53/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2343 - accuracy: 0.5629 - val_loss: 1.2336 - val_accuracy: 0.5608\n",
            "Epoch 54/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2220 - accuracy: 0.5673 - val_loss: 1.2231 - val_accuracy: 0.5678\n",
            "Epoch 55/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2180 - accuracy: 0.5695 - val_loss: 1.2283 - val_accuracy: 0.5595\n",
            "Epoch 56/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2152 - accuracy: 0.5713 - val_loss: 1.2082 - val_accuracy: 0.5715\n",
            "Epoch 57/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1949 - accuracy: 0.5785 - val_loss: 1.2122 - val_accuracy: 0.5703\n",
            "Epoch 58/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1993 - accuracy: 0.5781 - val_loss: 1.2012 - val_accuracy: 0.5740\n",
            "Epoch 59/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1835 - accuracy: 0.5822 - val_loss: 1.1934 - val_accuracy: 0.5770\n",
            "Epoch 60/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1815 - accuracy: 0.5782 - val_loss: 1.2031 - val_accuracy: 0.5704\n",
            "Epoch 61/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1780 - accuracy: 0.5823 - val_loss: 1.1858 - val_accuracy: 0.5795\n",
            "Epoch 62/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1710 - accuracy: 0.5859 - val_loss: 1.1865 - val_accuracy: 0.5790\n",
            "Epoch 63/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1663 - accuracy: 0.5873 - val_loss: 1.1748 - val_accuracy: 0.5839\n",
            "Epoch 64/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1564 - accuracy: 0.5926 - val_loss: 1.1725 - val_accuracy: 0.5835\n",
            "Epoch 65/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1505 - accuracy: 0.5948 - val_loss: 1.1778 - val_accuracy: 0.5825\n",
            "Epoch 66/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1548 - accuracy: 0.5909 - val_loss: 1.1732 - val_accuracy: 0.5813\n",
            "Epoch 67/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1352 - accuracy: 0.5958 - val_loss: 1.1648 - val_accuracy: 0.5836\n",
            "Epoch 68/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1381 - accuracy: 0.6015 - val_loss: 1.1670 - val_accuracy: 0.5832\n",
            "Epoch 69/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1332 - accuracy: 0.6019 - val_loss: 1.1751 - val_accuracy: 0.5833\n",
            "Epoch 70/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1255 - accuracy: 0.6008 - val_loss: 1.1575 - val_accuracy: 0.5880\n",
            "Epoch 71/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1128 - accuracy: 0.6035 - val_loss: 1.1506 - val_accuracy: 0.5936\n",
            "Epoch 72/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1001 - accuracy: 0.6118 - val_loss: 1.1557 - val_accuracy: 0.5886\n",
            "Epoch 73/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1055 - accuracy: 0.6074 - val_loss: 1.1591 - val_accuracy: 0.5852\n",
            "Epoch 74/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1132 - accuracy: 0.6080 - val_loss: 1.1472 - val_accuracy: 0.5906\n",
            "Epoch 75/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1040 - accuracy: 0.6141 - val_loss: 1.1457 - val_accuracy: 0.5947\n",
            "Epoch 76/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0952 - accuracy: 0.6168 - val_loss: 1.1439 - val_accuracy: 0.5917\n",
            "Epoch 77/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0828 - accuracy: 0.6200 - val_loss: 1.1492 - val_accuracy: 0.5871\n",
            "Epoch 78/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0778 - accuracy: 0.6227 - val_loss: 1.1334 - val_accuracy: 0.5949\n",
            "Epoch 79/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0801 - accuracy: 0.6211 - val_loss: 1.1155 - val_accuracy: 0.6038\n",
            "Epoch 80/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0681 - accuracy: 0.6239 - val_loss: 1.1226 - val_accuracy: 0.6005\n",
            "Epoch 81/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0628 - accuracy: 0.6250 - val_loss: 1.1155 - val_accuracy: 0.6043\n",
            "Epoch 82/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0602 - accuracy: 0.6270 - val_loss: 1.1139 - val_accuracy: 0.6014\n",
            "Epoch 83/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0590 - accuracy: 0.6294 - val_loss: 1.1118 - val_accuracy: 0.6073\n",
            "Epoch 84/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0536 - accuracy: 0.6286 - val_loss: 1.1110 - val_accuracy: 0.6037\n",
            "Epoch 85/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0559 - accuracy: 0.6295 - val_loss: 1.1036 - val_accuracy: 0.6094\n",
            "Epoch 86/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0426 - accuracy: 0.6357 - val_loss: 1.1111 - val_accuracy: 0.6079\n",
            "Epoch 87/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0452 - accuracy: 0.6358 - val_loss: 1.1012 - val_accuracy: 0.6102\n",
            "Epoch 88/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0392 - accuracy: 0.6367 - val_loss: 1.0963 - val_accuracy: 0.6129\n",
            "Epoch 89/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0236 - accuracy: 0.6395 - val_loss: 1.0999 - val_accuracy: 0.6127\n",
            "Epoch 90/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0239 - accuracy: 0.6398 - val_loss: 1.0912 - val_accuracy: 0.6150\n",
            "Epoch 91/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0207 - accuracy: 0.6422 - val_loss: 1.0883 - val_accuracy: 0.6140\n",
            "Epoch 92/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0137 - accuracy: 0.6417 - val_loss: 1.0964 - val_accuracy: 0.6107\n",
            "Epoch 93/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0128 - accuracy: 0.6442 - val_loss: 1.0877 - val_accuracy: 0.6177\n",
            "Epoch 94/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0070 - accuracy: 0.6470 - val_loss: 1.1316 - val_accuracy: 0.5999\n",
            "Epoch 95/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9948 - accuracy: 0.6502 - val_loss: 1.0847 - val_accuracy: 0.6180\n",
            "Epoch 96/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9940 - accuracy: 0.6531 - val_loss: 1.0849 - val_accuracy: 0.6172\n",
            "Epoch 97/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9858 - accuracy: 0.6545 - val_loss: 1.0774 - val_accuracy: 0.6185\n",
            "Epoch 98/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9858 - accuracy: 0.6580 - val_loss: 1.0794 - val_accuracy: 0.6206\n",
            "Epoch 99/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9925 - accuracy: 0.6515 - val_loss: 1.0709 - val_accuracy: 0.6206\n",
            "Epoch 100/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9742 - accuracy: 0.6581 - val_loss: 1.0716 - val_accuracy: 0.6209\n",
            "Epoch 101/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9589 - accuracy: 0.6635 - val_loss: 1.0793 - val_accuracy: 0.6165\n",
            "Epoch 102/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9673 - accuracy: 0.6602 - val_loss: 1.0749 - val_accuracy: 0.6244\n",
            "Epoch 103/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9652 - accuracy: 0.6614 - val_loss: 1.0879 - val_accuracy: 0.6117\n",
            "Epoch 00103: early stopping\n",
            "F1 Score: 0.6117\n",
            "\n",
            "Recreating Sig SGD Model: 1\n",
            "Best Model: 1 for Sig SGD\n",
            "F1 Score: 0.6206\n",
            "Training model: 2 for Sig SGD\n",
            "Training version: 0\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 2.3642 - accuracy: 0.1016 - val_loss: 2.3031 - val_accuracy: 0.1000\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3091 - accuracy: 0.0996 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3054 - accuracy: 0.1006 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3040 - accuracy: 0.0989 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3035 - accuracy: 0.0981 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3035 - accuracy: 0.0968 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3030 - accuracy: 0.1001 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 00007: early stopping\n",
            "F1 Score: 0.10000000000000002\n",
            "\n",
            "Recreating Sig SGD Model: 2\n",
            "Training version: 1\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 2.3617 - accuracy: 0.0982 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3084 - accuracy: 0.0993 - val_loss: 2.3027 - val_accuracy: 0.1048\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3043 - accuracy: 0.1027 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3039 - accuracy: 0.1011 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3037 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3033 - accuracy: 0.1024 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 00006: early stopping\n",
            "F1 Score: 0.10000000000000002\n",
            "\n",
            "Recreating Sig SGD Model: 2\n",
            "Training version: 2\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 2.3678 - accuracy: 0.0998 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3078 - accuracy: 0.1027 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3053 - accuracy: 0.1003 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3044 - accuracy: 0.0946 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3033 - accuracy: 0.0997 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3029 - accuracy: 0.1012 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3032 - accuracy: 0.0986 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3031 - accuracy: 0.1006 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3029 - accuracy: 0.1041 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3028 - accuracy: 0.1020 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 00010: early stopping\n",
            "F1 Score: 0.10000000000000002\n",
            "\n",
            "Recreating Sig SGD Model: 2\n",
            "Best Model: 2 for Sig SGD\n",
            "F1 Score: 0.10000000000000002\n",
            "Training model: 3 for Sig SGD\n",
            "Training version: 0\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 2.3183 - accuracy: 0.2785 - val_loss: 1.6606 - val_accuracy: 0.4271\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 1.5390 - accuracy: 0.4433 - val_loss: 1.5745 - val_accuracy: 0.4658\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3840 - accuracy: 0.5057 - val_loss: 1.3954 - val_accuracy: 0.5343\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2951 - accuracy: 0.5387 - val_loss: 1.3802 - val_accuracy: 0.5235\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 1.2414 - accuracy: 0.5586 - val_loss: 1.2156 - val_accuracy: 0.5843\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 1.1866 - accuracy: 0.5837 - val_loss: 1.3295 - val_accuracy: 0.5582\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1548 - accuracy: 0.5935 - val_loss: 1.2014 - val_accuracy: 0.5967\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 1.1191 - accuracy: 0.6093 - val_loss: 1.0897 - val_accuracy: 0.6329\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0802 - accuracy: 0.6189 - val_loss: 1.1030 - val_accuracy: 0.6265\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0663 - accuracy: 0.6268 - val_loss: 1.2406 - val_accuracy: 0.5988\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0318 - accuracy: 0.6387 - val_loss: 1.0680 - val_accuracy: 0.6385\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0099 - accuracy: 0.6463 - val_loss: 1.1667 - val_accuracy: 0.6166\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0010 - accuracy: 0.6514 - val_loss: 0.9828 - val_accuracy: 0.6685\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.9751 - accuracy: 0.6630 - val_loss: 0.9712 - val_accuracy: 0.6728\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.9468 - accuracy: 0.6708 - val_loss: 1.1946 - val_accuracy: 0.6150\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.9329 - accuracy: 0.6740 - val_loss: 0.9184 - val_accuracy: 0.6988\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9198 - accuracy: 0.6809 - val_loss: 0.8799 - val_accuracy: 0.7061\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8922 - accuracy: 0.6889 - val_loss: 0.8792 - val_accuracy: 0.7083\n",
            "Epoch 19/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8837 - accuracy: 0.6945 - val_loss: 0.9644 - val_accuracy: 0.6873\n",
            "Epoch 20/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.8751 - accuracy: 0.6979 - val_loss: 0.8437 - val_accuracy: 0.7209\n",
            "Epoch 21/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8664 - accuracy: 0.6983 - val_loss: 0.8794 - val_accuracy: 0.7116\n",
            "Epoch 22/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8405 - accuracy: 0.7082 - val_loss: 0.8387 - val_accuracy: 0.7242\n",
            "Epoch 23/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8281 - accuracy: 0.7158 - val_loss: 0.8612 - val_accuracy: 0.7205\n",
            "Epoch 24/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8184 - accuracy: 0.7157 - val_loss: 0.8602 - val_accuracy: 0.7185\n",
            "Epoch 25/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8055 - accuracy: 0.7215 - val_loss: 0.8409 - val_accuracy: 0.7288\n",
            "Epoch 26/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8030 - accuracy: 0.7238 - val_loss: 0.8073 - val_accuracy: 0.7408\n",
            "Epoch 27/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7837 - accuracy: 0.7308 - val_loss: 0.8893 - val_accuracy: 0.7255\n",
            "Epoch 28/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.7775 - accuracy: 0.7336 - val_loss: 0.8880 - val_accuracy: 0.7246\n",
            "Epoch 29/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.7692 - accuracy: 0.7322 - val_loss: 0.9285 - val_accuracy: 0.7159\n",
            "Epoch 30/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7677 - accuracy: 0.7356 - val_loss: 0.7476 - val_accuracy: 0.7591\n",
            "Epoch 31/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7413 - accuracy: 0.7469 - val_loss: 0.7630 - val_accuracy: 0.7554\n",
            "Epoch 32/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.7530 - accuracy: 0.7404 - val_loss: 0.7620 - val_accuracy: 0.7591\n",
            "Epoch 33/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7322 - accuracy: 0.7460 - val_loss: 0.7708 - val_accuracy: 0.7568\n",
            "Epoch 34/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.7329 - accuracy: 0.7474 - val_loss: 0.8535 - val_accuracy: 0.7316\n",
            "Epoch 00034: early stopping\n",
            "F1 Score: 0.7316\n",
            "\n",
            "Recreating Sig SGD Model: 3\n",
            "Training version: 1\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 2.3183 - accuracy: 0.2720 - val_loss: 2.0725 - val_accuracy: 0.3308\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5525 - accuracy: 0.4354 - val_loss: 1.5660 - val_accuracy: 0.4566\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4072 - accuracy: 0.4940 - val_loss: 1.4139 - val_accuracy: 0.5117\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3242 - accuracy: 0.5302 - val_loss: 1.3342 - val_accuracy: 0.5386\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2646 - accuracy: 0.5536 - val_loss: 1.4335 - val_accuracy: 0.5176\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2194 - accuracy: 0.5723 - val_loss: 1.5627 - val_accuracy: 0.4865\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 1.1834 - accuracy: 0.5845 - val_loss: 1.2327 - val_accuracy: 0.5736\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1415 - accuracy: 0.5986 - val_loss: 1.1790 - val_accuracy: 0.6040\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1068 - accuracy: 0.6098 - val_loss: 1.3404 - val_accuracy: 0.5632\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0740 - accuracy: 0.6233 - val_loss: 1.1889 - val_accuracy: 0.5967\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0565 - accuracy: 0.6331 - val_loss: 1.1426 - val_accuracy: 0.6162\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0322 - accuracy: 0.6398 - val_loss: 1.0552 - val_accuracy: 0.6412\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0159 - accuracy: 0.6459 - val_loss: 1.0866 - val_accuracy: 0.6264\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9837 - accuracy: 0.6576 - val_loss: 0.9753 - val_accuracy: 0.6695\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.9664 - accuracy: 0.6596 - val_loss: 0.9403 - val_accuracy: 0.6808\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9557 - accuracy: 0.6682 - val_loss: 0.9864 - val_accuracy: 0.6724\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9410 - accuracy: 0.6722 - val_loss: 1.1191 - val_accuracy: 0.6360\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9188 - accuracy: 0.6779 - val_loss: 0.9586 - val_accuracy: 0.6760\n",
            "Epoch 19/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9109 - accuracy: 0.6844 - val_loss: 0.9759 - val_accuracy: 0.6744\n",
            "Epoch 00019: early stopping\n",
            "F1 Score: 0.6744\n",
            "\n",
            "Recreating Sig SGD Model: 3\n",
            "Training version: 2\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 2.3051 - accuracy: 0.2740 - val_loss: 1.5762 - val_accuracy: 0.4420\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5442 - accuracy: 0.4423 - val_loss: 1.4094 - val_accuracy: 0.5114\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3937 - accuracy: 0.4995 - val_loss: 1.6843 - val_accuracy: 0.4412\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 1.3057 - accuracy: 0.5349 - val_loss: 1.2885 - val_accuracy: 0.5567\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 1.2570 - accuracy: 0.5581 - val_loss: 1.3243 - val_accuracy: 0.5482\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 1.2096 - accuracy: 0.5732 - val_loss: 1.1308 - val_accuracy: 0.6069\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1694 - accuracy: 0.5869 - val_loss: 1.1786 - val_accuracy: 0.5979\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1365 - accuracy: 0.6000 - val_loss: 1.1879 - val_accuracy: 0.5975\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1025 - accuracy: 0.6104 - val_loss: 1.2566 - val_accuracy: 0.5916\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 1.0741 - accuracy: 0.6254 - val_loss: 1.1500 - val_accuracy: 0.6160\n",
            "Epoch 00010: early stopping\n",
            "F1 Score: 0.616\n",
            "\n",
            "Recreating Sig SGD Model: 3\n",
            "Best Model: 3 for Sig SGD\n",
            "F1 Score: 0.6069\n",
            "Training model: 4 for Sig SGD\n",
            "Training version: 0\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.4151 - accuracy: 0.1017 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3136 - accuracy: 0.1020 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3080 - accuracy: 0.1014 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3051 - accuracy: 0.1004 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3053 - accuracy: 0.0989 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3041 - accuracy: 0.0980 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3040 - accuracy: 0.0992 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 00007: early stopping\n",
            "F1 Score: 0.10000000000000002\n",
            "\n",
            "Recreating Sig SGD Model: 4\n",
            "Training version: 1\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.4272 - accuracy: 0.1017 - val_loss: 2.3031 - val_accuracy: 0.1000\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3151 - accuracy: 0.1022 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3069 - accuracy: 0.1043 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3058 - accuracy: 0.1002 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3048 - accuracy: 0.1024 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3042 - accuracy: 0.0982 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 00006: early stopping\n",
            "F1 Score: 0.10000000000000002\n",
            "\n",
            "Recreating Sig SGD Model: 4\n",
            "Training version: 2\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 2.4271 - accuracy: 0.1005 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3151 - accuracy: 0.0982 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3080 - accuracy: 0.1004 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3058 - accuracy: 0.1001 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3045 - accuracy: 0.1019 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3042 - accuracy: 0.0982 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3043 - accuracy: 0.0970 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 00007: early stopping\n",
            "F1 Score: 0.10000000000000002\n",
            "\n",
            "Recreating Sig SGD Model: 4\n",
            "Best Model: 4 for Sig SGD\n",
            "F1 Score: 0.10000000000000002\n",
            "Training model: 5 for Sig SGD\n",
            "Training version: 0\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 6s 3ms/step - loss: 2.3694 - accuracy: 0.0975 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 2.3058 - accuracy: 0.0978 - val_loss: 2.3026 - val_accuracy: 0.1112\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 2.3038 - accuracy: 0.0975 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 2.3031 - accuracy: 0.0996 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 2.3037 - accuracy: 0.0997 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 2.3031 - accuracy: 0.0988 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 00006: early stopping\n",
            "F1 Score: 0.10000000000000002\n",
            "\n",
            "Recreating Sig SGD Model: 5\n",
            "Training version: 1\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 6s 3ms/step - loss: 2.3685 - accuracy: 0.1015 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 2.3054 - accuracy: 0.1008 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 2.3043 - accuracy: 0.0967 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 2.3033 - accuracy: 0.0991 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 2.3034 - accuracy: 0.1009 - val_loss: 2.3025 - val_accuracy: 0.0998\n",
            "Epoch 00005: early stopping\n",
            "F1 Score: 0.0998\n",
            "\n",
            "Recreating Sig SGD Model: 5\n",
            "Training version: 2\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 6s 3ms/step - loss: 2.3638 - accuracy: 0.1011 - val_loss: 2.3029 - val_accuracy: 0.0859\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 2.3048 - accuracy: 0.1023 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 2.3041 - accuracy: 0.0992 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 2.3035 - accuracy: 0.1002 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 2.3033 - accuracy: 0.0975 - val_loss: 2.3026 - val_accuracy: 0.1058\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 2.3034 - accuracy: 0.0979 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 2.3030 - accuracy: 0.0985 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 00007: early stopping\n",
            "F1 Score: 0.10000000000000002\n",
            "\n",
            "Recreating Sig SGD Model: 5\n",
            "Best Model: 5 for Sig SGD\n",
            "F1 Score: 0.1058\n",
            "Training model: 1 for Tanh Adam\n",
            "Training version: 0\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7054 - accuracy: 0.4142 - val_loss: 1.2906 - val_accuracy: 0.5479\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2176 - accuracy: 0.5754 - val_loss: 1.1640 - val_accuracy: 0.5873\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0446 - accuracy: 0.6364 - val_loss: 1.0727 - val_accuracy: 0.6219\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9093 - accuracy: 0.6861 - val_loss: 1.0872 - val_accuracy: 0.6201\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8145 - accuracy: 0.7216 - val_loss: 1.0689 - val_accuracy: 0.6331\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7258 - accuracy: 0.7479 - val_loss: 1.0860 - val_accuracy: 0.6317\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6374 - accuracy: 0.7834 - val_loss: 1.1024 - val_accuracy: 0.6278\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.5729 - accuracy: 0.8084 - val_loss: 1.1599 - val_accuracy: 0.6230\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.5155 - accuracy: 0.8259 - val_loss: 1.1663 - val_accuracy: 0.6260\n",
            "Epoch 00009: early stopping\n",
            "F1 Score: 0.626\n",
            "\n",
            "Recreating Tanh Adam Model: 1\n",
            "Training version: 1\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7277 - accuracy: 0.4093 - val_loss: 1.2694 - val_accuracy: 0.5580\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2124 - accuracy: 0.5737 - val_loss: 1.1580 - val_accuracy: 0.5907\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0377 - accuracy: 0.6405 - val_loss: 1.1491 - val_accuracy: 0.5976\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9177 - accuracy: 0.6820 - val_loss: 1.0753 - val_accuracy: 0.6260\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8116 - accuracy: 0.7202 - val_loss: 1.0764 - val_accuracy: 0.6364\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7265 - accuracy: 0.7503 - val_loss: 1.0895 - val_accuracy: 0.6323\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6382 - accuracy: 0.7825 - val_loss: 1.1149 - val_accuracy: 0.6218\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.5739 - accuracy: 0.8059 - val_loss: 1.1591 - val_accuracy: 0.6210\n",
            "Epoch 00008: early stopping\n",
            "F1 Score: 0.621\n",
            "\n",
            "Recreating Tanh Adam Model: 1\n",
            "Training version: 2\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7114 - accuracy: 0.4147 - val_loss: 1.2734 - val_accuracy: 0.5495\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1985 - accuracy: 0.5784 - val_loss: 1.1788 - val_accuracy: 0.5866\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0306 - accuracy: 0.6426 - val_loss: 1.1189 - val_accuracy: 0.6105\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9080 - accuracy: 0.6876 - val_loss: 1.1050 - val_accuracy: 0.6153\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8096 - accuracy: 0.7219 - val_loss: 1.0957 - val_accuracy: 0.6266\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7131 - accuracy: 0.7547 - val_loss: 1.1229 - val_accuracy: 0.6135\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6395 - accuracy: 0.7839 - val_loss: 1.1123 - val_accuracy: 0.6332\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.5721 - accuracy: 0.8051 - val_loss: 1.1738 - val_accuracy: 0.6173\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.5180 - accuracy: 0.8253 - val_loss: 1.2036 - val_accuracy: 0.6214\n",
            "Epoch 00009: early stopping\n",
            "F1 Score: 0.6214\n",
            "\n",
            "Recreating Tanh Adam Model: 1\n",
            "Best Model: 1 for Tanh Adam\n",
            "F1 Score: 0.6266\n",
            "Training model: 2 for Tanh Adam\n",
            "Training version: 0\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.7284 - accuracy: 0.3822 - val_loss: 1.4225 - val_accuracy: 0.4944\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3271 - accuracy: 0.5307 - val_loss: 1.1415 - val_accuracy: 0.6052\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2343 - accuracy: 0.5678 - val_loss: 1.1519 - val_accuracy: 0.6006\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1887 - accuracy: 0.5816 - val_loss: 1.1535 - val_accuracy: 0.5952\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1701 - accuracy: 0.5890 - val_loss: 1.0952 - val_accuracy: 0.6190\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1525 - accuracy: 0.5963 - val_loss: 1.0712 - val_accuracy: 0.6277\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1332 - accuracy: 0.6032 - val_loss: 1.0503 - val_accuracy: 0.6338\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1348 - accuracy: 0.6049 - val_loss: 1.1127 - val_accuracy: 0.6116\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1037 - accuracy: 0.6128 - val_loss: 1.0301 - val_accuracy: 0.6446\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1105 - accuracy: 0.6096 - val_loss: 1.0065 - val_accuracy: 0.6498\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0960 - accuracy: 0.6201 - val_loss: 1.0490 - val_accuracy: 0.6400\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0833 - accuracy: 0.6215 - val_loss: 1.0416 - val_accuracy: 0.6380\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0744 - accuracy: 0.6237 - val_loss: 0.9782 - val_accuracy: 0.6572\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0597 - accuracy: 0.6276 - val_loss: 1.0033 - val_accuracy: 0.6473\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0653 - accuracy: 0.6277 - val_loss: 0.9713 - val_accuracy: 0.6621\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0609 - accuracy: 0.6289 - val_loss: 0.9689 - val_accuracy: 0.6654\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0612 - accuracy: 0.6272 - val_loss: 0.9916 - val_accuracy: 0.6522\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0646 - accuracy: 0.6299 - val_loss: 0.9891 - val_accuracy: 0.6563\n",
            "Epoch 19/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0418 - accuracy: 0.6360 - val_loss: 0.9896 - val_accuracy: 0.6554\n",
            "Epoch 20/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0433 - accuracy: 0.6353 - val_loss: 0.9392 - val_accuracy: 0.6683\n",
            "Epoch 21/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0309 - accuracy: 0.6373 - val_loss: 1.0459 - val_accuracy: 0.6385\n",
            "Epoch 22/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0296 - accuracy: 0.6381 - val_loss: 0.9609 - val_accuracy: 0.6678\n",
            "Epoch 23/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0317 - accuracy: 0.6372 - val_loss: 0.9429 - val_accuracy: 0.6680\n",
            "Epoch 24/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0233 - accuracy: 0.6443 - val_loss: 0.9408 - val_accuracy: 0.6670\n",
            "Epoch 00024: early stopping\n",
            "F1 Score: 0.667\n",
            "\n",
            "Recreating Tanh Adam Model: 2\n",
            "Training version: 1\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.7324 - accuracy: 0.3741 - val_loss: 1.2902 - val_accuracy: 0.5400\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3317 - accuracy: 0.5313 - val_loss: 1.1816 - val_accuracy: 0.5826\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2359 - accuracy: 0.5701 - val_loss: 1.0883 - val_accuracy: 0.6236\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1989 - accuracy: 0.5819 - val_loss: 1.1212 - val_accuracy: 0.6139\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1679 - accuracy: 0.5903 - val_loss: 1.0808 - val_accuracy: 0.6252\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1574 - accuracy: 0.5947 - val_loss: 1.0557 - val_accuracy: 0.6373\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1269 - accuracy: 0.6051 - val_loss: 1.0985 - val_accuracy: 0.6192\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1143 - accuracy: 0.6091 - val_loss: 1.0724 - val_accuracy: 0.6227\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1125 - accuracy: 0.6103 - val_loss: 1.0689 - val_accuracy: 0.6302\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0968 - accuracy: 0.6158 - val_loss: 1.0506 - val_accuracy: 0.6350\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1026 - accuracy: 0.6107 - val_loss: 1.0266 - val_accuracy: 0.6380\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0897 - accuracy: 0.6213 - val_loss: 0.9646 - val_accuracy: 0.6652\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0765 - accuracy: 0.6252 - val_loss: 1.0612 - val_accuracy: 0.6315\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0697 - accuracy: 0.6242 - val_loss: 1.0769 - val_accuracy: 0.6197\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0651 - accuracy: 0.6259 - val_loss: 1.0258 - val_accuracy: 0.6379\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0642 - accuracy: 0.6289 - val_loss: 1.0216 - val_accuracy: 0.6482\n",
            "Epoch 00016: early stopping\n",
            "F1 Score: 0.6482\n",
            "\n",
            "Recreating Tanh Adam Model: 2\n",
            "Training version: 2\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.7160 - accuracy: 0.3852 - val_loss: 1.3619 - val_accuracy: 0.5298\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3242 - accuracy: 0.5327 - val_loss: 1.4078 - val_accuracy: 0.5018\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2338 - accuracy: 0.5683 - val_loss: 1.1268 - val_accuracy: 0.6055\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1852 - accuracy: 0.5874 - val_loss: 1.0919 - val_accuracy: 0.6201\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1719 - accuracy: 0.5901 - val_loss: 1.1187 - val_accuracy: 0.6116\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1528 - accuracy: 0.5946 - val_loss: 1.1029 - val_accuracy: 0.6083\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1389 - accuracy: 0.6019 - val_loss: 1.0480 - val_accuracy: 0.6361\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1270 - accuracy: 0.6059 - val_loss: 1.0756 - val_accuracy: 0.6211\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1220 - accuracy: 0.6080 - val_loss: 1.0178 - val_accuracy: 0.6542\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1019 - accuracy: 0.6151 - val_loss: 1.0097 - val_accuracy: 0.6465\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0972 - accuracy: 0.6182 - val_loss: 1.0003 - val_accuracy: 0.6502\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0867 - accuracy: 0.6210 - val_loss: 1.0210 - val_accuracy: 0.6452\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0785 - accuracy: 0.6234 - val_loss: 0.9857 - val_accuracy: 0.6539\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0883 - accuracy: 0.6209 - val_loss: 0.9617 - val_accuracy: 0.6668\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0636 - accuracy: 0.6321 - val_loss: 1.0839 - val_accuracy: 0.6251\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0637 - accuracy: 0.6261 - val_loss: 0.9882 - val_accuracy: 0.6611\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0730 - accuracy: 0.6225 - val_loss: 0.9749 - val_accuracy: 0.6628\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0527 - accuracy: 0.6313 - val_loss: 0.9746 - val_accuracy: 0.6602\n",
            "Epoch 00018: early stopping\n",
            "F1 Score: 0.6602\n",
            "\n",
            "Recreating Tanh Adam Model: 2\n",
            "Best Model: 2 for Tanh Adam\n",
            "F1 Score: 0.6668\n",
            "Training model: 3 for Tanh Adam\n",
            "Training version: 0\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 2.3199 - accuracy: 0.2563 - val_loss: 1.8018 - val_accuracy: 0.3425\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5532 - accuracy: 0.4317 - val_loss: 1.4638 - val_accuracy: 0.4932\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3882 - accuracy: 0.5030 - val_loss: 1.3886 - val_accuracy: 0.4947\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3088 - accuracy: 0.5353 - val_loss: 1.1969 - val_accuracy: 0.5754\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2485 - accuracy: 0.5629 - val_loss: 1.3638 - val_accuracy: 0.5227\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2306 - accuracy: 0.5679 - val_loss: 1.4480 - val_accuracy: 0.5084\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2069 - accuracy: 0.5772 - val_loss: 1.4554 - val_accuracy: 0.5122\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1850 - accuracy: 0.5901 - val_loss: 1.3888 - val_accuracy: 0.5091\n",
            "Epoch 00008: early stopping\n",
            "F1 Score: 0.5091\n",
            "\n",
            "Recreating Tanh Adam Model: 3\n",
            "Training version: 1\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 2.2870 - accuracy: 0.2630 - val_loss: 1.5466 - val_accuracy: 0.4423\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5453 - accuracy: 0.4361 - val_loss: 1.3465 - val_accuracy: 0.5102\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4107 - accuracy: 0.4947 - val_loss: 1.3350 - val_accuracy: 0.5174\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3065 - accuracy: 0.5406 - val_loss: 1.6143 - val_accuracy: 0.4519\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2573 - accuracy: 0.5570 - val_loss: 1.1154 - val_accuracy: 0.6078\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2236 - accuracy: 0.5688 - val_loss: 1.2542 - val_accuracy: 0.5534\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1998 - accuracy: 0.5817 - val_loss: 1.2689 - val_accuracy: 0.5502\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1837 - accuracy: 0.5874 - val_loss: 1.1170 - val_accuracy: 0.6086\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1652 - accuracy: 0.5919 - val_loss: 1.1808 - val_accuracy: 0.5828\n",
            "Epoch 00009: early stopping\n",
            "F1 Score: 0.5828\n",
            "\n",
            "Recreating Tanh Adam Model: 3\n",
            "Training version: 2\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 2.3033 - accuracy: 0.2596 - val_loss: 2.3956 - val_accuracy: 0.2206\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5323 - accuracy: 0.4435 - val_loss: 1.5069 - val_accuracy: 0.4551\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3865 - accuracy: 0.5051 - val_loss: 1.3824 - val_accuracy: 0.5170\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3099 - accuracy: 0.5329 - val_loss: 1.3156 - val_accuracy: 0.5273\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2737 - accuracy: 0.5523 - val_loss: 1.4056 - val_accuracy: 0.5035\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2161 - accuracy: 0.5744 - val_loss: 1.1906 - val_accuracy: 0.5787\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1958 - accuracy: 0.5816 - val_loss: 1.2758 - val_accuracy: 0.5594\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1810 - accuracy: 0.5882 - val_loss: 1.2076 - val_accuracy: 0.5758\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1794 - accuracy: 0.5876 - val_loss: 1.4437 - val_accuracy: 0.4940\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1698 - accuracy: 0.5911 - val_loss: 1.2181 - val_accuracy: 0.5681\n",
            "Epoch 00010: early stopping\n",
            "F1 Score: 0.5681\n",
            "\n",
            "Recreating Tanh Adam Model: 3\n",
            "Best Model: 3 for Tanh Adam\n",
            "F1 Score: 0.5787\n",
            "Training model: 4 for Tanh Adam\n",
            "Training version: 0\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.7943 - accuracy: 0.3425 - val_loss: 1.2740 - val_accuracy: 0.5515\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3228 - accuracy: 0.5313 - val_loss: 1.1351 - val_accuracy: 0.6029\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1768 - accuracy: 0.5854 - val_loss: 1.0872 - val_accuracy: 0.6225\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0953 - accuracy: 0.6159 - val_loss: 1.0227 - val_accuracy: 0.6449\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0369 - accuracy: 0.6415 - val_loss: 1.0043 - val_accuracy: 0.6477\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9972 - accuracy: 0.6583 - val_loss: 1.0279 - val_accuracy: 0.6447\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9684 - accuracy: 0.6667 - val_loss: 0.9657 - val_accuracy: 0.6678\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9215 - accuracy: 0.6843 - val_loss: 0.9743 - val_accuracy: 0.6686\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8923 - accuracy: 0.6962 - val_loss: 0.9468 - val_accuracy: 0.6755\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8794 - accuracy: 0.6975 - val_loss: 0.9503 - val_accuracy: 0.6752\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8535 - accuracy: 0.7098 - val_loss: 0.9112 - val_accuracy: 0.6878\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8355 - accuracy: 0.7183 - val_loss: 0.9185 - val_accuracy: 0.6846\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8070 - accuracy: 0.7247 - val_loss: 0.9065 - val_accuracy: 0.6903\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7931 - accuracy: 0.7323 - val_loss: 0.9218 - val_accuracy: 0.6817\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7836 - accuracy: 0.7362 - val_loss: 0.9121 - val_accuracy: 0.6912\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7609 - accuracy: 0.7397 - val_loss: 0.9034 - val_accuracy: 0.6949\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7588 - accuracy: 0.7445 - val_loss: 0.9056 - val_accuracy: 0.6896\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7307 - accuracy: 0.7520 - val_loss: 0.9245 - val_accuracy: 0.6849\n",
            "Epoch 19/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7256 - accuracy: 0.7535 - val_loss: 0.9350 - val_accuracy: 0.6869\n",
            "Epoch 20/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7233 - accuracy: 0.7543 - val_loss: 0.9522 - val_accuracy: 0.6775\n",
            "Epoch 00020: early stopping\n",
            "F1 Score: 0.6775\n",
            "\n",
            "Recreating Tanh Adam Model: 4\n",
            "Training version: 1\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.7795 - accuracy: 0.3459 - val_loss: 1.2698 - val_accuracy: 0.5492\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2927 - accuracy: 0.5452 - val_loss: 1.1397 - val_accuracy: 0.6077\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1786 - accuracy: 0.5885 - val_loss: 1.0706 - val_accuracy: 0.6234\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0948 - accuracy: 0.6216 - val_loss: 1.0448 - val_accuracy: 0.6377\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0314 - accuracy: 0.6428 - val_loss: 1.0203 - val_accuracy: 0.6424\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9898 - accuracy: 0.6570 - val_loss: 0.9896 - val_accuracy: 0.6594\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9586 - accuracy: 0.6706 - val_loss: 0.9577 - val_accuracy: 0.6702\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9186 - accuracy: 0.6842 - val_loss: 1.0072 - val_accuracy: 0.6513\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8940 - accuracy: 0.6941 - val_loss: 0.9684 - val_accuracy: 0.6662\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8741 - accuracy: 0.7001 - val_loss: 0.9651 - val_accuracy: 0.6658\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8447 - accuracy: 0.7108 - val_loss: 0.9401 - val_accuracy: 0.6785\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8371 - accuracy: 0.7178 - val_loss: 0.9612 - val_accuracy: 0.6697\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8093 - accuracy: 0.7234 - val_loss: 0.9304 - val_accuracy: 0.6773\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8012 - accuracy: 0.7278 - val_loss: 0.9190 - val_accuracy: 0.6856\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7835 - accuracy: 0.7335 - val_loss: 0.9312 - val_accuracy: 0.6806\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7680 - accuracy: 0.7376 - val_loss: 0.9432 - val_accuracy: 0.6780\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7508 - accuracy: 0.7447 - val_loss: 0.9544 - val_accuracy: 0.6743\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7355 - accuracy: 0.7495 - val_loss: 0.9428 - val_accuracy: 0.6786\n",
            "Epoch 00018: early stopping\n",
            "F1 Score: 0.6786\n",
            "\n",
            "Recreating Tanh Adam Model: 4\n",
            "Training version: 2\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.7701 - accuracy: 0.3547 - val_loss: 1.2897 - val_accuracy: 0.5389\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2936 - accuracy: 0.5427 - val_loss: 1.1419 - val_accuracy: 0.5989\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1676 - accuracy: 0.5929 - val_loss: 1.1008 - val_accuracy: 0.6054\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0850 - accuracy: 0.6239 - val_loss: 1.0458 - val_accuracy: 0.6399\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0309 - accuracy: 0.6426 - val_loss: 0.9891 - val_accuracy: 0.6578\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9736 - accuracy: 0.6670 - val_loss: 0.9856 - val_accuracy: 0.6618\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9507 - accuracy: 0.6766 - val_loss: 0.9571 - val_accuracy: 0.6743\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9106 - accuracy: 0.6905 - val_loss: 0.9772 - val_accuracy: 0.6623\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8918 - accuracy: 0.6911 - val_loss: 0.9371 - val_accuracy: 0.6762\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8617 - accuracy: 0.7051 - val_loss: 0.9558 - val_accuracy: 0.6712\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8436 - accuracy: 0.7109 - val_loss: 0.9233 - val_accuracy: 0.6876\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8152 - accuracy: 0.7182 - val_loss: 0.9127 - val_accuracy: 0.6904\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8165 - accuracy: 0.7241 - val_loss: 0.9148 - val_accuracy: 0.6883\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7935 - accuracy: 0.7309 - val_loss: 0.9218 - val_accuracy: 0.6865\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7790 - accuracy: 0.7365 - val_loss: 0.9154 - val_accuracy: 0.6890\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7608 - accuracy: 0.7402 - val_loss: 0.9211 - val_accuracy: 0.6884\n",
            "Epoch 00016: early stopping\n",
            "F1 Score: 0.6884\n",
            "\n",
            "Recreating Tanh Adam Model: 4\n",
            "Best Model: 4 for Tanh Adam\n",
            "F1 Score: 0.6904\n",
            "Training model: 5 for Tanh Adam\n",
            "Training version: 0\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 6s 3ms/step - loss: 1.7599 - accuracy: 0.3605 - val_loss: 1.3636 - val_accuracy: 0.5160\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3610 - accuracy: 0.5216 - val_loss: 1.2091 - val_accuracy: 0.5723\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2645 - accuracy: 0.5573 - val_loss: 1.1656 - val_accuracy: 0.5914\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2110 - accuracy: 0.5829 - val_loss: 1.1398 - val_accuracy: 0.5974\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1555 - accuracy: 0.5959 - val_loss: 1.1299 - val_accuracy: 0.6043\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1166 - accuracy: 0.6124 - val_loss: 1.1038 - val_accuracy: 0.6080\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0880 - accuracy: 0.6247 - val_loss: 1.1114 - val_accuracy: 0.6087\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0796 - accuracy: 0.6269 - val_loss: 1.0964 - val_accuracy: 0.6141\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0536 - accuracy: 0.6346 - val_loss: 1.1094 - val_accuracy: 0.6110\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0288 - accuracy: 0.6411 - val_loss: 1.0838 - val_accuracy: 0.6200\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0157 - accuracy: 0.6475 - val_loss: 1.0974 - val_accuracy: 0.6125\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0062 - accuracy: 0.6554 - val_loss: 1.0929 - val_accuracy: 0.6171\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9807 - accuracy: 0.6620 - val_loss: 1.0977 - val_accuracy: 0.6204\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9797 - accuracy: 0.6607 - val_loss: 1.0896 - val_accuracy: 0.6213\n",
            "Epoch 00014: early stopping\n",
            "F1 Score: 0.6213\n",
            "\n",
            "Recreating Tanh Adam Model: 5\n",
            "Training version: 1\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 6s 3ms/step - loss: 1.7589 - accuracy: 0.3686 - val_loss: 1.3560 - val_accuracy: 0.5197\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3697 - accuracy: 0.5160 - val_loss: 1.2557 - val_accuracy: 0.5632\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2659 - accuracy: 0.5568 - val_loss: 1.1610 - val_accuracy: 0.5910\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1990 - accuracy: 0.5814 - val_loss: 1.1291 - val_accuracy: 0.6048\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1636 - accuracy: 0.5953 - val_loss: 1.1423 - val_accuracy: 0.5963\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1266 - accuracy: 0.6077 - val_loss: 1.1052 - val_accuracy: 0.6162\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1072 - accuracy: 0.6148 - val_loss: 1.1139 - val_accuracy: 0.6107\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0835 - accuracy: 0.6239 - val_loss: 1.0988 - val_accuracy: 0.6170\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0626 - accuracy: 0.6315 - val_loss: 1.0932 - val_accuracy: 0.6195\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0370 - accuracy: 0.6431 - val_loss: 1.1224 - val_accuracy: 0.6070\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0183 - accuracy: 0.6482 - val_loss: 1.0867 - val_accuracy: 0.6199\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9986 - accuracy: 0.6525 - val_loss: 1.0890 - val_accuracy: 0.6215\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9874 - accuracy: 0.6601 - val_loss: 1.1135 - val_accuracy: 0.6113\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9790 - accuracy: 0.6589 - val_loss: 1.0876 - val_accuracy: 0.6187\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9611 - accuracy: 0.6651 - val_loss: 1.0756 - val_accuracy: 0.6299\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9420 - accuracy: 0.6737 - val_loss: 1.0785 - val_accuracy: 0.6260\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9475 - accuracy: 0.6747 - val_loss: 1.1024 - val_accuracy: 0.6173\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9309 - accuracy: 0.6811 - val_loss: 1.1114 - val_accuracy: 0.6191\n",
            "Epoch 19/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9020 - accuracy: 0.6910 - val_loss: 1.0947 - val_accuracy: 0.6183\n",
            "Epoch 00019: early stopping\n",
            "F1 Score: 0.6183\n",
            "\n",
            "Recreating Tanh Adam Model: 5\n",
            "Training version: 2\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 6s 3ms/step - loss: 1.7631 - accuracy: 0.3601 - val_loss: 1.3345 - val_accuracy: 0.5313\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3648 - accuracy: 0.5179 - val_loss: 1.2185 - val_accuracy: 0.5734\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2476 - accuracy: 0.5669 - val_loss: 1.1625 - val_accuracy: 0.5906\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1911 - accuracy: 0.5842 - val_loss: 1.1295 - val_accuracy: 0.6071\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1522 - accuracy: 0.6015 - val_loss: 1.1406 - val_accuracy: 0.5966\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1112 - accuracy: 0.6164 - val_loss: 1.1253 - val_accuracy: 0.6013\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0904 - accuracy: 0.6201 - val_loss: 1.1034 - val_accuracy: 0.6179\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0686 - accuracy: 0.6339 - val_loss: 1.0893 - val_accuracy: 0.6232\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0537 - accuracy: 0.6340 - val_loss: 1.1103 - val_accuracy: 0.6124\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0274 - accuracy: 0.6473 - val_loss: 1.1047 - val_accuracy: 0.6137\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0042 - accuracy: 0.6520 - val_loss: 1.0929 - val_accuracy: 0.6199\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9878 - accuracy: 0.6583 - val_loss: 1.0894 - val_accuracy: 0.6178\n",
            "Epoch 00012: early stopping\n",
            "F1 Score: 0.6178\n",
            "\n",
            "Recreating Tanh Adam Model: 5\n",
            "Best Model: 5 for Tanh Adam\n",
            "F1 Score: 0.6232\n",
            "Training model: 1 for Tanh SGD\n",
            "Training version: 0\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.9528 - accuracy: 0.3037 - val_loss: 1.6449 - val_accuracy: 0.4170\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5926 - accuracy: 0.4448 - val_loss: 1.4790 - val_accuracy: 0.4778\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4533 - accuracy: 0.4913 - val_loss: 1.4373 - val_accuracy: 0.4995\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3823 - accuracy: 0.5213 - val_loss: 1.3977 - val_accuracy: 0.5164\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3220 - accuracy: 0.5373 - val_loss: 1.2928 - val_accuracy: 0.5445\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2710 - accuracy: 0.5559 - val_loss: 1.2704 - val_accuracy: 0.5569\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2212 - accuracy: 0.5747 - val_loss: 1.2721 - val_accuracy: 0.5626\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1803 - accuracy: 0.5889 - val_loss: 1.2942 - val_accuracy: 0.5398\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1395 - accuracy: 0.6049 - val_loss: 1.2729 - val_accuracy: 0.5561\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0991 - accuracy: 0.6173 - val_loss: 1.2451 - val_accuracy: 0.5684\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0571 - accuracy: 0.6346 - val_loss: 1.1170 - val_accuracy: 0.6090\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0174 - accuracy: 0.6461 - val_loss: 1.1529 - val_accuracy: 0.5975\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9800 - accuracy: 0.6601 - val_loss: 1.1032 - val_accuracy: 0.6131\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9473 - accuracy: 0.6730 - val_loss: 1.0744 - val_accuracy: 0.6241\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9133 - accuracy: 0.6834 - val_loss: 1.0404 - val_accuracy: 0.6371\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8863 - accuracy: 0.6960 - val_loss: 1.0387 - val_accuracy: 0.6387\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8506 - accuracy: 0.7063 - val_loss: 1.0345 - val_accuracy: 0.6417\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8260 - accuracy: 0.7170 - val_loss: 1.0295 - val_accuracy: 0.6419\n",
            "Epoch 19/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7967 - accuracy: 0.7260 - val_loss: 1.0005 - val_accuracy: 0.6532\n",
            "Epoch 20/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7634 - accuracy: 0.7415 - val_loss: 1.0036 - val_accuracy: 0.6496\n",
            "Epoch 21/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7415 - accuracy: 0.7447 - val_loss: 1.0392 - val_accuracy: 0.6429\n",
            "Epoch 22/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7141 - accuracy: 0.7567 - val_loss: 1.0142 - val_accuracy: 0.6528\n",
            "Epoch 23/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6793 - accuracy: 0.7696 - val_loss: 1.0135 - val_accuracy: 0.6502\n",
            "Epoch 00023: early stopping\n",
            "F1 Score: 0.6502\n",
            "\n",
            "Recreating Tanh SGD Model: 1\n",
            "Training version: 1\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.9468 - accuracy: 0.3001 - val_loss: 1.6250 - val_accuracy: 0.4279\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5875 - accuracy: 0.4441 - val_loss: 1.4664 - val_accuracy: 0.4870\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4577 - accuracy: 0.4932 - val_loss: 1.4728 - val_accuracy: 0.4816\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3717 - accuracy: 0.5224 - val_loss: 1.3370 - val_accuracy: 0.5368\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3115 - accuracy: 0.5427 - val_loss: 1.3508 - val_accuracy: 0.5336\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2655 - accuracy: 0.5589 - val_loss: 1.2899 - val_accuracy: 0.5468\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2175 - accuracy: 0.5780 - val_loss: 1.2514 - val_accuracy: 0.5558\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1702 - accuracy: 0.5938 - val_loss: 1.1910 - val_accuracy: 0.5771\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1280 - accuracy: 0.6069 - val_loss: 1.2192 - val_accuracy: 0.5720\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0851 - accuracy: 0.6245 - val_loss: 1.1505 - val_accuracy: 0.5967\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0410 - accuracy: 0.6416 - val_loss: 1.1138 - val_accuracy: 0.6074\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0076 - accuracy: 0.6505 - val_loss: 1.1293 - val_accuracy: 0.6042\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9732 - accuracy: 0.6634 - val_loss: 1.0895 - val_accuracy: 0.6120\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9438 - accuracy: 0.6724 - val_loss: 1.0886 - val_accuracy: 0.6176\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9070 - accuracy: 0.6851 - val_loss: 1.0362 - val_accuracy: 0.6394\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8870 - accuracy: 0.6958 - val_loss: 1.0353 - val_accuracy: 0.6391\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8472 - accuracy: 0.7118 - val_loss: 1.0440 - val_accuracy: 0.6387\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8113 - accuracy: 0.7210 - val_loss: 1.0149 - val_accuracy: 0.6494\n",
            "Epoch 19/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7938 - accuracy: 0.7281 - val_loss: 1.0389 - val_accuracy: 0.6425\n",
            "Epoch 20/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7655 - accuracy: 0.7395 - val_loss: 1.0203 - val_accuracy: 0.6452\n",
            "Epoch 21/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7394 - accuracy: 0.7452 - val_loss: 1.0174 - val_accuracy: 0.6531\n",
            "Epoch 22/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7140 - accuracy: 0.7567 - val_loss: 1.0234 - val_accuracy: 0.6453\n",
            "Epoch 00022: early stopping\n",
            "F1 Score: 0.6453\n",
            "\n",
            "Recreating Tanh SGD Model: 1\n",
            "Training version: 2\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.9548 - accuracy: 0.3024 - val_loss: 1.6125 - val_accuracy: 0.4437\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5954 - accuracy: 0.4413 - val_loss: 1.6493 - val_accuracy: 0.4241\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4569 - accuracy: 0.4893 - val_loss: 1.5064 - val_accuracy: 0.4784\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3788 - accuracy: 0.5195 - val_loss: 1.3273 - val_accuracy: 0.5377\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3016 - accuracy: 0.5444 - val_loss: 1.4567 - val_accuracy: 0.4932\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2395 - accuracy: 0.5681 - val_loss: 1.2817 - val_accuracy: 0.5544\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1945 - accuracy: 0.5849 - val_loss: 1.2539 - val_accuracy: 0.5623\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1560 - accuracy: 0.5940 - val_loss: 1.2676 - val_accuracy: 0.5698\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0969 - accuracy: 0.6202 - val_loss: 1.1662 - val_accuracy: 0.5851\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0564 - accuracy: 0.6293 - val_loss: 1.1254 - val_accuracy: 0.6030\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0208 - accuracy: 0.6430 - val_loss: 1.1275 - val_accuracy: 0.6063\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9823 - accuracy: 0.6632 - val_loss: 1.0995 - val_accuracy: 0.6141\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9408 - accuracy: 0.6772 - val_loss: 1.0884 - val_accuracy: 0.6228\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9081 - accuracy: 0.6880 - val_loss: 1.0283 - val_accuracy: 0.6444\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8804 - accuracy: 0.6978 - val_loss: 1.0390 - val_accuracy: 0.6350\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8467 - accuracy: 0.7112 - val_loss: 1.0505 - val_accuracy: 0.6317\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8234 - accuracy: 0.7167 - val_loss: 1.0598 - val_accuracy: 0.6275\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7927 - accuracy: 0.7283 - val_loss: 1.0437 - val_accuracy: 0.6361\n",
            "Epoch 00018: early stopping\n",
            "F1 Score: 0.6361\n",
            "\n",
            "Recreating Tanh SGD Model: 1\n",
            "Best Model: 1 for Tanh SGD\n",
            "F1 Score: 0.6444\n",
            "Training model: 2 for Tanh SGD\n",
            "Training version: 0\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 2.0459 - accuracy: 0.2473 - val_loss: 1.7160 - val_accuracy: 0.3677\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6720 - accuracy: 0.3988 - val_loss: 1.7514 - val_accuracy: 0.3624\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5526 - accuracy: 0.4442 - val_loss: 1.4264 - val_accuracy: 0.4895\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.4554 - accuracy: 0.4834 - val_loss: 1.4562 - val_accuracy: 0.4872\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3961 - accuracy: 0.5058 - val_loss: 1.3892 - val_accuracy: 0.5096\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3458 - accuracy: 0.5202 - val_loss: 1.3045 - val_accuracy: 0.5382\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3030 - accuracy: 0.5417 - val_loss: 1.2334 - val_accuracy: 0.5601\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2608 - accuracy: 0.5566 - val_loss: 1.2957 - val_accuracy: 0.5353\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2301 - accuracy: 0.5678 - val_loss: 1.3546 - val_accuracy: 0.5445\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2107 - accuracy: 0.5737 - val_loss: 1.1715 - val_accuracy: 0.5873\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1947 - accuracy: 0.5804 - val_loss: 1.1792 - val_accuracy: 0.5893\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1676 - accuracy: 0.5927 - val_loss: 1.5225 - val_accuracy: 0.4768\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1589 - accuracy: 0.5921 - val_loss: 1.3621 - val_accuracy: 0.5231\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1417 - accuracy: 0.5964 - val_loss: 1.2762 - val_accuracy: 0.5623\n",
            "Epoch 00014: early stopping\n",
            "F1 Score: 0.5623\n",
            "\n",
            "Recreating Tanh SGD Model: 2\n",
            "Training version: 1\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 2.0736 - accuracy: 0.2294 - val_loss: 1.7049 - val_accuracy: 0.3962\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6510 - accuracy: 0.4053 - val_loss: 1.5184 - val_accuracy: 0.4622\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5048 - accuracy: 0.4648 - val_loss: 1.4472 - val_accuracy: 0.4815\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.4413 - accuracy: 0.4913 - val_loss: 1.4069 - val_accuracy: 0.5134\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3829 - accuracy: 0.5101 - val_loss: 1.2849 - val_accuracy: 0.5395\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3242 - accuracy: 0.5305 - val_loss: 1.3545 - val_accuracy: 0.5098\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2896 - accuracy: 0.5439 - val_loss: 1.3095 - val_accuracy: 0.5328\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2613 - accuracy: 0.5528 - val_loss: 1.1823 - val_accuracy: 0.5887\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2380 - accuracy: 0.5630 - val_loss: 1.2213 - val_accuracy: 0.5762\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2069 - accuracy: 0.5724 - val_loss: 1.1672 - val_accuracy: 0.5928\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1849 - accuracy: 0.5808 - val_loss: 1.1512 - val_accuracy: 0.5977\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1766 - accuracy: 0.5875 - val_loss: 1.2583 - val_accuracy: 0.5652\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1614 - accuracy: 0.5920 - val_loss: 1.1893 - val_accuracy: 0.5789\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1384 - accuracy: 0.5978 - val_loss: 1.1132 - val_accuracy: 0.6056\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1241 - accuracy: 0.6054 - val_loss: 1.1548 - val_accuracy: 0.5914\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1090 - accuracy: 0.6087 - val_loss: 1.2154 - val_accuracy: 0.5675\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1014 - accuracy: 0.6120 - val_loss: 1.1019 - val_accuracy: 0.6184\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0856 - accuracy: 0.6185 - val_loss: 1.0849 - val_accuracy: 0.6204\n",
            "Epoch 19/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0923 - accuracy: 0.6182 - val_loss: 1.0100 - val_accuracy: 0.6531\n",
            "Epoch 20/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0795 - accuracy: 0.6247 - val_loss: 1.0447 - val_accuracy: 0.6332\n",
            "Epoch 21/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0622 - accuracy: 0.6271 - val_loss: 1.0181 - val_accuracy: 0.6514\n",
            "Epoch 22/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0589 - accuracy: 0.6292 - val_loss: 1.0760 - val_accuracy: 0.6250\n",
            "Epoch 23/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0403 - accuracy: 0.6316 - val_loss: 1.0701 - val_accuracy: 0.6203\n",
            "Epoch 00023: early stopping\n",
            "F1 Score: 0.6203\n",
            "\n",
            "Recreating Tanh SGD Model: 2\n",
            "Training version: 2\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 2.0737 - accuracy: 0.2389 - val_loss: 1.7495 - val_accuracy: 0.3661\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6409 - accuracy: 0.4125 - val_loss: 1.7392 - val_accuracy: 0.3705\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5103 - accuracy: 0.4636 - val_loss: 1.4785 - val_accuracy: 0.4630\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.4363 - accuracy: 0.4893 - val_loss: 1.4608 - val_accuracy: 0.4852\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3930 - accuracy: 0.5034 - val_loss: 1.3438 - val_accuracy: 0.5119\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3470 - accuracy: 0.5208 - val_loss: 1.2505 - val_accuracy: 0.5495\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2947 - accuracy: 0.5373 - val_loss: 1.2159 - val_accuracy: 0.5681\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2824 - accuracy: 0.5464 - val_loss: 1.2094 - val_accuracy: 0.5743\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2388 - accuracy: 0.5607 - val_loss: 1.2194 - val_accuracy: 0.5643\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.2223 - accuracy: 0.5696 - val_loss: 1.1325 - val_accuracy: 0.6045\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1991 - accuracy: 0.5790 - val_loss: 1.1448 - val_accuracy: 0.5964\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1782 - accuracy: 0.5852 - val_loss: 1.1174 - val_accuracy: 0.6080\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1640 - accuracy: 0.5914 - val_loss: 1.2052 - val_accuracy: 0.5808\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1454 - accuracy: 0.5977 - val_loss: 1.1408 - val_accuracy: 0.6018\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1421 - accuracy: 0.5975 - val_loss: 1.0709 - val_accuracy: 0.6334\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1205 - accuracy: 0.6061 - val_loss: 1.1602 - val_accuracy: 0.5871\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1127 - accuracy: 0.6085 - val_loss: 1.0751 - val_accuracy: 0.6246\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0930 - accuracy: 0.6143 - val_loss: 1.0993 - val_accuracy: 0.6209\n",
            "Epoch 19/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0843 - accuracy: 0.6170 - val_loss: 1.0992 - val_accuracy: 0.6143\n",
            "Epoch 00019: early stopping\n",
            "F1 Score: 0.6143\n",
            "\n",
            "Recreating Tanh SGD Model: 2\n",
            "Best Model: 2 for Tanh SGD\n",
            "F1 Score: 0.6334\n",
            "Training model: 3 for Tanh SGD\n",
            "Training version: 0\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 2.4838 - accuracy: 0.2338 - val_loss: 1.8720 - val_accuracy: 0.3511\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.6360 - accuracy: 0.4012 - val_loss: 1.4681 - val_accuracy: 0.4801\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5089 - accuracy: 0.4544 - val_loss: 1.4328 - val_accuracy: 0.5003\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4408 - accuracy: 0.4822 - val_loss: 1.4275 - val_accuracy: 0.5027\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3741 - accuracy: 0.5098 - val_loss: 1.3448 - val_accuracy: 0.5309\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3115 - accuracy: 0.5340 - val_loss: 1.4811 - val_accuracy: 0.5171\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 1.2613 - accuracy: 0.5536 - val_loss: 1.2711 - val_accuracy: 0.5648\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2087 - accuracy: 0.5701 - val_loss: 1.2998 - val_accuracy: 0.5703\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 1.1730 - accuracy: 0.5854 - val_loss: 1.1405 - val_accuracy: 0.6089\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1421 - accuracy: 0.5963 - val_loss: 1.1982 - val_accuracy: 0.5925\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 1.1185 - accuracy: 0.6062 - val_loss: 1.1098 - val_accuracy: 0.6273\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0925 - accuracy: 0.6161 - val_loss: 1.1431 - val_accuracy: 0.6114\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0636 - accuracy: 0.6312 - val_loss: 1.0370 - val_accuracy: 0.6490\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0398 - accuracy: 0.6378 - val_loss: 1.0842 - val_accuracy: 0.6292\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 1.0053 - accuracy: 0.6522 - val_loss: 0.9951 - val_accuracy: 0.6613\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9863 - accuracy: 0.6571 - val_loss: 0.9559 - val_accuracy: 0.6789\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9693 - accuracy: 0.6637 - val_loss: 1.0164 - val_accuracy: 0.6610\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9444 - accuracy: 0.6700 - val_loss: 0.9208 - val_accuracy: 0.6898\n",
            "Epoch 19/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9425 - accuracy: 0.6755 - val_loss: 1.0501 - val_accuracy: 0.6544\n",
            "Epoch 20/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9176 - accuracy: 0.6842 - val_loss: 0.8857 - val_accuracy: 0.6986\n",
            "Epoch 21/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9002 - accuracy: 0.6892 - val_loss: 0.9286 - val_accuracy: 0.6935\n",
            "Epoch 22/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8891 - accuracy: 0.6905 - val_loss: 0.9147 - val_accuracy: 0.6980\n",
            "Epoch 23/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.8827 - accuracy: 0.6955 - val_loss: 0.8677 - val_accuracy: 0.7133\n",
            "Epoch 24/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8629 - accuracy: 0.7042 - val_loss: 0.8523 - val_accuracy: 0.7150\n",
            "Epoch 25/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8497 - accuracy: 0.7079 - val_loss: 0.9115 - val_accuracy: 0.6985\n",
            "Epoch 26/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8453 - accuracy: 0.7113 - val_loss: 0.8484 - val_accuracy: 0.7191\n",
            "Epoch 27/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8397 - accuracy: 0.7114 - val_loss: 0.8596 - val_accuracy: 0.7199\n",
            "Epoch 28/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8264 - accuracy: 0.7160 - val_loss: 0.9411 - val_accuracy: 0.6955\n",
            "Epoch 29/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8190 - accuracy: 0.7152 - val_loss: 0.8269 - val_accuracy: 0.7247\n",
            "Epoch 30/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8006 - accuracy: 0.7262 - val_loss: 0.8196 - val_accuracy: 0.7269\n",
            "Epoch 31/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7942 - accuracy: 0.7250 - val_loss: 0.7607 - val_accuracy: 0.7513\n",
            "Epoch 32/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7958 - accuracy: 0.7284 - val_loss: 0.9437 - val_accuracy: 0.7060\n",
            "Epoch 33/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7863 - accuracy: 0.7295 - val_loss: 0.7866 - val_accuracy: 0.7438\n",
            "Epoch 34/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.7771 - accuracy: 0.7326 - val_loss: 0.7505 - val_accuracy: 0.7510\n",
            "Epoch 35/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7694 - accuracy: 0.7365 - val_loss: 0.8480 - val_accuracy: 0.7319\n",
            "Epoch 36/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7480 - accuracy: 0.7451 - val_loss: 0.8575 - val_accuracy: 0.7223\n",
            "Epoch 37/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7554 - accuracy: 0.7423 - val_loss: 0.7775 - val_accuracy: 0.7450\n",
            "Epoch 38/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.7306 - accuracy: 0.7488 - val_loss: 0.7973 - val_accuracy: 0.7437\n",
            "Epoch 00038: early stopping\n",
            "F1 Score: 0.7437\n",
            "\n",
            "Recreating Tanh SGD Model: 3\n",
            "Training version: 1\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 2.4603 - accuracy: 0.2444 - val_loss: 1.7288 - val_accuracy: 0.4025\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.6211 - accuracy: 0.4075 - val_loss: 1.4999 - val_accuracy: 0.4745\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4952 - accuracy: 0.4592 - val_loss: 1.4587 - val_accuracy: 0.4872\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4098 - accuracy: 0.4927 - val_loss: 1.4676 - val_accuracy: 0.4985\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3308 - accuracy: 0.5241 - val_loss: 1.2585 - val_accuracy: 0.5640\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2608 - accuracy: 0.5515 - val_loss: 1.2340 - val_accuracy: 0.5719\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2229 - accuracy: 0.5689 - val_loss: 1.2744 - val_accuracy: 0.5628\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1794 - accuracy: 0.5836 - val_loss: 1.1948 - val_accuracy: 0.5932\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1384 - accuracy: 0.5995 - val_loss: 1.1448 - val_accuracy: 0.6127\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1124 - accuracy: 0.6106 - val_loss: 1.0809 - val_accuracy: 0.6322\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0981 - accuracy: 0.6139 - val_loss: 1.0392 - val_accuracy: 0.6456\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0709 - accuracy: 0.6272 - val_loss: 1.0978 - val_accuracy: 0.6295\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0497 - accuracy: 0.6365 - val_loss: 0.9784 - val_accuracy: 0.6709\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0237 - accuracy: 0.6451 - val_loss: 1.0268 - val_accuracy: 0.6547\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 1.0060 - accuracy: 0.6500 - val_loss: 0.9966 - val_accuracy: 0.6718\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9799 - accuracy: 0.6631 - val_loss: 0.9239 - val_accuracy: 0.6859\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9665 - accuracy: 0.6639 - val_loss: 0.9420 - val_accuracy: 0.6779\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9498 - accuracy: 0.6717 - val_loss: 1.1441 - val_accuracy: 0.6184\n",
            "Epoch 19/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.9367 - accuracy: 0.6764 - val_loss: 0.8979 - val_accuracy: 0.6979\n",
            "Epoch 20/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9286 - accuracy: 0.6793 - val_loss: 0.9062 - val_accuracy: 0.6984\n",
            "Epoch 21/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9099 - accuracy: 0.6862 - val_loss: 0.8454 - val_accuracy: 0.7158\n",
            "Epoch 22/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8974 - accuracy: 0.6903 - val_loss: 0.9755 - val_accuracy: 0.6822\n",
            "Epoch 23/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8695 - accuracy: 0.6976 - val_loss: 0.8494 - val_accuracy: 0.7199\n",
            "Epoch 24/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8653 - accuracy: 0.7043 - val_loss: 0.8461 - val_accuracy: 0.7130\n",
            "Epoch 25/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8506 - accuracy: 0.7067 - val_loss: 0.8481 - val_accuracy: 0.7221\n",
            "Epoch 00025: early stopping\n",
            "F1 Score: 0.7221\n",
            "\n",
            "Recreating Tanh SGD Model: 3\n",
            "Training version: 2\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 2.4481 - accuracy: 0.2384 - val_loss: 1.7510 - val_accuracy: 0.3720\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.6273 - accuracy: 0.4042 - val_loss: 1.5507 - val_accuracy: 0.4644\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5000 - accuracy: 0.4547 - val_loss: 1.3711 - val_accuracy: 0.5166\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4115 - accuracy: 0.4897 - val_loss: 1.4331 - val_accuracy: 0.5222\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3493 - accuracy: 0.5172 - val_loss: 1.2986 - val_accuracy: 0.5465\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 1.2844 - accuracy: 0.5420 - val_loss: 1.2121 - val_accuracy: 0.5834\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2180 - accuracy: 0.5684 - val_loss: 1.2894 - val_accuracy: 0.5570\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1887 - accuracy: 0.5815 - val_loss: 1.2689 - val_accuracy: 0.5730\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 1.1510 - accuracy: 0.5931 - val_loss: 1.0530 - val_accuracy: 0.6382\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 1.1243 - accuracy: 0.6059 - val_loss: 1.1719 - val_accuracy: 0.5980\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1066 - accuracy: 0.6102 - val_loss: 1.0263 - val_accuracy: 0.6451\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0675 - accuracy: 0.6245 - val_loss: 1.1273 - val_accuracy: 0.6273\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 1.0484 - accuracy: 0.6338 - val_loss: 1.0591 - val_accuracy: 0.6349\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0229 - accuracy: 0.6443 - val_loss: 1.1039 - val_accuracy: 0.6274\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 1.0087 - accuracy: 0.6506 - val_loss: 0.9544 - val_accuracy: 0.6719\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.9872 - accuracy: 0.6578 - val_loss: 0.9230 - val_accuracy: 0.6840\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.9746 - accuracy: 0.6591 - val_loss: 0.9926 - val_accuracy: 0.6593\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.9392 - accuracy: 0.6731 - val_loss: 0.9556 - val_accuracy: 0.6735\n",
            "Epoch 19/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.9299 - accuracy: 0.6771 - val_loss: 0.9201 - val_accuracy: 0.6900\n",
            "Epoch 20/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.9131 - accuracy: 0.6842 - val_loss: 0.8683 - val_accuracy: 0.7064\n",
            "Epoch 21/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9077 - accuracy: 0.6896 - val_loss: 0.8569 - val_accuracy: 0.7082\n",
            "Epoch 22/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8832 - accuracy: 0.6944 - val_loss: 0.8965 - val_accuracy: 0.6974\n",
            "Epoch 23/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.8781 - accuracy: 0.6945 - val_loss: 0.8680 - val_accuracy: 0.7088\n",
            "Epoch 24/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8736 - accuracy: 0.6981 - val_loss: 0.8626 - val_accuracy: 0.7133\n",
            "Epoch 25/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8577 - accuracy: 0.7024 - val_loss: 0.8669 - val_accuracy: 0.7138\n",
            "Epoch 00025: early stopping\n",
            "F1 Score: 0.7138\n",
            "\n",
            "Recreating Tanh SGD Model: 3\n",
            "Best Model: 3 for Tanh SGD\n",
            "F1 Score: 0.7082\n",
            "Training model: 4 for Tanh SGD\n",
            "Training version: 0\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.1339 - accuracy: 0.2011 - val_loss: 1.7632 - val_accuracy: 0.3758\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.7545 - accuracy: 0.3612 - val_loss: 1.5542 - val_accuracy: 0.4463\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5944 - accuracy: 0.4243 - val_loss: 1.4459 - val_accuracy: 0.4884\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.4832 - accuracy: 0.4617 - val_loss: 1.3819 - val_accuracy: 0.5141\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.4182 - accuracy: 0.4924 - val_loss: 1.3407 - val_accuracy: 0.5160\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3433 - accuracy: 0.5232 - val_loss: 1.2663 - val_accuracy: 0.5426\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2948 - accuracy: 0.5398 - val_loss: 1.1884 - val_accuracy: 0.5739\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2464 - accuracy: 0.5603 - val_loss: 1.2293 - val_accuracy: 0.5574\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2028 - accuracy: 0.5766 - val_loss: 1.1347 - val_accuracy: 0.5948\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1742 - accuracy: 0.5833 - val_loss: 1.0825 - val_accuracy: 0.6159\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1377 - accuracy: 0.6032 - val_loss: 1.0715 - val_accuracy: 0.6195\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1038 - accuracy: 0.6126 - val_loss: 1.0424 - val_accuracy: 0.6322\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0798 - accuracy: 0.6198 - val_loss: 1.2120 - val_accuracy: 0.5751\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0552 - accuracy: 0.6346 - val_loss: 1.0176 - val_accuracy: 0.6481\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0282 - accuracy: 0.6432 - val_loss: 1.0025 - val_accuracy: 0.6472\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0157 - accuracy: 0.6471 - val_loss: 1.0172 - val_accuracy: 0.6440\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9963 - accuracy: 0.6527 - val_loss: 1.0075 - val_accuracy: 0.6455\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9780 - accuracy: 0.6619 - val_loss: 0.9695 - val_accuracy: 0.6643\n",
            "Epoch 19/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9533 - accuracy: 0.6714 - val_loss: 0.9717 - val_accuracy: 0.6561\n",
            "Epoch 20/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9352 - accuracy: 0.6751 - val_loss: 0.9503 - val_accuracy: 0.6649\n",
            "Epoch 21/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9181 - accuracy: 0.6820 - val_loss: 0.9715 - val_accuracy: 0.6630\n",
            "Epoch 22/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9106 - accuracy: 0.6856 - val_loss: 0.9605 - val_accuracy: 0.6636\n",
            "Epoch 23/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8889 - accuracy: 0.6910 - val_loss: 0.9509 - val_accuracy: 0.6694\n",
            "Epoch 24/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8702 - accuracy: 0.6994 - val_loss: 0.9181 - val_accuracy: 0.6803\n",
            "Epoch 25/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8664 - accuracy: 0.7031 - val_loss: 0.9581 - val_accuracy: 0.6695\n",
            "Epoch 26/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8561 - accuracy: 0.7033 - val_loss: 0.9114 - val_accuracy: 0.6838\n",
            "Epoch 27/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8319 - accuracy: 0.7135 - val_loss: 0.9035 - val_accuracy: 0.6842\n",
            "Epoch 28/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8454 - accuracy: 0.7078 - val_loss: 0.9368 - val_accuracy: 0.6775\n",
            "Epoch 29/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8221 - accuracy: 0.7151 - val_loss: 0.9353 - val_accuracy: 0.6750\n",
            "Epoch 30/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8044 - accuracy: 0.7237 - val_loss: 0.9169 - val_accuracy: 0.6802\n",
            "Epoch 31/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7928 - accuracy: 0.7270 - val_loss: 0.9367 - val_accuracy: 0.6803\n",
            "Epoch 00031: early stopping\n",
            "F1 Score: 0.6803\n",
            "\n",
            "Recreating Tanh SGD Model: 4\n",
            "Training version: 1\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.1164 - accuracy: 0.2132 - val_loss: 1.8292 - val_accuracy: 0.3305\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.7505 - accuracy: 0.3632 - val_loss: 1.5700 - val_accuracy: 0.4478\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5923 - accuracy: 0.4245 - val_loss: 1.4561 - val_accuracy: 0.4676\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.4690 - accuracy: 0.4702 - val_loss: 1.3338 - val_accuracy: 0.5216\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3977 - accuracy: 0.4969 - val_loss: 1.2641 - val_accuracy: 0.5473\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3315 - accuracy: 0.5297 - val_loss: 1.2251 - val_accuracy: 0.5656\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2728 - accuracy: 0.5461 - val_loss: 1.1694 - val_accuracy: 0.5841\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2258 - accuracy: 0.5702 - val_loss: 1.1485 - val_accuracy: 0.5927\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1951 - accuracy: 0.5778 - val_loss: 1.1603 - val_accuracy: 0.5792\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1688 - accuracy: 0.5894 - val_loss: 1.1102 - val_accuracy: 0.6060\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1323 - accuracy: 0.6029 - val_loss: 1.0811 - val_accuracy: 0.6208\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1008 - accuracy: 0.6125 - val_loss: 1.0673 - val_accuracy: 0.6242\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0777 - accuracy: 0.6251 - val_loss: 1.0144 - val_accuracy: 0.6460\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0458 - accuracy: 0.6339 - val_loss: 1.0537 - val_accuracy: 0.6312\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0272 - accuracy: 0.6388 - val_loss: 0.9883 - val_accuracy: 0.6548\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0002 - accuracy: 0.6534 - val_loss: 1.0396 - val_accuracy: 0.6322\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9865 - accuracy: 0.6580 - val_loss: 0.9876 - val_accuracy: 0.6548\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9674 - accuracy: 0.6656 - val_loss: 0.9828 - val_accuracy: 0.6552\n",
            "Epoch 19/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9486 - accuracy: 0.6720 - val_loss: 0.9529 - val_accuracy: 0.6697\n",
            "Epoch 20/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9296 - accuracy: 0.6777 - val_loss: 0.9785 - val_accuracy: 0.6577\n",
            "Epoch 21/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9097 - accuracy: 0.6848 - val_loss: 0.9856 - val_accuracy: 0.6600\n",
            "Epoch 22/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9059 - accuracy: 0.6874 - val_loss: 0.9438 - val_accuracy: 0.6704\n",
            "Epoch 23/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8933 - accuracy: 0.6940 - val_loss: 0.9821 - val_accuracy: 0.6599\n",
            "Epoch 24/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8687 - accuracy: 0.7003 - val_loss: 0.9200 - val_accuracy: 0.6843\n",
            "Epoch 25/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8608 - accuracy: 0.7051 - val_loss: 0.9162 - val_accuracy: 0.6812\n",
            "Epoch 26/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8502 - accuracy: 0.7019 - val_loss: 0.9956 - val_accuracy: 0.6535\n",
            "Epoch 27/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8367 - accuracy: 0.7126 - val_loss: 0.9466 - val_accuracy: 0.6728\n",
            "Epoch 28/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8204 - accuracy: 0.7172 - val_loss: 0.8952 - val_accuracy: 0.6899\n",
            "Epoch 29/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8152 - accuracy: 0.7191 - val_loss: 0.9031 - val_accuracy: 0.6827\n",
            "Epoch 30/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7972 - accuracy: 0.7245 - val_loss: 0.9172 - val_accuracy: 0.6823\n",
            "Epoch 31/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7852 - accuracy: 0.7274 - val_loss: 0.9430 - val_accuracy: 0.6717\n",
            "Epoch 32/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7765 - accuracy: 0.7328 - val_loss: 0.8971 - val_accuracy: 0.6873\n",
            "Epoch 00032: early stopping\n",
            "F1 Score: 0.6873\n",
            "\n",
            "Recreating Tanh SGD Model: 4\n",
            "Training version: 2\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.1310 - accuracy: 0.2095 - val_loss: 1.7572 - val_accuracy: 0.3713\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.7508 - accuracy: 0.3631 - val_loss: 1.5530 - val_accuracy: 0.4412\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5782 - accuracy: 0.4276 - val_loss: 1.4222 - val_accuracy: 0.4967\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.4736 - accuracy: 0.4704 - val_loss: 1.3690 - val_accuracy: 0.5019\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.4033 - accuracy: 0.5004 - val_loss: 1.2838 - val_accuracy: 0.5455\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3421 - accuracy: 0.5247 - val_loss: 1.2262 - val_accuracy: 0.5668\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2950 - accuracy: 0.5434 - val_loss: 1.1962 - val_accuracy: 0.5713\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2366 - accuracy: 0.5658 - val_loss: 1.2066 - val_accuracy: 0.5729\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2067 - accuracy: 0.5763 - val_loss: 1.1515 - val_accuracy: 0.5892\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1562 - accuracy: 0.5941 - val_loss: 1.1347 - val_accuracy: 0.5932\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1305 - accuracy: 0.6065 - val_loss: 1.0945 - val_accuracy: 0.6136\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0900 - accuracy: 0.6222 - val_loss: 1.0556 - val_accuracy: 0.6252\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0731 - accuracy: 0.6298 - val_loss: 1.0613 - val_accuracy: 0.6198\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0455 - accuracy: 0.6386 - val_loss: 1.0292 - val_accuracy: 0.6438\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0255 - accuracy: 0.6439 - val_loss: 1.0372 - val_accuracy: 0.6319\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0080 - accuracy: 0.6512 - val_loss: 0.9998 - val_accuracy: 0.6477\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9852 - accuracy: 0.6603 - val_loss: 1.0068 - val_accuracy: 0.6554\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9681 - accuracy: 0.6684 - val_loss: 1.0452 - val_accuracy: 0.6300\n",
            "Epoch 19/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9517 - accuracy: 0.6747 - val_loss: 0.9417 - val_accuracy: 0.6651\n",
            "Epoch 20/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9360 - accuracy: 0.6785 - val_loss: 0.9354 - val_accuracy: 0.6741\n",
            "Epoch 21/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9161 - accuracy: 0.6817 - val_loss: 0.9696 - val_accuracy: 0.6605\n",
            "Epoch 22/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8976 - accuracy: 0.6897 - val_loss: 0.9263 - val_accuracy: 0.6758\n",
            "Epoch 23/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8858 - accuracy: 0.6939 - val_loss: 0.9346 - val_accuracy: 0.6708\n",
            "Epoch 24/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8790 - accuracy: 0.7010 - val_loss: 0.9257 - val_accuracy: 0.6778\n",
            "Epoch 25/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8571 - accuracy: 0.7056 - val_loss: 0.9302 - val_accuracy: 0.6790\n",
            "Epoch 26/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8491 - accuracy: 0.7078 - val_loss: 0.9268 - val_accuracy: 0.6805\n",
            "Epoch 27/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8357 - accuracy: 0.7127 - val_loss: 0.9583 - val_accuracy: 0.6682\n",
            "Epoch 28/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8309 - accuracy: 0.7171 - val_loss: 0.9560 - val_accuracy: 0.6700\n",
            "Epoch 00028: early stopping\n",
            "F1 Score: 0.67\n",
            "\n",
            "Recreating Tanh SGD Model: 4\n",
            "Best Model: 4 for Tanh SGD\n",
            "F1 Score: 0.6778\n",
            "Training model: 5 for Tanh SGD\n",
            "Training version: 0\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 6s 3ms/step - loss: 2.1262 - accuracy: 0.2133 - val_loss: 1.7689 - val_accuracy: 0.3784\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7749 - accuracy: 0.3632 - val_loss: 1.6195 - val_accuracy: 0.4314\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6293 - accuracy: 0.4114 - val_loss: 1.5048 - val_accuracy: 0.4614\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5385 - accuracy: 0.4499 - val_loss: 1.5079 - val_accuracy: 0.4715\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4837 - accuracy: 0.4759 - val_loss: 1.3987 - val_accuracy: 0.5068\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4416 - accuracy: 0.4858 - val_loss: 1.3677 - val_accuracy: 0.5191\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3957 - accuracy: 0.5041 - val_loss: 1.3339 - val_accuracy: 0.5290\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3747 - accuracy: 0.5121 - val_loss: 1.2991 - val_accuracy: 0.5431\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3444 - accuracy: 0.5263 - val_loss: 1.2827 - val_accuracy: 0.5471\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3042 - accuracy: 0.5431 - val_loss: 1.2516 - val_accuracy: 0.5614\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2876 - accuracy: 0.5470 - val_loss: 1.2786 - val_accuracy: 0.5532\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2636 - accuracy: 0.5607 - val_loss: 1.2159 - val_accuracy: 0.5707\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2424 - accuracy: 0.5628 - val_loss: 1.2432 - val_accuracy: 0.5648\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2324 - accuracy: 0.5688 - val_loss: 1.2029 - val_accuracy: 0.5770\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2067 - accuracy: 0.5775 - val_loss: 1.1861 - val_accuracy: 0.5791\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1921 - accuracy: 0.5818 - val_loss: 1.1622 - val_accuracy: 0.5924\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1725 - accuracy: 0.5871 - val_loss: 1.1498 - val_accuracy: 0.5965\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1559 - accuracy: 0.5946 - val_loss: 1.1883 - val_accuracy: 0.5790\n",
            "Epoch 19/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1580 - accuracy: 0.5985 - val_loss: 1.1393 - val_accuracy: 0.6011\n",
            "Epoch 20/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1329 - accuracy: 0.6050 - val_loss: 1.1224 - val_accuracy: 0.6077\n",
            "Epoch 21/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1301 - accuracy: 0.6024 - val_loss: 1.1518 - val_accuracy: 0.5940\n",
            "Epoch 22/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1143 - accuracy: 0.6090 - val_loss: 1.1156 - val_accuracy: 0.6090\n",
            "Epoch 23/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0978 - accuracy: 0.6145 - val_loss: 1.1264 - val_accuracy: 0.6030\n",
            "Epoch 24/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0924 - accuracy: 0.6190 - val_loss: 1.1085 - val_accuracy: 0.6107\n",
            "Epoch 25/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0771 - accuracy: 0.6276 - val_loss: 1.1045 - val_accuracy: 0.6119\n",
            "Epoch 26/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0784 - accuracy: 0.6210 - val_loss: 1.1423 - val_accuracy: 0.6010\n",
            "Epoch 27/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0581 - accuracy: 0.6325 - val_loss: 1.1022 - val_accuracy: 0.6119\n",
            "Epoch 28/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0528 - accuracy: 0.6324 - val_loss: 1.0945 - val_accuracy: 0.6175\n",
            "Epoch 29/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0413 - accuracy: 0.6377 - val_loss: 1.0938 - val_accuracy: 0.6122\n",
            "Epoch 30/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0374 - accuracy: 0.6355 - val_loss: 1.1291 - val_accuracy: 0.6049\n",
            "Epoch 31/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0321 - accuracy: 0.6401 - val_loss: 1.0855 - val_accuracy: 0.6167\n",
            "Epoch 32/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0214 - accuracy: 0.6436 - val_loss: 1.0892 - val_accuracy: 0.6173\n",
            "Epoch 33/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0139 - accuracy: 0.6459 - val_loss: 1.0745 - val_accuracy: 0.6225\n",
            "Epoch 34/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9986 - accuracy: 0.6524 - val_loss: 1.0639 - val_accuracy: 0.6252\n",
            "Epoch 35/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9985 - accuracy: 0.6537 - val_loss: 1.0732 - val_accuracy: 0.6231\n",
            "Epoch 36/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9830 - accuracy: 0.6583 - val_loss: 1.0584 - val_accuracy: 0.6282\n",
            "Epoch 37/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9723 - accuracy: 0.6615 - val_loss: 1.0606 - val_accuracy: 0.6301\n",
            "Epoch 38/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9747 - accuracy: 0.6642 - val_loss: 1.0533 - val_accuracy: 0.6285\n",
            "Epoch 39/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9672 - accuracy: 0.6635 - val_loss: 1.0574 - val_accuracy: 0.6311\n",
            "Epoch 40/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9656 - accuracy: 0.6636 - val_loss: 1.0797 - val_accuracy: 0.6269\n",
            "Epoch 41/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9498 - accuracy: 0.6721 - val_loss: 1.0721 - val_accuracy: 0.6301\n",
            "Epoch 42/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9517 - accuracy: 0.6719 - val_loss: 1.0544 - val_accuracy: 0.6343\n",
            "Epoch 00042: early stopping\n",
            "F1 Score: 0.6343\n",
            "\n",
            "Recreating Tanh SGD Model: 5\n",
            "Training version: 1\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 6s 3ms/step - loss: 2.1313 - accuracy: 0.2126 - val_loss: 1.8498 - val_accuracy: 0.3449\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7863 - accuracy: 0.3598 - val_loss: 1.6019 - val_accuracy: 0.4424\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6454 - accuracy: 0.4092 - val_loss: 1.5069 - val_accuracy: 0.4696\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5488 - accuracy: 0.4453 - val_loss: 1.4501 - val_accuracy: 0.4877\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4933 - accuracy: 0.4661 - val_loss: 1.4068 - val_accuracy: 0.5010\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4493 - accuracy: 0.4830 - val_loss: 1.3599 - val_accuracy: 0.5223\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4035 - accuracy: 0.5004 - val_loss: 1.3399 - val_accuracy: 0.5231\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3746 - accuracy: 0.5132 - val_loss: 1.3127 - val_accuracy: 0.5339\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3420 - accuracy: 0.5271 - val_loss: 1.2832 - val_accuracy: 0.5434\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3138 - accuracy: 0.5357 - val_loss: 1.2545 - val_accuracy: 0.5580\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2956 - accuracy: 0.5454 - val_loss: 1.2447 - val_accuracy: 0.5580\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2657 - accuracy: 0.5548 - val_loss: 1.2250 - val_accuracy: 0.5662\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2481 - accuracy: 0.5616 - val_loss: 1.2035 - val_accuracy: 0.5788\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2307 - accuracy: 0.5673 - val_loss: 1.1812 - val_accuracy: 0.5880\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2095 - accuracy: 0.5753 - val_loss: 1.1834 - val_accuracy: 0.5861\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1924 - accuracy: 0.5818 - val_loss: 1.1705 - val_accuracy: 0.5904\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1820 - accuracy: 0.5902 - val_loss: 1.1491 - val_accuracy: 0.5994\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1681 - accuracy: 0.5908 - val_loss: 1.1740 - val_accuracy: 0.5932\n",
            "Epoch 19/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1548 - accuracy: 0.5946 - val_loss: 1.1390 - val_accuracy: 0.6006\n",
            "Epoch 20/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1525 - accuracy: 0.5978 - val_loss: 1.1314 - val_accuracy: 0.6092\n",
            "Epoch 21/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1292 - accuracy: 0.6048 - val_loss: 1.1368 - val_accuracy: 0.6046\n",
            "Epoch 22/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1111 - accuracy: 0.6127 - val_loss: 1.1205 - val_accuracy: 0.6095\n",
            "Epoch 23/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1191 - accuracy: 0.6077 - val_loss: 1.1209 - val_accuracy: 0.6073\n",
            "Epoch 24/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0931 - accuracy: 0.6194 - val_loss: 1.1194 - val_accuracy: 0.6113\n",
            "Epoch 25/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0830 - accuracy: 0.6236 - val_loss: 1.1068 - val_accuracy: 0.6128\n",
            "Epoch 26/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0807 - accuracy: 0.6220 - val_loss: 1.0930 - val_accuracy: 0.6154\n",
            "Epoch 27/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0755 - accuracy: 0.6263 - val_loss: 1.1048 - val_accuracy: 0.6123\n",
            "Epoch 28/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0502 - accuracy: 0.6344 - val_loss: 1.1085 - val_accuracy: 0.6147\n",
            "Epoch 29/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0605 - accuracy: 0.6311 - val_loss: 1.0848 - val_accuracy: 0.6197\n",
            "Epoch 30/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0420 - accuracy: 0.6388 - val_loss: 1.1034 - val_accuracy: 0.6168\n",
            "Epoch 31/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0304 - accuracy: 0.6412 - val_loss: 1.0791 - val_accuracy: 0.6256\n",
            "Epoch 32/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0300 - accuracy: 0.6424 - val_loss: 1.0984 - val_accuracy: 0.6187\n",
            "Epoch 33/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0209 - accuracy: 0.6457 - val_loss: 1.0847 - val_accuracy: 0.6194\n",
            "Epoch 34/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0236 - accuracy: 0.6447 - val_loss: 1.0857 - val_accuracy: 0.6230\n",
            "Epoch 35/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0101 - accuracy: 0.6453 - val_loss: 1.0886 - val_accuracy: 0.6210\n",
            "Epoch 00035: early stopping\n",
            "F1 Score: 0.621\n",
            "\n",
            "Recreating Tanh SGD Model: 5\n",
            "Training version: 2\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 6s 3ms/step - loss: 2.1556 - accuracy: 0.2026 - val_loss: 1.8098 - val_accuracy: 0.3639\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7879 - accuracy: 0.3609 - val_loss: 1.6364 - val_accuracy: 0.4242\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6487 - accuracy: 0.4144 - val_loss: 1.5135 - val_accuracy: 0.4672\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5583 - accuracy: 0.4452 - val_loss: 1.4833 - val_accuracy: 0.4679\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4906 - accuracy: 0.4671 - val_loss: 1.4030 - val_accuracy: 0.5040\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4513 - accuracy: 0.4864 - val_loss: 1.3572 - val_accuracy: 0.5199\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4026 - accuracy: 0.5007 - val_loss: 1.3265 - val_accuracy: 0.5343\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3696 - accuracy: 0.5148 - val_loss: 1.2916 - val_accuracy: 0.5443\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3463 - accuracy: 0.5254 - val_loss: 1.2972 - val_accuracy: 0.5497\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3081 - accuracy: 0.5393 - val_loss: 1.2509 - val_accuracy: 0.5601\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2944 - accuracy: 0.5473 - val_loss: 1.2302 - val_accuracy: 0.5675\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2686 - accuracy: 0.5579 - val_loss: 1.2202 - val_accuracy: 0.5737\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2464 - accuracy: 0.5644 - val_loss: 1.2059 - val_accuracy: 0.5725\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2290 - accuracy: 0.5691 - val_loss: 1.2015 - val_accuracy: 0.5748\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2139 - accuracy: 0.5742 - val_loss: 1.2147 - val_accuracy: 0.5759\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2112 - accuracy: 0.5753 - val_loss: 1.1742 - val_accuracy: 0.5893\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1879 - accuracy: 0.5851 - val_loss: 1.1627 - val_accuracy: 0.5946\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1671 - accuracy: 0.5927 - val_loss: 1.1557 - val_accuracy: 0.5953\n",
            "Epoch 19/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1607 - accuracy: 0.5950 - val_loss: 1.1854 - val_accuracy: 0.5841\n",
            "Epoch 20/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1467 - accuracy: 0.5980 - val_loss: 1.1493 - val_accuracy: 0.5914\n",
            "Epoch 21/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1355 - accuracy: 0.6022 - val_loss: 1.1337 - val_accuracy: 0.6016\n",
            "Epoch 22/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1302 - accuracy: 0.6061 - val_loss: 1.1448 - val_accuracy: 0.5898\n",
            "Epoch 23/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1215 - accuracy: 0.6074 - val_loss: 1.1163 - val_accuracy: 0.6129\n",
            "Epoch 24/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0927 - accuracy: 0.6194 - val_loss: 1.1210 - val_accuracy: 0.6058\n",
            "Epoch 25/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0902 - accuracy: 0.6221 - val_loss: 1.1127 - val_accuracy: 0.6121\n",
            "Epoch 26/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0816 - accuracy: 0.6222 - val_loss: 1.1051 - val_accuracy: 0.6165\n",
            "Epoch 27/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0744 - accuracy: 0.6266 - val_loss: 1.0967 - val_accuracy: 0.6124\n",
            "Epoch 28/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0626 - accuracy: 0.6298 - val_loss: 1.1179 - val_accuracy: 0.6051\n",
            "Epoch 29/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0535 - accuracy: 0.6311 - val_loss: 1.0980 - val_accuracy: 0.6129\n",
            "Epoch 30/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0437 - accuracy: 0.6373 - val_loss: 1.0992 - val_accuracy: 0.6139\n",
            "Epoch 31/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0378 - accuracy: 0.6412 - val_loss: 1.0883 - val_accuracy: 0.6175\n",
            "Epoch 32/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0276 - accuracy: 0.6426 - val_loss: 1.0995 - val_accuracy: 0.6117\n",
            "Epoch 33/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0252 - accuracy: 0.6434 - val_loss: 1.0769 - val_accuracy: 0.6196\n",
            "Epoch 34/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0264 - accuracy: 0.6455 - val_loss: 1.0927 - val_accuracy: 0.6174\n",
            "Epoch 35/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0017 - accuracy: 0.6509 - val_loss: 1.1020 - val_accuracy: 0.6092\n",
            "Epoch 36/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9962 - accuracy: 0.6563 - val_loss: 1.0845 - val_accuracy: 0.6204\n",
            "Epoch 37/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9894 - accuracy: 0.6579 - val_loss: 1.0718 - val_accuracy: 0.6204\n",
            "Epoch 38/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9814 - accuracy: 0.6601 - val_loss: 1.0664 - val_accuracy: 0.6276\n",
            "Epoch 39/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9816 - accuracy: 0.6612 - val_loss: 1.0763 - val_accuracy: 0.6228\n",
            "Epoch 40/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9757 - accuracy: 0.6628 - val_loss: 1.0720 - val_accuracy: 0.6260\n",
            "Epoch 41/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9667 - accuracy: 0.6648 - val_loss: 1.0637 - val_accuracy: 0.6312\n",
            "Epoch 42/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9652 - accuracy: 0.6686 - val_loss: 1.0817 - val_accuracy: 0.6172\n",
            "Epoch 43/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9543 - accuracy: 0.6710 - val_loss: 1.0817 - val_accuracy: 0.6224\n",
            "Epoch 44/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9554 - accuracy: 0.6669 - val_loss: 1.0800 - val_accuracy: 0.6230\n",
            "Epoch 45/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9394 - accuracy: 0.6762 - val_loss: 1.0704 - val_accuracy: 0.6250\n",
            "Epoch 00045: early stopping\n",
            "F1 Score: 0.625\n",
            "\n",
            "Recreating Tanh SGD Model: 5\n",
            "Best Model: 5 for Tanh SGD\n",
            "F1 Score: 0.6312\n",
            "Training model: 1 for Relu SGD\n",
            "Training version: 0\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 2.0380 - accuracy: 0.2551 - val_loss: 1.6471 - val_accuracy: 0.4138\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6048 - accuracy: 0.4351 - val_loss: 1.4142 - val_accuracy: 0.4994\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4068 - accuracy: 0.5029 - val_loss: 1.3106 - val_accuracy: 0.5336\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3068 - accuracy: 0.5400 - val_loss: 1.2538 - val_accuracy: 0.5583\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2400 - accuracy: 0.5674 - val_loss: 1.2094 - val_accuracy: 0.5746\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1847 - accuracy: 0.5821 - val_loss: 1.1779 - val_accuracy: 0.5825\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1399 - accuracy: 0.6001 - val_loss: 1.1453 - val_accuracy: 0.5990\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0989 - accuracy: 0.6149 - val_loss: 1.1200 - val_accuracy: 0.6063\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0551 - accuracy: 0.6302 - val_loss: 1.2436 - val_accuracy: 0.5713\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0286 - accuracy: 0.6411 - val_loss: 1.1250 - val_accuracy: 0.6023\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9930 - accuracy: 0.6524 - val_loss: 1.0719 - val_accuracy: 0.6254\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9676 - accuracy: 0.6618 - val_loss: 1.0744 - val_accuracy: 0.6283\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9185 - accuracy: 0.6802 - val_loss: 1.0872 - val_accuracy: 0.6196\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8894 - accuracy: 0.6865 - val_loss: 1.0107 - val_accuracy: 0.6481\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8547 - accuracy: 0.7044 - val_loss: 1.0344 - val_accuracy: 0.6420\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8263 - accuracy: 0.7106 - val_loss: 1.0042 - val_accuracy: 0.6514\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7913 - accuracy: 0.7254 - val_loss: 0.9932 - val_accuracy: 0.6594\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7557 - accuracy: 0.7370 - val_loss: 1.0886 - val_accuracy: 0.6263\n",
            "Epoch 19/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7350 - accuracy: 0.7462 - val_loss: 1.0167 - val_accuracy: 0.6486\n",
            "Epoch 20/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6968 - accuracy: 0.7584 - val_loss: 1.0019 - val_accuracy: 0.6596\n",
            "Epoch 21/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6788 - accuracy: 0.7633 - val_loss: 1.0350 - val_accuracy: 0.6483\n",
            "Epoch 00021: early stopping\n",
            "F1 Score: 0.6483\n",
            "\n",
            "Recreating Relu SGD Model: 1\n",
            "Training version: 1\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 2.0248 - accuracy: 0.2626 - val_loss: 1.6636 - val_accuracy: 0.4041\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5788 - accuracy: 0.4411 - val_loss: 1.4111 - val_accuracy: 0.5092\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3927 - accuracy: 0.5103 - val_loss: 1.3205 - val_accuracy: 0.5417\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2943 - accuracy: 0.5460 - val_loss: 1.2802 - val_accuracy: 0.5489\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2248 - accuracy: 0.5690 - val_loss: 1.2062 - val_accuracy: 0.5792\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1618 - accuracy: 0.5945 - val_loss: 1.1869 - val_accuracy: 0.5798\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1164 - accuracy: 0.6096 - val_loss: 1.1673 - val_accuracy: 0.5888\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0835 - accuracy: 0.6228 - val_loss: 1.1050 - val_accuracy: 0.6134\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0381 - accuracy: 0.6364 - val_loss: 1.1612 - val_accuracy: 0.5966\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0002 - accuracy: 0.6504 - val_loss: 1.0907 - val_accuracy: 0.6174\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9837 - accuracy: 0.6577 - val_loss: 1.0699 - val_accuracy: 0.6248\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9378 - accuracy: 0.6727 - val_loss: 1.0296 - val_accuracy: 0.6414\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9024 - accuracy: 0.6880 - val_loss: 1.0123 - val_accuracy: 0.6502\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8729 - accuracy: 0.6982 - val_loss: 1.0002 - val_accuracy: 0.6501\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8464 - accuracy: 0.7053 - val_loss: 1.0054 - val_accuracy: 0.6482\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8092 - accuracy: 0.7165 - val_loss: 1.0048 - val_accuracy: 0.6525\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7799 - accuracy: 0.7252 - val_loss: 1.0472 - val_accuracy: 0.6362\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7635 - accuracy: 0.7357 - val_loss: 0.9776 - val_accuracy: 0.6687\n",
            "Epoch 19/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7274 - accuracy: 0.7466 - val_loss: 0.9702 - val_accuracy: 0.6664\n",
            "Epoch 20/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6927 - accuracy: 0.7632 - val_loss: 0.9937 - val_accuracy: 0.6564\n",
            "Epoch 21/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6711 - accuracy: 0.7704 - val_loss: 0.9648 - val_accuracy: 0.6741\n",
            "Epoch 22/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6434 - accuracy: 0.7778 - val_loss: 0.9833 - val_accuracy: 0.6706\n",
            "Epoch 23/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6152 - accuracy: 0.7865 - val_loss: 0.9747 - val_accuracy: 0.6693\n",
            "Epoch 24/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.5902 - accuracy: 0.7947 - val_loss: 1.0034 - val_accuracy: 0.6665\n",
            "Epoch 25/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.5654 - accuracy: 0.8057 - val_loss: 0.9766 - val_accuracy: 0.6732\n",
            "Epoch 00025: early stopping\n",
            "F1 Score: 0.6732\n",
            "\n",
            "Recreating Relu SGD Model: 1\n",
            "Training version: 2\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 2.0437 - accuracy: 0.2546 - val_loss: 1.6287 - val_accuracy: 0.4178\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5991 - accuracy: 0.4355 - val_loss: 1.4253 - val_accuracy: 0.5011\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4022 - accuracy: 0.5078 - val_loss: 1.3315 - val_accuracy: 0.5282\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2964 - accuracy: 0.5438 - val_loss: 1.2553 - val_accuracy: 0.5540\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2259 - accuracy: 0.5723 - val_loss: 1.2037 - val_accuracy: 0.5781\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1697 - accuracy: 0.5912 - val_loss: 1.2240 - val_accuracy: 0.5653\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1323 - accuracy: 0.6035 - val_loss: 1.1780 - val_accuracy: 0.5922\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0851 - accuracy: 0.6199 - val_loss: 1.1115 - val_accuracy: 0.6048\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0387 - accuracy: 0.6398 - val_loss: 1.1348 - val_accuracy: 0.5961\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0075 - accuracy: 0.6496 - val_loss: 1.0941 - val_accuracy: 0.6184\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9741 - accuracy: 0.6611 - val_loss: 1.0321 - val_accuracy: 0.6383\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9351 - accuracy: 0.6730 - val_loss: 1.0877 - val_accuracy: 0.6242\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9014 - accuracy: 0.6853 - val_loss: 1.0726 - val_accuracy: 0.6235\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8717 - accuracy: 0.6961 - val_loss: 1.0037 - val_accuracy: 0.6489\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8462 - accuracy: 0.7089 - val_loss: 1.0301 - val_accuracy: 0.6479\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8127 - accuracy: 0.7203 - val_loss: 0.9906 - val_accuracy: 0.6553\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7914 - accuracy: 0.7254 - val_loss: 0.9703 - val_accuracy: 0.6629\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7600 - accuracy: 0.7358 - val_loss: 0.9745 - val_accuracy: 0.6601\n",
            "Epoch 19/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7334 - accuracy: 0.7443 - val_loss: 0.9822 - val_accuracy: 0.6607\n",
            "Epoch 20/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7108 - accuracy: 0.7519 - val_loss: 0.9976 - val_accuracy: 0.6568\n",
            "Epoch 21/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6782 - accuracy: 0.7653 - val_loss: 0.9888 - val_accuracy: 0.6651\n",
            "Epoch 00021: early stopping\n",
            "F1 Score: 0.6651\n",
            "\n",
            "Recreating Relu SGD Model: 1\n",
            "Best Model: 1 for Relu SGD\n",
            "F1 Score: 0.6629\n",
            "Training model: 2 for Relu SGD\n",
            "Training version: 0\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 2.2510 - accuracy: 0.1421 - val_loss: 1.9713 - val_accuracy: 0.2894\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.9513 - accuracy: 0.2769 - val_loss: 1.7929 - val_accuracy: 0.3590\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.7498 - accuracy: 0.3561 - val_loss: 1.6213 - val_accuracy: 0.4066\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6115 - accuracy: 0.4085 - val_loss: 1.4627 - val_accuracy: 0.4667\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5024 - accuracy: 0.4552 - val_loss: 1.3786 - val_accuracy: 0.5010\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.4464 - accuracy: 0.4755 - val_loss: 1.3934 - val_accuracy: 0.4913\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3945 - accuracy: 0.4980 - val_loss: 1.2959 - val_accuracy: 0.5405\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3544 - accuracy: 0.5079 - val_loss: 1.2642 - val_accuracy: 0.5457\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3091 - accuracy: 0.5319 - val_loss: 1.2041 - val_accuracy: 0.5729\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2728 - accuracy: 0.5448 - val_loss: 1.1775 - val_accuracy: 0.5834\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2381 - accuracy: 0.5564 - val_loss: 1.1258 - val_accuracy: 0.5976\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2016 - accuracy: 0.5728 - val_loss: 1.1748 - val_accuracy: 0.5889\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1703 - accuracy: 0.5844 - val_loss: 1.1179 - val_accuracy: 0.6037\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1523 - accuracy: 0.5897 - val_loss: 1.1274 - val_accuracy: 0.6083\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1226 - accuracy: 0.5990 - val_loss: 1.0081 - val_accuracy: 0.6431\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1051 - accuracy: 0.6090 - val_loss: 1.0176 - val_accuracy: 0.6452\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0890 - accuracy: 0.6122 - val_loss: 0.9617 - val_accuracy: 0.6617\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0644 - accuracy: 0.6219 - val_loss: 0.9856 - val_accuracy: 0.6521\n",
            "Epoch 19/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0275 - accuracy: 0.6362 - val_loss: 0.9456 - val_accuracy: 0.6693\n",
            "Epoch 20/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0291 - accuracy: 0.6389 - val_loss: 0.9488 - val_accuracy: 0.6638\n",
            "Epoch 21/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0200 - accuracy: 0.6385 - val_loss: 0.9065 - val_accuracy: 0.6805\n",
            "Epoch 22/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9916 - accuracy: 0.6518 - val_loss: 0.9008 - val_accuracy: 0.6838\n",
            "Epoch 23/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9730 - accuracy: 0.6573 - val_loss: 0.8919 - val_accuracy: 0.6880\n",
            "Epoch 24/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9612 - accuracy: 0.6580 - val_loss: 0.9170 - val_accuracy: 0.6744\n",
            "Epoch 25/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9618 - accuracy: 0.6605 - val_loss: 0.8643 - val_accuracy: 0.6944\n",
            "Epoch 26/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9381 - accuracy: 0.6678 - val_loss: 0.8678 - val_accuracy: 0.6984\n",
            "Epoch 27/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9196 - accuracy: 0.6763 - val_loss: 0.8721 - val_accuracy: 0.6929\n",
            "Epoch 28/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9122 - accuracy: 0.6744 - val_loss: 0.9051 - val_accuracy: 0.6848\n",
            "Epoch 29/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9017 - accuracy: 0.6793 - val_loss: 0.8290 - val_accuracy: 0.7061\n",
            "Epoch 30/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8991 - accuracy: 0.6837 - val_loss: 0.8864 - val_accuracy: 0.6853\n",
            "Epoch 31/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8906 - accuracy: 0.6843 - val_loss: 0.8475 - val_accuracy: 0.6968\n",
            "Epoch 32/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8808 - accuracy: 0.6891 - val_loss: 0.8301 - val_accuracy: 0.7011\n",
            "Epoch 33/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8635 - accuracy: 0.6982 - val_loss: 0.8050 - val_accuracy: 0.7183\n",
            "Epoch 34/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8600 - accuracy: 0.6960 - val_loss: 0.8161 - val_accuracy: 0.7149\n",
            "Epoch 35/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8420 - accuracy: 0.7019 - val_loss: 0.7944 - val_accuracy: 0.7183\n",
            "Epoch 36/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8280 - accuracy: 0.7095 - val_loss: 0.7765 - val_accuracy: 0.7296\n",
            "Epoch 37/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8348 - accuracy: 0.7062 - val_loss: 0.7989 - val_accuracy: 0.7195\n",
            "Epoch 38/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8267 - accuracy: 0.7084 - val_loss: 0.8973 - val_accuracy: 0.6865\n",
            "Epoch 39/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8165 - accuracy: 0.7143 - val_loss: 0.7807 - val_accuracy: 0.7315\n",
            "Epoch 40/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8127 - accuracy: 0.7154 - val_loss: 0.8212 - val_accuracy: 0.7125\n",
            "Epoch 00040: early stopping\n",
            "F1 Score: 0.7125\n",
            "\n",
            "Recreating Relu SGD Model: 2\n",
            "Training version: 1\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 2.2410 - accuracy: 0.1444 - val_loss: 1.9820 - val_accuracy: 0.2791\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.9700 - accuracy: 0.2724 - val_loss: 1.7852 - val_accuracy: 0.3536\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.7664 - accuracy: 0.3500 - val_loss: 1.6045 - val_accuracy: 0.4179\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6231 - accuracy: 0.4053 - val_loss: 1.5141 - val_accuracy: 0.4524\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5406 - accuracy: 0.4397 - val_loss: 1.4417 - val_accuracy: 0.4748\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.4642 - accuracy: 0.4690 - val_loss: 1.3266 - val_accuracy: 0.5279\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.4037 - accuracy: 0.4920 - val_loss: 1.3019 - val_accuracy: 0.5371\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3758 - accuracy: 0.5075 - val_loss: 1.2475 - val_accuracy: 0.5563\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3274 - accuracy: 0.5277 - val_loss: 1.2303 - val_accuracy: 0.5641\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3061 - accuracy: 0.5304 - val_loss: 1.1705 - val_accuracy: 0.5875\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2661 - accuracy: 0.5463 - val_loss: 1.1815 - val_accuracy: 0.5823\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2280 - accuracy: 0.5591 - val_loss: 1.1679 - val_accuracy: 0.5861\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2097 - accuracy: 0.5662 - val_loss: 1.0971 - val_accuracy: 0.6103\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1852 - accuracy: 0.5794 - val_loss: 1.1000 - val_accuracy: 0.6039\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1595 - accuracy: 0.5886 - val_loss: 1.0539 - val_accuracy: 0.6333\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1332 - accuracy: 0.5995 - val_loss: 1.0727 - val_accuracy: 0.6251\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1254 - accuracy: 0.6019 - val_loss: 1.0187 - val_accuracy: 0.6431\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0983 - accuracy: 0.6086 - val_loss: 1.0486 - val_accuracy: 0.6397\n",
            "Epoch 19/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0802 - accuracy: 0.6156 - val_loss: 1.1131 - val_accuracy: 0.6141\n",
            "Epoch 20/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0707 - accuracy: 0.6212 - val_loss: 0.9786 - val_accuracy: 0.6629\n",
            "Epoch 21/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0496 - accuracy: 0.6294 - val_loss: 1.0246 - val_accuracy: 0.6470\n",
            "Epoch 22/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0263 - accuracy: 0.6396 - val_loss: 0.9322 - val_accuracy: 0.6763\n",
            "Epoch 23/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0111 - accuracy: 0.6446 - val_loss: 1.0655 - val_accuracy: 0.6280\n",
            "Epoch 24/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9971 - accuracy: 0.6483 - val_loss: 0.9059 - val_accuracy: 0.6878\n",
            "Epoch 25/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9940 - accuracy: 0.6510 - val_loss: 0.9637 - val_accuracy: 0.6693\n",
            "Epoch 26/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9763 - accuracy: 0.6585 - val_loss: 0.9736 - val_accuracy: 0.6614\n",
            "Epoch 27/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9515 - accuracy: 0.6631 - val_loss: 0.8846 - val_accuracy: 0.6963\n",
            "Epoch 28/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9489 - accuracy: 0.6652 - val_loss: 0.9091 - val_accuracy: 0.6823\n",
            "Epoch 29/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9399 - accuracy: 0.6670 - val_loss: 0.8746 - val_accuracy: 0.6943\n",
            "Epoch 30/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9294 - accuracy: 0.6738 - val_loss: 0.8520 - val_accuracy: 0.7074\n",
            "Epoch 31/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9141 - accuracy: 0.6801 - val_loss: 0.8400 - val_accuracy: 0.7101\n",
            "Epoch 32/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8956 - accuracy: 0.6821 - val_loss: 0.8453 - val_accuracy: 0.7051\n",
            "Epoch 33/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8890 - accuracy: 0.6879 - val_loss: 0.8244 - val_accuracy: 0.7147\n",
            "Epoch 34/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8853 - accuracy: 0.6885 - val_loss: 0.8273 - val_accuracy: 0.7059\n",
            "Epoch 35/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8796 - accuracy: 0.6883 - val_loss: 0.8255 - val_accuracy: 0.7132\n",
            "Epoch 36/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8742 - accuracy: 0.6908 - val_loss: 0.8491 - val_accuracy: 0.7026\n",
            "Epoch 37/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8650 - accuracy: 0.6947 - val_loss: 0.8201 - val_accuracy: 0.7115\n",
            "Epoch 38/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8523 - accuracy: 0.6988 - val_loss: 0.7961 - val_accuracy: 0.7207\n",
            "Epoch 39/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8345 - accuracy: 0.7079 - val_loss: 0.8055 - val_accuracy: 0.7160\n",
            "Epoch 40/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8383 - accuracy: 0.7089 - val_loss: 0.7925 - val_accuracy: 0.7231\n",
            "Epoch 41/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8344 - accuracy: 0.7080 - val_loss: 0.7767 - val_accuracy: 0.7280\n",
            "Epoch 42/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8253 - accuracy: 0.7090 - val_loss: 0.7668 - val_accuracy: 0.7320\n",
            "Epoch 43/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8106 - accuracy: 0.7144 - val_loss: 0.7944 - val_accuracy: 0.7255\n",
            "Epoch 44/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8122 - accuracy: 0.7128 - val_loss: 0.7676 - val_accuracy: 0.7318\n",
            "Epoch 45/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8035 - accuracy: 0.7181 - val_loss: 0.7918 - val_accuracy: 0.7245\n",
            "Epoch 46/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7887 - accuracy: 0.7239 - val_loss: 0.7835 - val_accuracy: 0.7278\n",
            "Epoch 00046: early stopping\n",
            "F1 Score: 0.7278000000000001\n",
            "\n",
            "Recreating Relu SGD Model: 2\n",
            "Training version: 2\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 2.2535 - accuracy: 0.1389 - val_loss: 1.9970 - val_accuracy: 0.2697\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.9655 - accuracy: 0.2682 - val_loss: 1.8483 - val_accuracy: 0.3371\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.7666 - accuracy: 0.3455 - val_loss: 1.5877 - val_accuracy: 0.4325\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6155 - accuracy: 0.4071 - val_loss: 1.4838 - val_accuracy: 0.4723\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5386 - accuracy: 0.4367 - val_loss: 1.5381 - val_accuracy: 0.4544\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.4530 - accuracy: 0.4729 - val_loss: 1.3197 - val_accuracy: 0.5297\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3981 - accuracy: 0.4969 - val_loss: 1.3958 - val_accuracy: 0.5088\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3574 - accuracy: 0.5096 - val_loss: 1.3178 - val_accuracy: 0.5401\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3206 - accuracy: 0.5245 - val_loss: 1.1885 - val_accuracy: 0.5824\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2846 - accuracy: 0.5395 - val_loss: 1.1542 - val_accuracy: 0.5985\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2499 - accuracy: 0.5510 - val_loss: 1.1771 - val_accuracy: 0.5870\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2202 - accuracy: 0.5641 - val_loss: 1.1252 - val_accuracy: 0.6015\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1966 - accuracy: 0.5746 - val_loss: 1.0734 - val_accuracy: 0.6226\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1646 - accuracy: 0.5840 - val_loss: 1.0686 - val_accuracy: 0.6256\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1415 - accuracy: 0.5936 - val_loss: 1.0426 - val_accuracy: 0.6327\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1136 - accuracy: 0.6052 - val_loss: 1.0275 - val_accuracy: 0.6338\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0966 - accuracy: 0.6186 - val_loss: 1.0047 - val_accuracy: 0.6513\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0770 - accuracy: 0.6207 - val_loss: 1.0428 - val_accuracy: 0.6334\n",
            "Epoch 19/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0450 - accuracy: 0.6297 - val_loss: 0.9677 - val_accuracy: 0.6589\n",
            "Epoch 20/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0356 - accuracy: 0.6369 - val_loss: 0.9564 - val_accuracy: 0.6637\n",
            "Epoch 21/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0140 - accuracy: 0.6426 - val_loss: 0.9474 - val_accuracy: 0.6686\n",
            "Epoch 22/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9884 - accuracy: 0.6503 - val_loss: 0.9099 - val_accuracy: 0.6811\n",
            "Epoch 23/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9736 - accuracy: 0.6568 - val_loss: 0.8922 - val_accuracy: 0.6874\n",
            "Epoch 24/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9767 - accuracy: 0.6561 - val_loss: 0.8799 - val_accuracy: 0.6915\n",
            "Epoch 25/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9553 - accuracy: 0.6617 - val_loss: 0.8872 - val_accuracy: 0.6882\n",
            "Epoch 26/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9322 - accuracy: 0.6714 - val_loss: 0.9506 - val_accuracy: 0.6678\n",
            "Epoch 27/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9278 - accuracy: 0.6754 - val_loss: 0.8731 - val_accuracy: 0.6951\n",
            "Epoch 28/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9161 - accuracy: 0.6780 - val_loss: 0.8460 - val_accuracy: 0.7053\n",
            "Epoch 29/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8978 - accuracy: 0.6824 - val_loss: 0.8717 - val_accuracy: 0.6972\n",
            "Epoch 30/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8967 - accuracy: 0.6847 - val_loss: 0.8145 - val_accuracy: 0.7139\n",
            "Epoch 31/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8815 - accuracy: 0.6924 - val_loss: 0.8479 - val_accuracy: 0.7064\n",
            "Epoch 32/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8665 - accuracy: 0.6961 - val_loss: 0.8436 - val_accuracy: 0.7097\n",
            "Epoch 33/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8644 - accuracy: 0.6950 - val_loss: 0.8116 - val_accuracy: 0.7174\n",
            "Epoch 34/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8413 - accuracy: 0.7036 - val_loss: 0.7785 - val_accuracy: 0.7309\n",
            "Epoch 35/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8400 - accuracy: 0.7051 - val_loss: 0.7828 - val_accuracy: 0.7294\n",
            "Epoch 36/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8246 - accuracy: 0.7080 - val_loss: 0.8641 - val_accuracy: 0.7003\n",
            "Epoch 37/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8154 - accuracy: 0.7140 - val_loss: 0.7978 - val_accuracy: 0.7205\n",
            "Epoch 38/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8194 - accuracy: 0.7113 - val_loss: 0.7992 - val_accuracy: 0.7228\n",
            "Epoch 00038: early stopping\n",
            "F1 Score: 0.7228\n",
            "\n",
            "Recreating Relu SGD Model: 2\n",
            "Best Model: 2 for Relu SGD\n",
            "F1 Score: 0.7309000000000001\n",
            "Training model: 3 for Relu SGD\n",
            "Training version: 0\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 2.3271 - accuracy: 0.2604 - val_loss: 1.8074 - val_accuracy: 0.3535\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 1.5438 - accuracy: 0.4332 - val_loss: 1.5602 - val_accuracy: 0.4434\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3948 - accuracy: 0.4992 - val_loss: 1.2459 - val_accuracy: 0.5564\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2577 - accuracy: 0.5471 - val_loss: 1.1399 - val_accuracy: 0.5987\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 1.1850 - accuracy: 0.5777 - val_loss: 1.0943 - val_accuracy: 0.6055\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 1.1267 - accuracy: 0.5996 - val_loss: 1.1702 - val_accuracy: 0.5931\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 1.0671 - accuracy: 0.6227 - val_loss: 1.0008 - val_accuracy: 0.6455\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0133 - accuracy: 0.6456 - val_loss: 1.0192 - val_accuracy: 0.6423\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9873 - accuracy: 0.6548 - val_loss: 0.9546 - val_accuracy: 0.6611\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.9700 - accuracy: 0.6620 - val_loss: 1.0154 - val_accuracy: 0.6450\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.9418 - accuracy: 0.6710 - val_loss: 1.0565 - val_accuracy: 0.6364\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.9155 - accuracy: 0.6795 - val_loss: 0.9511 - val_accuracy: 0.6726\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.8874 - accuracy: 0.6929 - val_loss: 0.8472 - val_accuracy: 0.7033\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8708 - accuracy: 0.6964 - val_loss: 0.8250 - val_accuracy: 0.7111\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8604 - accuracy: 0.7011 - val_loss: 0.9781 - val_accuracy: 0.6673\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.8365 - accuracy: 0.7103 - val_loss: 0.7668 - val_accuracy: 0.7331\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.8249 - accuracy: 0.7151 - val_loss: 0.7468 - val_accuracy: 0.7379\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.8121 - accuracy: 0.7182 - val_loss: 0.8490 - val_accuracy: 0.7032\n",
            "Epoch 19/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.7804 - accuracy: 0.7320 - val_loss: 0.7422 - val_accuracy: 0.7429\n",
            "Epoch 20/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7828 - accuracy: 0.7280 - val_loss: 0.7409 - val_accuracy: 0.7376\n",
            "Epoch 21/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.7700 - accuracy: 0.7343 - val_loss: 0.7485 - val_accuracy: 0.7371\n",
            "Epoch 22/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7507 - accuracy: 0.7383 - val_loss: 0.7406 - val_accuracy: 0.7437\n",
            "Epoch 23/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.7377 - accuracy: 0.7453 - val_loss: 0.6800 - val_accuracy: 0.7629\n",
            "Epoch 24/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7371 - accuracy: 0.7450 - val_loss: 0.7229 - val_accuracy: 0.7507\n",
            "Epoch 25/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.7231 - accuracy: 0.7494 - val_loss: 0.7222 - val_accuracy: 0.7490\n",
            "Epoch 26/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.7188 - accuracy: 0.7534 - val_loss: 0.6833 - val_accuracy: 0.7651\n",
            "Epoch 27/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.7171 - accuracy: 0.7541 - val_loss: 0.6701 - val_accuracy: 0.7676\n",
            "Epoch 28/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.7063 - accuracy: 0.7569 - val_loss: 0.6838 - val_accuracy: 0.7615\n",
            "Epoch 29/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.6859 - accuracy: 0.7630 - val_loss: 0.6603 - val_accuracy: 0.7694\n",
            "Epoch 30/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.6791 - accuracy: 0.7656 - val_loss: 0.6131 - val_accuracy: 0.7875\n",
            "Epoch 31/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.6758 - accuracy: 0.7668 - val_loss: 0.6790 - val_accuracy: 0.7626\n",
            "Epoch 32/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6674 - accuracy: 0.7703 - val_loss: 0.6421 - val_accuracy: 0.7785\n",
            "Epoch 33/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.6495 - accuracy: 0.7758 - val_loss: 0.6544 - val_accuracy: 0.7738\n",
            "Epoch 34/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.6611 - accuracy: 0.7744 - val_loss: 0.6033 - val_accuracy: 0.7935\n",
            "Epoch 35/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.6521 - accuracy: 0.7741 - val_loss: 0.6134 - val_accuracy: 0.7869\n",
            "Epoch 36/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.6431 - accuracy: 0.7818 - val_loss: 0.6092 - val_accuracy: 0.7905\n",
            "Epoch 37/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6239 - accuracy: 0.7872 - val_loss: 0.6400 - val_accuracy: 0.7773\n",
            "Epoch 38/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.6197 - accuracy: 0.7858 - val_loss: 0.5923 - val_accuracy: 0.7916\n",
            "Epoch 39/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6157 - accuracy: 0.7884 - val_loss: 0.6033 - val_accuracy: 0.7940\n",
            "Epoch 40/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.6111 - accuracy: 0.7928 - val_loss: 0.6027 - val_accuracy: 0.7915\n",
            "Epoch 41/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.6212 - accuracy: 0.7872 - val_loss: 0.6039 - val_accuracy: 0.7894\n",
            "Epoch 42/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.5877 - accuracy: 0.7985 - val_loss: 0.5801 - val_accuracy: 0.8021\n",
            "Epoch 43/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5864 - accuracy: 0.7983 - val_loss: 0.5737 - val_accuracy: 0.8041\n",
            "Epoch 44/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.5939 - accuracy: 0.7940 - val_loss: 0.5801 - val_accuracy: 0.8019\n",
            "Epoch 45/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.5877 - accuracy: 0.7991 - val_loss: 0.8108 - val_accuracy: 0.7418\n",
            "Epoch 46/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5711 - accuracy: 0.8016 - val_loss: 0.6717 - val_accuracy: 0.7736\n",
            "Epoch 47/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5664 - accuracy: 0.8036 - val_loss: 0.5851 - val_accuracy: 0.7990\n",
            "Epoch 00047: early stopping\n",
            "F1 Score: 0.799\n",
            "\n",
            "Recreating Relu SGD Model: 3\n",
            "Training version: 1\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 2.3194 - accuracy: 0.2670 - val_loss: 1.6465 - val_accuracy: 0.4096\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5490 - accuracy: 0.4313 - val_loss: 1.4032 - val_accuracy: 0.4999\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 1.3807 - accuracy: 0.5031 - val_loss: 1.5123 - val_accuracy: 0.4638\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 1.2754 - accuracy: 0.5457 - val_loss: 1.6190 - val_accuracy: 0.4569\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1980 - accuracy: 0.5745 - val_loss: 1.1650 - val_accuracy: 0.5847\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 1.1407 - accuracy: 0.6001 - val_loss: 1.2187 - val_accuracy: 0.5799\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0757 - accuracy: 0.6188 - val_loss: 1.2121 - val_accuracy: 0.5846\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0380 - accuracy: 0.6342 - val_loss: 0.9638 - val_accuracy: 0.6568\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0027 - accuracy: 0.6492 - val_loss: 0.9383 - val_accuracy: 0.6701\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.9706 - accuracy: 0.6619 - val_loss: 0.9103 - val_accuracy: 0.6774\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.9433 - accuracy: 0.6681 - val_loss: 0.9517 - val_accuracy: 0.6619\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.9149 - accuracy: 0.6837 - val_loss: 0.9325 - val_accuracy: 0.6721\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.9014 - accuracy: 0.6860 - val_loss: 0.8477 - val_accuracy: 0.7017\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8770 - accuracy: 0.6959 - val_loss: 0.8412 - val_accuracy: 0.7054\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.8577 - accuracy: 0.7002 - val_loss: 0.7747 - val_accuracy: 0.7284\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8437 - accuracy: 0.7052 - val_loss: 0.7896 - val_accuracy: 0.7234\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8211 - accuracy: 0.7127 - val_loss: 0.8121 - val_accuracy: 0.7214\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8130 - accuracy: 0.7198 - val_loss: 0.7667 - val_accuracy: 0.7353\n",
            "Epoch 19/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.7906 - accuracy: 0.7267 - val_loss: 0.7429 - val_accuracy: 0.7368\n",
            "Epoch 20/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7880 - accuracy: 0.7266 - val_loss: 0.7777 - val_accuracy: 0.7345\n",
            "Epoch 21/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.7716 - accuracy: 0.7341 - val_loss: 0.6809 - val_accuracy: 0.7630\n",
            "Epoch 22/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.7584 - accuracy: 0.7379 - val_loss: 0.7287 - val_accuracy: 0.7470\n",
            "Epoch 23/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7437 - accuracy: 0.7425 - val_loss: 0.7675 - val_accuracy: 0.7320\n",
            "Epoch 24/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7374 - accuracy: 0.7428 - val_loss: 0.6763 - val_accuracy: 0.7651\n",
            "Epoch 25/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7133 - accuracy: 0.7537 - val_loss: 0.8267 - val_accuracy: 0.7226\n",
            "Epoch 26/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.7193 - accuracy: 0.7509 - val_loss: 0.6631 - val_accuracy: 0.7735\n",
            "Epoch 27/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.6989 - accuracy: 0.7577 - val_loss: 0.6839 - val_accuracy: 0.7646\n",
            "Epoch 28/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7041 - accuracy: 0.7580 - val_loss: 0.6462 - val_accuracy: 0.7761\n",
            "Epoch 29/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.6785 - accuracy: 0.7670 - val_loss: 0.6582 - val_accuracy: 0.7747\n",
            "Epoch 30/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.6896 - accuracy: 0.7620 - val_loss: 0.6666 - val_accuracy: 0.7705\n",
            "Epoch 31/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.6664 - accuracy: 0.7710 - val_loss: 0.6138 - val_accuracy: 0.7838\n",
            "Epoch 32/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6617 - accuracy: 0.7707 - val_loss: 0.6454 - val_accuracy: 0.7827\n",
            "Epoch 33/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6628 - accuracy: 0.7743 - val_loss: 0.6363 - val_accuracy: 0.7844\n",
            "Epoch 34/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.6379 - accuracy: 0.7816 - val_loss: 0.6423 - val_accuracy: 0.7845\n",
            "Epoch 35/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.6403 - accuracy: 0.7772 - val_loss: 0.5854 - val_accuracy: 0.7997\n",
            "Epoch 36/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.6338 - accuracy: 0.7792 - val_loss: 0.7266 - val_accuracy: 0.7544\n",
            "Epoch 37/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6336 - accuracy: 0.7818 - val_loss: 0.6182 - val_accuracy: 0.7923\n",
            "Epoch 38/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.6102 - accuracy: 0.7907 - val_loss: 0.6159 - val_accuracy: 0.7929\n",
            "Epoch 39/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6050 - accuracy: 0.7951 - val_loss: 0.5780 - val_accuracy: 0.8040\n",
            "Epoch 40/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6174 - accuracy: 0.7859 - val_loss: 0.5966 - val_accuracy: 0.7987\n",
            "Epoch 41/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.6008 - accuracy: 0.7935 - val_loss: 0.6032 - val_accuracy: 0.7956\n",
            "Epoch 42/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5875 - accuracy: 0.7991 - val_loss: 0.5856 - val_accuracy: 0.7993\n",
            "Epoch 43/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5860 - accuracy: 0.7982 - val_loss: 0.5637 - val_accuracy: 0.8078\n",
            "Epoch 44/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.5710 - accuracy: 0.8031 - val_loss: 0.5974 - val_accuracy: 0.7979\n",
            "Epoch 45/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.5677 - accuracy: 0.8036 - val_loss: 0.5764 - val_accuracy: 0.8065\n",
            "Epoch 46/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.5766 - accuracy: 0.8045 - val_loss: 0.5652 - val_accuracy: 0.8104\n",
            "Epoch 47/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.5575 - accuracy: 0.8090 - val_loss: 0.5750 - val_accuracy: 0.8047\n",
            "Epoch 00047: early stopping\n",
            "F1 Score: 0.8047\n",
            "\n",
            "Recreating Relu SGD Model: 3\n",
            "Training version: 2\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 2.3333 - accuracy: 0.2668 - val_loss: 1.5182 - val_accuracy: 0.4463\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 1.5347 - accuracy: 0.4348 - val_loss: 1.4059 - val_accuracy: 0.4804\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 1.3589 - accuracy: 0.5058 - val_loss: 1.6427 - val_accuracy: 0.4433\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 1.2523 - accuracy: 0.5513 - val_loss: 1.1945 - val_accuracy: 0.5757\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 1.1866 - accuracy: 0.5775 - val_loss: 1.1665 - val_accuracy: 0.5843\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 1.1236 - accuracy: 0.6000 - val_loss: 1.0753 - val_accuracy: 0.6102\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 1.0756 - accuracy: 0.6178 - val_loss: 1.0652 - val_accuracy: 0.6202\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 1.0344 - accuracy: 0.6331 - val_loss: 1.1761 - val_accuracy: 0.5711\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0052 - accuracy: 0.6443 - val_loss: 0.9127 - val_accuracy: 0.6779\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.9647 - accuracy: 0.6606 - val_loss: 1.0369 - val_accuracy: 0.6327\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.9568 - accuracy: 0.6609 - val_loss: 1.0053 - val_accuracy: 0.6435\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.9238 - accuracy: 0.6729 - val_loss: 0.7995 - val_accuracy: 0.7128\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.8982 - accuracy: 0.6870 - val_loss: 0.8996 - val_accuracy: 0.6812\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8890 - accuracy: 0.6889 - val_loss: 0.8649 - val_accuracy: 0.6882\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.8593 - accuracy: 0.6969 - val_loss: 0.9029 - val_accuracy: 0.6825\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.8405 - accuracy: 0.7098 - val_loss: 0.8223 - val_accuracy: 0.7087\n",
            "Epoch 00016: early stopping\n",
            "F1 Score: 0.7087\n",
            "\n",
            "Recreating Relu SGD Model: 3\n",
            "Best Model: 3 for Relu SGD\n",
            "F1 Score: 0.7128\n",
            "Training model: 4 for Relu SGD\n",
            "Training version: 0\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.2530 - accuracy: 0.1457 - val_loss: 2.2840 - val_accuracy: 0.1783\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.9521 - accuracy: 0.2744 - val_loss: 1.7084 - val_accuracy: 0.3885\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.7713 - accuracy: 0.3511 - val_loss: 1.5967 - val_accuracy: 0.4261\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6813 - accuracy: 0.3820 - val_loss: 1.5605 - val_accuracy: 0.4266\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6131 - accuracy: 0.4092 - val_loss: 1.4731 - val_accuracy: 0.4643\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5567 - accuracy: 0.4367 - val_loss: 1.4567 - val_accuracy: 0.4590\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5167 - accuracy: 0.4455 - val_loss: 1.3799 - val_accuracy: 0.4974\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.4721 - accuracy: 0.4697 - val_loss: 1.3697 - val_accuracy: 0.4992\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.4318 - accuracy: 0.4789 - val_loss: 1.2939 - val_accuracy: 0.5320\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.4102 - accuracy: 0.4941 - val_loss: 1.2635 - val_accuracy: 0.5416\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3749 - accuracy: 0.5048 - val_loss: 1.2833 - val_accuracy: 0.5376\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3421 - accuracy: 0.5154 - val_loss: 1.2174 - val_accuracy: 0.5664\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3043 - accuracy: 0.5370 - val_loss: 1.1971 - val_accuracy: 0.5716\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2923 - accuracy: 0.5371 - val_loss: 1.2418 - val_accuracy: 0.5623\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2627 - accuracy: 0.5500 - val_loss: 1.1417 - val_accuracy: 0.5892\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2213 - accuracy: 0.5674 - val_loss: 1.1594 - val_accuracy: 0.5888\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2139 - accuracy: 0.5745 - val_loss: 1.1356 - val_accuracy: 0.5936\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1876 - accuracy: 0.5756 - val_loss: 1.1152 - val_accuracy: 0.5996\n",
            "Epoch 19/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1716 - accuracy: 0.5882 - val_loss: 1.1543 - val_accuracy: 0.5876\n",
            "Epoch 20/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1492 - accuracy: 0.5944 - val_loss: 1.0946 - val_accuracy: 0.6089\n",
            "Epoch 21/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1292 - accuracy: 0.5985 - val_loss: 1.0698 - val_accuracy: 0.6179\n",
            "Epoch 22/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1169 - accuracy: 0.6067 - val_loss: 1.0548 - val_accuracy: 0.6238\n",
            "Epoch 23/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1011 - accuracy: 0.6135 - val_loss: 1.0158 - val_accuracy: 0.6391\n",
            "Epoch 24/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0763 - accuracy: 0.6225 - val_loss: 1.0631 - val_accuracy: 0.6304\n",
            "Epoch 25/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0654 - accuracy: 0.6273 - val_loss: 1.0149 - val_accuracy: 0.6413\n",
            "Epoch 26/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0547 - accuracy: 0.6269 - val_loss: 0.9829 - val_accuracy: 0.6478\n",
            "Epoch 27/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0380 - accuracy: 0.6406 - val_loss: 0.9922 - val_accuracy: 0.6538\n",
            "Epoch 28/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0224 - accuracy: 0.6444 - val_loss: 1.0334 - val_accuracy: 0.6363\n",
            "Epoch 29/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0036 - accuracy: 0.6460 - val_loss: 0.9609 - val_accuracy: 0.6643\n",
            "Epoch 30/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9942 - accuracy: 0.6533 - val_loss: 0.9948 - val_accuracy: 0.6516\n",
            "Epoch 31/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9834 - accuracy: 0.6549 - val_loss: 1.1059 - val_accuracy: 0.6326\n",
            "Epoch 32/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9728 - accuracy: 0.6611 - val_loss: 1.0417 - val_accuracy: 0.6349\n",
            "Epoch 33/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9599 - accuracy: 0.6652 - val_loss: 0.9468 - val_accuracy: 0.6753\n",
            "Epoch 34/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9457 - accuracy: 0.6715 - val_loss: 0.9809 - val_accuracy: 0.6567\n",
            "Epoch 35/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9414 - accuracy: 0.6715 - val_loss: 0.9601 - val_accuracy: 0.6716\n",
            "Epoch 36/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9292 - accuracy: 0.6766 - val_loss: 0.9311 - val_accuracy: 0.6727\n",
            "Epoch 37/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9166 - accuracy: 0.6784 - val_loss: 0.9466 - val_accuracy: 0.6681\n",
            "Epoch 38/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9118 - accuracy: 0.6833 - val_loss: 0.9304 - val_accuracy: 0.6787\n",
            "Epoch 39/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9045 - accuracy: 0.6826 - val_loss: 0.9385 - val_accuracy: 0.6747\n",
            "Epoch 40/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8904 - accuracy: 0.6886 - val_loss: 0.9096 - val_accuracy: 0.6849\n",
            "Epoch 41/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8788 - accuracy: 0.6942 - val_loss: 0.8980 - val_accuracy: 0.6885\n",
            "Epoch 42/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8774 - accuracy: 0.6939 - val_loss: 0.9132 - val_accuracy: 0.6860\n",
            "Epoch 43/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8612 - accuracy: 0.6982 - val_loss: 0.9040 - val_accuracy: 0.6840\n",
            "Epoch 44/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8587 - accuracy: 0.7003 - val_loss: 0.9174 - val_accuracy: 0.6879\n",
            "Epoch 45/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8431 - accuracy: 0.7045 - val_loss: 0.8752 - val_accuracy: 0.6962\n",
            "Epoch 46/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8401 - accuracy: 0.7083 - val_loss: 0.9352 - val_accuracy: 0.6817\n",
            "Epoch 47/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8372 - accuracy: 0.7079 - val_loss: 0.8841 - val_accuracy: 0.6964\n",
            "Epoch 48/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8253 - accuracy: 0.7096 - val_loss: 0.8928 - val_accuracy: 0.6876\n",
            "Epoch 49/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8135 - accuracy: 0.7141 - val_loss: 0.9535 - val_accuracy: 0.6648\n",
            "Epoch 00049: early stopping\n",
            "F1 Score: 0.6648\n",
            "\n",
            "Recreating Relu SGD Model: 4\n",
            "Training version: 1\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.2567 - accuracy: 0.1471 - val_loss: 2.0316 - val_accuracy: 0.2728\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.0292 - accuracy: 0.2428 - val_loss: 1.7701 - val_accuracy: 0.3617\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.8249 - accuracy: 0.3204 - val_loss: 1.6357 - val_accuracy: 0.4048\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.7120 - accuracy: 0.3667 - val_loss: 1.5289 - val_accuracy: 0.4549\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6135 - accuracy: 0.4121 - val_loss: 1.5069 - val_accuracy: 0.4644\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5507 - accuracy: 0.4359 - val_loss: 1.4405 - val_accuracy: 0.4844\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.4916 - accuracy: 0.4580 - val_loss: 1.3436 - val_accuracy: 0.5121\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.4484 - accuracy: 0.4768 - val_loss: 1.2899 - val_accuracy: 0.5415\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.4074 - accuracy: 0.4929 - val_loss: 1.2769 - val_accuracy: 0.5448\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3793 - accuracy: 0.5023 - val_loss: 1.2624 - val_accuracy: 0.5507\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3322 - accuracy: 0.5279 - val_loss: 1.2636 - val_accuracy: 0.5470\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3114 - accuracy: 0.5284 - val_loss: 1.1892 - val_accuracy: 0.5762\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2769 - accuracy: 0.5433 - val_loss: 1.1804 - val_accuracy: 0.5791\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2532 - accuracy: 0.5528 - val_loss: 1.1396 - val_accuracy: 0.5943\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2330 - accuracy: 0.5614 - val_loss: 1.1674 - val_accuracy: 0.5883\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2023 - accuracy: 0.5724 - val_loss: 1.1318 - val_accuracy: 0.5985\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1844 - accuracy: 0.5843 - val_loss: 1.1333 - val_accuracy: 0.5988\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1668 - accuracy: 0.5881 - val_loss: 1.2702 - val_accuracy: 0.5611\n",
            "Epoch 19/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1367 - accuracy: 0.5983 - val_loss: 1.0617 - val_accuracy: 0.6273\n",
            "Epoch 20/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1292 - accuracy: 0.5989 - val_loss: 1.0728 - val_accuracy: 0.6204\n",
            "Epoch 21/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0949 - accuracy: 0.6162 - val_loss: 1.1144 - val_accuracy: 0.6038\n",
            "Epoch 22/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0792 - accuracy: 0.6166 - val_loss: 1.1361 - val_accuracy: 0.6016\n",
            "Epoch 23/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0552 - accuracy: 0.6314 - val_loss: 1.0058 - val_accuracy: 0.6493\n",
            "Epoch 24/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0396 - accuracy: 0.6377 - val_loss: 0.9946 - val_accuracy: 0.6528\n",
            "Epoch 25/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0371 - accuracy: 0.6354 - val_loss: 1.0205 - val_accuracy: 0.6426\n",
            "Epoch 26/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0084 - accuracy: 0.6464 - val_loss: 0.9888 - val_accuracy: 0.6494\n",
            "Epoch 27/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0089 - accuracy: 0.6456 - val_loss: 0.9656 - val_accuracy: 0.6661\n",
            "Epoch 28/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9823 - accuracy: 0.6529 - val_loss: 1.0046 - val_accuracy: 0.6529\n",
            "Epoch 29/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9684 - accuracy: 0.6605 - val_loss: 0.9497 - val_accuracy: 0.6691\n",
            "Epoch 30/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9526 - accuracy: 0.6621 - val_loss: 0.9418 - val_accuracy: 0.6686\n",
            "Epoch 31/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9460 - accuracy: 0.6679 - val_loss: 1.0534 - val_accuracy: 0.6299\n",
            "Epoch 32/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9352 - accuracy: 0.6702 - val_loss: 0.9346 - val_accuracy: 0.6771\n",
            "Epoch 33/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9109 - accuracy: 0.6786 - val_loss: 0.9286 - val_accuracy: 0.6777\n",
            "Epoch 34/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9123 - accuracy: 0.6783 - val_loss: 0.9276 - val_accuracy: 0.6756\n",
            "Epoch 35/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9075 - accuracy: 0.6835 - val_loss: 0.9349 - val_accuracy: 0.6796\n",
            "Epoch 36/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8940 - accuracy: 0.6860 - val_loss: 0.9430 - val_accuracy: 0.6807\n",
            "Epoch 37/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8884 - accuracy: 0.6898 - val_loss: 0.9099 - val_accuracy: 0.6834\n",
            "Epoch 38/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8785 - accuracy: 0.6880 - val_loss: 0.9622 - val_accuracy: 0.6753\n",
            "Epoch 39/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8638 - accuracy: 0.6950 - val_loss: 0.8939 - val_accuracy: 0.6914\n",
            "Epoch 40/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8619 - accuracy: 0.6963 - val_loss: 0.9115 - val_accuracy: 0.6879\n",
            "Epoch 41/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8451 - accuracy: 0.7044 - val_loss: 0.9768 - val_accuracy: 0.6616\n",
            "Epoch 42/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8312 - accuracy: 0.7108 - val_loss: 0.9118 - val_accuracy: 0.6900\n",
            "Epoch 43/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8251 - accuracy: 0.7099 - val_loss: 0.9090 - val_accuracy: 0.6853\n",
            "Epoch 00043: early stopping\n",
            "F1 Score: 0.6853\n",
            "\n",
            "Recreating Relu SGD Model: 4\n",
            "Training version: 2\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.2487 - accuracy: 0.1491 - val_loss: 1.9889 - val_accuracy: 0.2803\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.9869 - accuracy: 0.2657 - val_loss: 1.8480 - val_accuracy: 0.3437\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.8032 - accuracy: 0.3297 - val_loss: 1.6335 - val_accuracy: 0.3963\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6780 - accuracy: 0.3841 - val_loss: 1.4971 - val_accuracy: 0.4572\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6041 - accuracy: 0.4136 - val_loss: 1.4607 - val_accuracy: 0.4774\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5246 - accuracy: 0.4445 - val_loss: 1.3981 - val_accuracy: 0.4863\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.4740 - accuracy: 0.4627 - val_loss: 1.3511 - val_accuracy: 0.5128\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.4276 - accuracy: 0.4843 - val_loss: 1.2990 - val_accuracy: 0.5332\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.4021 - accuracy: 0.4963 - val_loss: 1.2581 - val_accuracy: 0.5512\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3599 - accuracy: 0.5097 - val_loss: 1.3353 - val_accuracy: 0.5225\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3220 - accuracy: 0.5242 - val_loss: 1.2660 - val_accuracy: 0.5483\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2920 - accuracy: 0.5363 - val_loss: 1.2557 - val_accuracy: 0.5419\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2573 - accuracy: 0.5529 - val_loss: 1.1760 - val_accuracy: 0.5842\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2339 - accuracy: 0.5657 - val_loss: 1.2276 - val_accuracy: 0.5584\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2087 - accuracy: 0.5679 - val_loss: 1.2320 - val_accuracy: 0.5670\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1982 - accuracy: 0.5753 - val_loss: 1.1029 - val_accuracy: 0.6118\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1705 - accuracy: 0.5850 - val_loss: 1.1366 - val_accuracy: 0.5931\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1407 - accuracy: 0.5936 - val_loss: 1.0649 - val_accuracy: 0.6239\n",
            "Epoch 19/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1271 - accuracy: 0.6029 - val_loss: 1.0849 - val_accuracy: 0.6152\n",
            "Epoch 20/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0978 - accuracy: 0.6139 - val_loss: 1.1872 - val_accuracy: 0.5899\n",
            "Epoch 21/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0823 - accuracy: 0.6206 - val_loss: 1.0484 - val_accuracy: 0.6294\n",
            "Epoch 22/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0696 - accuracy: 0.6239 - val_loss: 1.0100 - val_accuracy: 0.6450\n",
            "Epoch 23/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0522 - accuracy: 0.6318 - val_loss: 0.9968 - val_accuracy: 0.6484\n",
            "Epoch 24/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0298 - accuracy: 0.6385 - val_loss: 1.0294 - val_accuracy: 0.6349\n",
            "Epoch 25/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0231 - accuracy: 0.6397 - val_loss: 1.0539 - val_accuracy: 0.6310\n",
            "Epoch 26/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0129 - accuracy: 0.6422 - val_loss: 0.9611 - val_accuracy: 0.6681\n",
            "Epoch 27/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9984 - accuracy: 0.6506 - val_loss: 0.9608 - val_accuracy: 0.6635\n",
            "Epoch 28/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9751 - accuracy: 0.6592 - val_loss: 1.0490 - val_accuracy: 0.6411\n",
            "Epoch 29/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9608 - accuracy: 0.6598 - val_loss: 0.9261 - val_accuracy: 0.6758\n",
            "Epoch 30/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9581 - accuracy: 0.6653 - val_loss: 1.0580 - val_accuracy: 0.6280\n",
            "Epoch 31/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9420 - accuracy: 0.6700 - val_loss: 0.9745 - val_accuracy: 0.6615\n",
            "Epoch 32/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9310 - accuracy: 0.6727 - val_loss: 0.9487 - val_accuracy: 0.6673\n",
            "Epoch 33/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9163 - accuracy: 0.6791 - val_loss: 0.9291 - val_accuracy: 0.6791\n",
            "Epoch 00033: early stopping\n",
            "F1 Score: 0.6791\n",
            "\n",
            "Recreating Relu SGD Model: 4\n",
            "Best Model: 4 for Relu SGD\n",
            "F1 Score: 0.6758\n",
            "Training model: 5 for Relu SGD\n",
            "Training version: 0\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 6s 3ms/step - loss: 2.2497 - accuracy: 0.1515 - val_loss: 2.0165 - val_accuracy: 0.2718\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 2.0114 - accuracy: 0.2630 - val_loss: 1.7682 - val_accuracy: 0.3800\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.8386 - accuracy: 0.3338 - val_loss: 1.6580 - val_accuracy: 0.4160\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7343 - accuracy: 0.3738 - val_loss: 1.5762 - val_accuracy: 0.4403\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6698 - accuracy: 0.3980 - val_loss: 1.5294 - val_accuracy: 0.4579\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6077 - accuracy: 0.4212 - val_loss: 1.4920 - val_accuracy: 0.4749\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5796 - accuracy: 0.4307 - val_loss: 1.4736 - val_accuracy: 0.4752\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5426 - accuracy: 0.4476 - val_loss: 1.4357 - val_accuracy: 0.4906\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5145 - accuracy: 0.4556 - val_loss: 1.4018 - val_accuracy: 0.4999\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4942 - accuracy: 0.4645 - val_loss: 1.3765 - val_accuracy: 0.5163\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4608 - accuracy: 0.4760 - val_loss: 1.3761 - val_accuracy: 0.5122\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4410 - accuracy: 0.4814 - val_loss: 1.3311 - val_accuracy: 0.5326\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4170 - accuracy: 0.4933 - val_loss: 1.3134 - val_accuracy: 0.5333\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4045 - accuracy: 0.4935 - val_loss: 1.3031 - val_accuracy: 0.5391\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3885 - accuracy: 0.5032 - val_loss: 1.2629 - val_accuracy: 0.5541\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3602 - accuracy: 0.5111 - val_loss: 1.2591 - val_accuracy: 0.5581\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3522 - accuracy: 0.5172 - val_loss: 1.2613 - val_accuracy: 0.5540\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3298 - accuracy: 0.5209 - val_loss: 1.2234 - val_accuracy: 0.5687\n",
            "Epoch 19/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3173 - accuracy: 0.5276 - val_loss: 1.2805 - val_accuracy: 0.5472\n",
            "Epoch 20/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3074 - accuracy: 0.5335 - val_loss: 1.2459 - val_accuracy: 0.5525\n",
            "Epoch 21/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2844 - accuracy: 0.5409 - val_loss: 1.2122 - val_accuracy: 0.5727\n",
            "Epoch 22/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2746 - accuracy: 0.5423 - val_loss: 1.1712 - val_accuracy: 0.5843\n",
            "Epoch 23/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2586 - accuracy: 0.5501 - val_loss: 1.1639 - val_accuracy: 0.5906\n",
            "Epoch 24/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2387 - accuracy: 0.5531 - val_loss: 1.1477 - val_accuracy: 0.5936\n",
            "Epoch 25/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2292 - accuracy: 0.5594 - val_loss: 1.1370 - val_accuracy: 0.5993\n",
            "Epoch 26/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2179 - accuracy: 0.5653 - val_loss: 1.1473 - val_accuracy: 0.5961\n",
            "Epoch 27/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2136 - accuracy: 0.5682 - val_loss: 1.1340 - val_accuracy: 0.6006\n",
            "Epoch 28/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1942 - accuracy: 0.5732 - val_loss: 1.1428 - val_accuracy: 0.5937\n",
            "Epoch 29/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1858 - accuracy: 0.5790 - val_loss: 1.1168 - val_accuracy: 0.6060\n",
            "Epoch 30/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1673 - accuracy: 0.5808 - val_loss: 1.1177 - val_accuracy: 0.6048\n",
            "Epoch 31/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1641 - accuracy: 0.5863 - val_loss: 1.0963 - val_accuracy: 0.6145\n",
            "Epoch 32/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1599 - accuracy: 0.5902 - val_loss: 1.0998 - val_accuracy: 0.6124\n",
            "Epoch 33/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1442 - accuracy: 0.5940 - val_loss: 1.0858 - val_accuracy: 0.6171\n",
            "Epoch 34/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1402 - accuracy: 0.5962 - val_loss: 1.0937 - val_accuracy: 0.6131\n",
            "Epoch 35/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1314 - accuracy: 0.5959 - val_loss: 1.0849 - val_accuracy: 0.6212\n",
            "Epoch 36/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1173 - accuracy: 0.6035 - val_loss: 1.0765 - val_accuracy: 0.6216\n",
            "Epoch 37/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1087 - accuracy: 0.6053 - val_loss: 1.0764 - val_accuracy: 0.6170\n",
            "Epoch 38/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1035 - accuracy: 0.6114 - val_loss: 1.0677 - val_accuracy: 0.6228\n",
            "Epoch 39/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0938 - accuracy: 0.6139 - val_loss: 1.0818 - val_accuracy: 0.6193\n",
            "Epoch 40/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0854 - accuracy: 0.6144 - val_loss: 1.0703 - val_accuracy: 0.6222\n",
            "Epoch 41/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0654 - accuracy: 0.6201 - val_loss: 1.0571 - val_accuracy: 0.6282\n",
            "Epoch 42/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0731 - accuracy: 0.6167 - val_loss: 1.0669 - val_accuracy: 0.6200\n",
            "Epoch 43/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0696 - accuracy: 0.6184 - val_loss: 1.0703 - val_accuracy: 0.6254\n",
            "Epoch 44/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0557 - accuracy: 0.6237 - val_loss: 1.0820 - val_accuracy: 0.6207\n",
            "Epoch 45/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0558 - accuracy: 0.6269 - val_loss: 1.0590 - val_accuracy: 0.6270\n",
            "Epoch 00045: early stopping\n",
            "F1 Score: 0.627\n",
            "\n",
            "Recreating Relu SGD Model: 5\n",
            "Training version: 1\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 6s 3ms/step - loss: 2.2254 - accuracy: 0.1593 - val_loss: 1.9744 - val_accuracy: 0.2898\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.9971 - accuracy: 0.2641 - val_loss: 1.7660 - val_accuracy: 0.3713\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.8223 - accuracy: 0.3373 - val_loss: 1.6412 - val_accuracy: 0.4217\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7225 - accuracy: 0.3798 - val_loss: 1.6502 - val_accuracy: 0.4202\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6528 - accuracy: 0.3996 - val_loss: 1.5251 - val_accuracy: 0.4615\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5972 - accuracy: 0.4257 - val_loss: 1.4947 - val_accuracy: 0.4654\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5556 - accuracy: 0.4366 - val_loss: 1.4415 - val_accuracy: 0.4827\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5382 - accuracy: 0.4475 - val_loss: 1.4211 - val_accuracy: 0.4960\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5095 - accuracy: 0.4538 - val_loss: 1.3862 - val_accuracy: 0.4976\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4780 - accuracy: 0.4687 - val_loss: 1.3787 - val_accuracy: 0.5030\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4511 - accuracy: 0.4784 - val_loss: 1.3480 - val_accuracy: 0.5221\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4249 - accuracy: 0.4867 - val_loss: 1.3409 - val_accuracy: 0.5250\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4048 - accuracy: 0.4969 - val_loss: 1.3116 - val_accuracy: 0.5327\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3779 - accuracy: 0.5058 - val_loss: 1.2825 - val_accuracy: 0.5411\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3723 - accuracy: 0.5083 - val_loss: 1.2619 - val_accuracy: 0.5468\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3477 - accuracy: 0.5147 - val_loss: 1.2348 - val_accuracy: 0.5625\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3279 - accuracy: 0.5255 - val_loss: 1.2678 - val_accuracy: 0.5530\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3005 - accuracy: 0.5324 - val_loss: 1.2107 - val_accuracy: 0.5734\n",
            "Epoch 19/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2917 - accuracy: 0.5375 - val_loss: 1.1947 - val_accuracy: 0.5780\n",
            "Epoch 20/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2693 - accuracy: 0.5495 - val_loss: 1.1890 - val_accuracy: 0.5798\n",
            "Epoch 21/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2588 - accuracy: 0.5542 - val_loss: 1.1773 - val_accuracy: 0.5778\n",
            "Epoch 22/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2473 - accuracy: 0.5558 - val_loss: 1.1655 - val_accuracy: 0.5895\n",
            "Epoch 23/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2314 - accuracy: 0.5638 - val_loss: 1.1691 - val_accuracy: 0.5840\n",
            "Epoch 24/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2264 - accuracy: 0.5651 - val_loss: 1.1527 - val_accuracy: 0.5897\n",
            "Epoch 25/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2060 - accuracy: 0.5677 - val_loss: 1.1492 - val_accuracy: 0.5913\n",
            "Epoch 26/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2046 - accuracy: 0.5719 - val_loss: 1.1451 - val_accuracy: 0.5908\n",
            "Epoch 27/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1902 - accuracy: 0.5712 - val_loss: 1.1233 - val_accuracy: 0.6039\n",
            "Epoch 28/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1787 - accuracy: 0.5824 - val_loss: 1.1190 - val_accuracy: 0.6031\n",
            "Epoch 29/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1663 - accuracy: 0.5836 - val_loss: 1.1062 - val_accuracy: 0.6048\n",
            "Epoch 30/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1544 - accuracy: 0.5967 - val_loss: 1.1062 - val_accuracy: 0.6088\n",
            "Epoch 31/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1523 - accuracy: 0.5895 - val_loss: 1.1187 - val_accuracy: 0.6076\n",
            "Epoch 32/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1367 - accuracy: 0.5953 - val_loss: 1.0985 - val_accuracy: 0.6128\n",
            "Epoch 33/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1245 - accuracy: 0.6028 - val_loss: 1.1095 - val_accuracy: 0.6149\n",
            "Epoch 34/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1153 - accuracy: 0.6057 - val_loss: 1.1033 - val_accuracy: 0.6094\n",
            "Epoch 35/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1100 - accuracy: 0.6047 - val_loss: 1.0926 - val_accuracy: 0.6115\n",
            "Epoch 36/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1023 - accuracy: 0.6107 - val_loss: 1.0909 - val_accuracy: 0.6142\n",
            "Epoch 37/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0964 - accuracy: 0.6137 - val_loss: 1.0688 - val_accuracy: 0.6204\n",
            "Epoch 38/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0894 - accuracy: 0.6111 - val_loss: 1.0618 - val_accuracy: 0.6253\n",
            "Epoch 39/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0700 - accuracy: 0.6187 - val_loss: 1.0759 - val_accuracy: 0.6175\n",
            "Epoch 40/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0718 - accuracy: 0.6203 - val_loss: 1.0777 - val_accuracy: 0.6226\n",
            "Epoch 41/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0651 - accuracy: 0.6204 - val_loss: 1.0524 - val_accuracy: 0.6263\n",
            "Epoch 42/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0619 - accuracy: 0.6240 - val_loss: 1.0465 - val_accuracy: 0.6302\n",
            "Epoch 43/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0539 - accuracy: 0.6236 - val_loss: 1.0522 - val_accuracy: 0.6274\n",
            "Epoch 44/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0436 - accuracy: 0.6288 - val_loss: 1.0569 - val_accuracy: 0.6245\n",
            "Epoch 45/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0326 - accuracy: 0.6309 - val_loss: 1.0531 - val_accuracy: 0.6322\n",
            "Epoch 46/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0312 - accuracy: 0.6327 - val_loss: 1.0574 - val_accuracy: 0.6246\n",
            "Epoch 00046: early stopping\n",
            "F1 Score: 0.6246\n",
            "\n",
            "Recreating Relu SGD Model: 5\n",
            "Training version: 2\n",
            "Epoch 1/1000\n",
            "1563/1563 [==============================] - 6s 3ms/step - loss: 2.2328 - accuracy: 0.1643 - val_loss: 1.9624 - val_accuracy: 0.2978\n",
            "Epoch 2/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.9801 - accuracy: 0.2788 - val_loss: 1.7489 - val_accuracy: 0.3881\n",
            "Epoch 3/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.8052 - accuracy: 0.3449 - val_loss: 1.6244 - val_accuracy: 0.4198\n",
            "Epoch 4/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7026 - accuracy: 0.3877 - val_loss: 1.5844 - val_accuracy: 0.4355\n",
            "Epoch 5/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6393 - accuracy: 0.4050 - val_loss: 1.5030 - val_accuracy: 0.4661\n",
            "Epoch 6/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5988 - accuracy: 0.4213 - val_loss: 1.4980 - val_accuracy: 0.4680\n",
            "Epoch 7/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5694 - accuracy: 0.4352 - val_loss: 1.4355 - val_accuracy: 0.4870\n",
            "Epoch 8/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5403 - accuracy: 0.4418 - val_loss: 1.4149 - val_accuracy: 0.4999\n",
            "Epoch 9/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5073 - accuracy: 0.4601 - val_loss: 1.4229 - val_accuracy: 0.4918\n",
            "Epoch 10/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4825 - accuracy: 0.4640 - val_loss: 1.4082 - val_accuracy: 0.5057\n",
            "Epoch 11/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4647 - accuracy: 0.4692 - val_loss: 1.3553 - val_accuracy: 0.5246\n",
            "Epoch 12/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4442 - accuracy: 0.4776 - val_loss: 1.3251 - val_accuracy: 0.5312\n",
            "Epoch 13/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4108 - accuracy: 0.4965 - val_loss: 1.2994 - val_accuracy: 0.5398\n",
            "Epoch 14/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4070 - accuracy: 0.4979 - val_loss: 1.3037 - val_accuracy: 0.5352\n",
            "Epoch 15/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3746 - accuracy: 0.5093 - val_loss: 1.2661 - val_accuracy: 0.5416\n",
            "Epoch 16/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3569 - accuracy: 0.5116 - val_loss: 1.2527 - val_accuracy: 0.5558\n",
            "Epoch 17/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3422 - accuracy: 0.5162 - val_loss: 1.2604 - val_accuracy: 0.5567\n",
            "Epoch 18/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3200 - accuracy: 0.5274 - val_loss: 1.2196 - val_accuracy: 0.5702\n",
            "Epoch 19/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3045 - accuracy: 0.5302 - val_loss: 1.2156 - val_accuracy: 0.5677\n",
            "Epoch 20/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2826 - accuracy: 0.5407 - val_loss: 1.2027 - val_accuracy: 0.5773\n",
            "Epoch 21/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2708 - accuracy: 0.5471 - val_loss: 1.1948 - val_accuracy: 0.5788\n",
            "Epoch 22/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2620 - accuracy: 0.5499 - val_loss: 1.1859 - val_accuracy: 0.5873\n",
            "Epoch 23/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2425 - accuracy: 0.5556 - val_loss: 1.1719 - val_accuracy: 0.5928\n",
            "Epoch 24/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2363 - accuracy: 0.5585 - val_loss: 1.1607 - val_accuracy: 0.5901\n",
            "Epoch 25/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2164 - accuracy: 0.5694 - val_loss: 1.1650 - val_accuracy: 0.5845\n",
            "Epoch 26/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2050 - accuracy: 0.5711 - val_loss: 1.1507 - val_accuracy: 0.5938\n",
            "Epoch 27/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1888 - accuracy: 0.5776 - val_loss: 1.1340 - val_accuracy: 0.5999\n",
            "Epoch 28/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1750 - accuracy: 0.5778 - val_loss: 1.1071 - val_accuracy: 0.6102\n",
            "Epoch 29/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1626 - accuracy: 0.5900 - val_loss: 1.1060 - val_accuracy: 0.6161\n",
            "Epoch 30/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1557 - accuracy: 0.5902 - val_loss: 1.0936 - val_accuracy: 0.6182\n",
            "Epoch 31/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1355 - accuracy: 0.5966 - val_loss: 1.0927 - val_accuracy: 0.6153\n",
            "Epoch 32/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1376 - accuracy: 0.5951 - val_loss: 1.0812 - val_accuracy: 0.6165\n",
            "Epoch 33/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1300 - accuracy: 0.5988 - val_loss: 1.0950 - val_accuracy: 0.6135\n",
            "Epoch 34/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0997 - accuracy: 0.6090 - val_loss: 1.0677 - val_accuracy: 0.6259\n",
            "Epoch 35/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0964 - accuracy: 0.6116 - val_loss: 1.0590 - val_accuracy: 0.6292\n",
            "Epoch 36/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0893 - accuracy: 0.6149 - val_loss: 1.0643 - val_accuracy: 0.6327\n",
            "Epoch 37/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0756 - accuracy: 0.6155 - val_loss: 1.0737 - val_accuracy: 0.6227\n",
            "Epoch 38/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0885 - accuracy: 0.6114 - val_loss: 1.0583 - val_accuracy: 0.6316\n",
            "Epoch 39/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0701 - accuracy: 0.6200 - val_loss: 1.0579 - val_accuracy: 0.6334\n",
            "Epoch 40/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0665 - accuracy: 0.6174 - val_loss: 1.0514 - val_accuracy: 0.6350\n",
            "Epoch 41/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0459 - accuracy: 0.6262 - val_loss: 1.0442 - val_accuracy: 0.6389\n",
            "Epoch 42/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0402 - accuracy: 0.6334 - val_loss: 1.0290 - val_accuracy: 0.6400\n",
            "Epoch 43/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0325 - accuracy: 0.6338 - val_loss: 1.0401 - val_accuracy: 0.6410\n",
            "Epoch 44/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0180 - accuracy: 0.6347 - val_loss: 1.0660 - val_accuracy: 0.6333\n",
            "Epoch 45/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0082 - accuracy: 0.6419 - val_loss: 1.0347 - val_accuracy: 0.6427\n",
            "Epoch 46/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0081 - accuracy: 0.6424 - val_loss: 1.0278 - val_accuracy: 0.6479\n",
            "Epoch 47/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9918 - accuracy: 0.6449 - val_loss: 1.0327 - val_accuracy: 0.6438\n",
            "Epoch 48/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9915 - accuracy: 0.6466 - val_loss: 1.0515 - val_accuracy: 0.6344\n",
            "Epoch 49/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9864 - accuracy: 0.6480 - val_loss: 1.0301 - val_accuracy: 0.6448\n",
            "Epoch 50/1000\n",
            "1563/1563 [==============================] - 5s 4ms/step - loss: 0.9744 - accuracy: 0.6502 - val_loss: 1.0264 - val_accuracy: 0.6426\n",
            "Epoch 51/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9701 - accuracy: 0.6525 - val_loss: 1.0205 - val_accuracy: 0.6472\n",
            "Epoch 52/1000\n",
            "1563/1563 [==============================] - 5s 4ms/step - loss: 0.9632 - accuracy: 0.6594 - val_loss: 1.0128 - val_accuracy: 0.6486\n",
            "Epoch 53/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9586 - accuracy: 0.6549 - val_loss: 1.0271 - val_accuracy: 0.6459\n",
            "Epoch 54/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9505 - accuracy: 0.6623 - val_loss: 1.0197 - val_accuracy: 0.6482\n",
            "Epoch 55/1000\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9490 - accuracy: 0.6619 - val_loss: 1.0183 - val_accuracy: 0.6502\n",
            "Epoch 56/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9387 - accuracy: 0.6654 - val_loss: 1.0092 - val_accuracy: 0.6561\n",
            "Epoch 57/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9247 - accuracy: 0.6690 - val_loss: 1.0138 - val_accuracy: 0.6550\n",
            "Epoch 58/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9192 - accuracy: 0.6721 - val_loss: 1.0394 - val_accuracy: 0.6486\n",
            "Epoch 59/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9142 - accuracy: 0.6725 - val_loss: 1.0268 - val_accuracy: 0.6463\n",
            "Epoch 60/1000\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9122 - accuracy: 0.6747 - val_loss: 1.0291 - val_accuracy: 0.6488\n",
            "Epoch 00060: early stopping\n",
            "F1 Score: 0.6488\n",
            "\n",
            "Recreating Relu SGD Model: 5\n",
            "Best Model: 5 for Relu SGD\n",
            "F1 Score: 0.6561\n",
            "Training finished...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xigd26XOoU-F"
      },
      "source": [
        "### Training Results\n",
        "Below you will find the code I used to print out my results. The best model of each type is shown with their CNN type (the function used to create the model) listed first. You will find each models scores for precision, recall, F1 score, and their classification report. In addition, I printed out the confusion matrix for each model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_92T0bsfOgQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b88d7d14-ee8c-4bc5-838c-c10a9e31dde0"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import metrics\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "path = '/content/drive/MyDrive/CSC180_Project3/'\n",
        "\n",
        "#Prints the confusion matrix and scores of a passed model\n",
        "def printModelReport(model):\n",
        "  pred = model.predict(x_test)\n",
        "  pred = np.argmax(pred, axis=1)\n",
        "\n",
        "  #Show confusion matrix\n",
        "  cm = confusion_matrix(np.argmax(y_test, axis=1), pred)\n",
        "  plot_confusion_matrix(cm, list(range(10)))\n",
        "\n",
        "  #Show model scores\n",
        "  print('Model Precision: ' + str(metrics.precision_score(np.argmax(y_test, axis=1), pred, average='micro')))\n",
        "  print('Model Recall: ' + str(metrics.recall_score(np.argmax(y_test, axis=1), pred, average='micro')))\n",
        "  print('Model F1 Score: ' + str(metrics.f1_score(np.argmax(y_test, axis=1), pred, average='micro')))\n",
        "  print('\\nModel Classification Report:\\n' + str(metrics.classification_report(np.argmax(y_test, axis=1), pred)))\n",
        "\n",
        "#Finds the best model in a given folder\n",
        "def findBestModel(folderPath):\n",
        "  i = 1\n",
        "  maxF1 = 0\n",
        "  modelNumber = 0\n",
        "\n",
        "  for entry in os.listdir(folderPath):\n",
        "    model = tf.keras.models.load_model(folderPath + entry)\n",
        "    pred = model.predict(x_test)\n",
        "    pred = np.argmax(pred, axis=1)\n",
        "    f1Score = metrics.f1_score(np.argmax(y_test, axis=1), pred, average='micro')\n",
        "\n",
        "    #If the f1 score is higher than saved max save the index\n",
        "    if (f1Score > maxF1):\n",
        "      maxF1 = f1Score\n",
        "      modelNumber = i\n",
        "\n",
        "    i += 1  \n",
        "  \n",
        "  #Print the report on the best model\n",
        "  print('CNN Type: ' + str(modelNumber))\n",
        "  model = tf.keras.models.load_model(folderPath + 'best_weights_' + str(modelNumber) + '.hdf5')\n",
        "  printModelReport(model)  \n",
        "\n",
        "\n",
        "#Print the best models of each type\n",
        "print('Best Sigmoid Adam Model')\n",
        "print('=======================')\n",
        "findBestModel(path + 'sig_adam/')\n",
        "\n",
        "print('\\nBest Sigmoid SGD Model')\n",
        "print('======================')\n",
        "findBestModel(path + 'sig_sgd/')\n",
        "\n",
        "print('\\nBest Tanh Adam Model')\n",
        "print('====================')\n",
        "findBestModel(path + 'tan_adam/')\n",
        "\n",
        "print('\\nBest Tanh SGD Model')\n",
        "print('===================')\n",
        "findBestModel(path + 'tan_sgd/')\n",
        "\n",
        "print('\\nBest Relu Adam Model')\n",
        "print('====================')\n",
        "findBestModel(path + 'relu_adam/')\n",
        "\n",
        "print('\\nBest Relu SGD Model')\n",
        "print('===================')\n",
        "findBestModel(path + 'relu_sgd/')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Sigmoid Adam Model\n",
            "=======================\n",
            "CNN Type: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Model Precision: 0.7347\n",
            "Model Recall: 0.7347\n",
            "Model F1 Score: 0.7347\n",
            "\n",
            "Model Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.72      0.73      1000\n",
            "           1       0.81      0.90      0.85      1000\n",
            "           2       0.66      0.60      0.63      1000\n",
            "           3       0.57      0.53      0.55      1000\n",
            "           4       0.77      0.66      0.71      1000\n",
            "           5       0.64      0.64      0.64      1000\n",
            "           6       0.79      0.82      0.81      1000\n",
            "           7       0.85      0.74      0.79      1000\n",
            "           8       0.73      0.87      0.79      1000\n",
            "           9       0.77      0.87      0.82      1000\n",
            "\n",
            "    accuracy                           0.73     10000\n",
            "   macro avg       0.73      0.73      0.73     10000\n",
            "weighted avg       0.73      0.73      0.73     10000\n",
            "\n",
            "\n",
            "Best Sigmoid SGD Model\n",
            "======================\n",
            "CNN Type: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Model Precision: 0.6206\n",
            "Model Recall: 0.6206\n",
            "Model F1 Score: 0.6206\n",
            "\n",
            "Model Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.69      0.68      1000\n",
            "           1       0.69      0.79      0.74      1000\n",
            "           2       0.53      0.46      0.49      1000\n",
            "           3       0.46      0.41      0.43      1000\n",
            "           4       0.57      0.50      0.53      1000\n",
            "           5       0.54      0.50      0.52      1000\n",
            "           6       0.66      0.73      0.70      1000\n",
            "           7       0.62      0.72      0.66      1000\n",
            "           8       0.72      0.76      0.74      1000\n",
            "           9       0.71      0.64      0.67      1000\n",
            "\n",
            "    accuracy                           0.62     10000\n",
            "   macro avg       0.62      0.62      0.62     10000\n",
            "weighted avg       0.62      0.62      0.62     10000\n",
            "\n",
            "\n",
            "Best Tanh Adam Model\n",
            "====================\n",
            "CNN Type: 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Model Precision: 0.6904\n",
            "Model Recall: 0.6904\n",
            "Model F1 Score: 0.6904\n",
            "\n",
            "Model Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.75      0.73      1000\n",
            "           1       0.78      0.82      0.80      1000\n",
            "           2       0.60      0.53      0.56      1000\n",
            "           3       0.57      0.39      0.46      1000\n",
            "           4       0.63      0.68      0.65      1000\n",
            "           5       0.59      0.66      0.62      1000\n",
            "           6       0.65      0.83      0.73      1000\n",
            "           7       0.78      0.72      0.75      1000\n",
            "           8       0.79      0.79      0.79      1000\n",
            "           9       0.79      0.76      0.77      1000\n",
            "\n",
            "    accuracy                           0.69     10000\n",
            "   macro avg       0.69      0.69      0.69     10000\n",
            "weighted avg       0.69      0.69      0.69     10000\n",
            "\n",
            "\n",
            "Best Tanh SGD Model\n",
            "===================\n",
            "CNN Type: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Model Precision: 0.7082\n",
            "Model Recall: 0.7082\n",
            "Model F1 Score: 0.7082\n",
            "\n",
            "Model Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.68      0.73      1000\n",
            "           1       0.85      0.82      0.84      1000\n",
            "           2       0.64      0.55      0.59      1000\n",
            "           3       0.57      0.47      0.51      1000\n",
            "           4       0.70      0.61      0.65      1000\n",
            "           5       0.60      0.63      0.61      1000\n",
            "           6       0.60      0.91      0.72      1000\n",
            "           7       0.82      0.70      0.75      1000\n",
            "           8       0.77      0.87      0.82      1000\n",
            "           9       0.78      0.85      0.81      1000\n",
            "\n",
            "    accuracy                           0.71     10000\n",
            "   macro avg       0.71      0.71      0.70     10000\n",
            "weighted avg       0.71      0.71      0.70     10000\n",
            "\n",
            "\n",
            "Best Relu Adam Model\n",
            "====================\n",
            "CNN Type: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Model Precision: 0.8349\n",
            "Model Recall: 0.8349\n",
            "Model F1 Score: 0.8349000000000001\n",
            "\n",
            "Model Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.87      0.85      1000\n",
            "           1       0.96      0.89      0.92      1000\n",
            "           2       0.84      0.68      0.75      1000\n",
            "           3       0.72      0.67      0.70      1000\n",
            "           4       0.77      0.86      0.82      1000\n",
            "           5       0.74      0.79      0.77      1000\n",
            "           6       0.84      0.91      0.87      1000\n",
            "           7       0.90      0.85      0.87      1000\n",
            "           8       0.88      0.92      0.90      1000\n",
            "           9       0.87      0.91      0.89      1000\n",
            "\n",
            "    accuracy                           0.83     10000\n",
            "   macro avg       0.84      0.83      0.83     10000\n",
            "weighted avg       0.84      0.83      0.83     10000\n",
            "\n",
            "\n",
            "Best Relu SGD Model\n",
            "===================\n",
            "CNN Type: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Model Precision: 0.7309\n",
            "Model Recall: 0.7309\n",
            "Model F1 Score: 0.7309000000000001\n",
            "\n",
            "Model Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.75      0.77      1000\n",
            "           1       0.87      0.84      0.85      1000\n",
            "           2       0.67      0.55      0.60      1000\n",
            "           3       0.56      0.51      0.53      1000\n",
            "           4       0.62      0.75      0.68      1000\n",
            "           5       0.67      0.61      0.64      1000\n",
            "           6       0.68      0.89      0.77      1000\n",
            "           7       0.80      0.75      0.77      1000\n",
            "           8       0.79      0.89      0.84      1000\n",
            "           9       0.88      0.77      0.82      1000\n",
            "\n",
            "    accuracy                           0.73     10000\n",
            "   macro avg       0.73      0.73      0.73     10000\n",
            "weighted avg       0.73      0.73      0.73     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "103RRPUvtOie"
      },
      "source": [
        "### 3-5 Images with Predicted and True Labels\n",
        "Using the best custom model produced (Relu/Adam of type 3) I choose 5 random images from my test set and print out the predicted label along with its actual label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFryw76VtOie"
      },
      "source": [
        "import random\n",
        "\n",
        "#Best model in testing is Relu Adam CNN Type 3, we will use that\n",
        "model = tf.keras.models.load_model('/content/drive/MyDrive/CSC180_Project3/relu_adam/best_weights_3.hdf5')\n",
        "pred = model.predict(x_test)\n",
        "pred = np.argmax(pred, axis=1)\n",
        "\n",
        "#Get a random 5 images to show\n",
        "randList = random.sample(range(0, x_test.shape[0]), 5)"
      ],
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lS2RA1SaPkrp"
      },
      "source": [
        "#Class names\n",
        "className = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck']"
      ],
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "LDgMgTCxDSfg",
        "outputId": "4a70854b-34ca-4ce8-ea42-6f479bb9c387"
      },
      "source": [
        "#Show the first image\n",
        "print('Predicted: ' + className[pred[randList[0]]])\n",
        "print('True: ' + className[np.argmax(y_test[randList[0]])])\n",
        "plt.imshow(x_test[randList[0]])"
      ],
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted: Automobile\n",
            "True: Automobile\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f71866a8210>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 199
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "EQl0oiEcEe2b",
        "outputId": "810b0eb7-1672-4289-8af2-41e0277184d5"
      },
      "source": [
        "#Show the second image\n",
        "print('Predicted: ' + className[pred[randList[1]]])\n",
        "print('True: ' + className[np.argmax(y_test[randList[1]])])\n",
        "plt.imshow(x_test[randList[1]])"
      ],
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted: Horse\n",
            "True: Horse\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f70983910d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 200
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "jj5oIhHxEi-z",
        "outputId": "afe19199-9cac-4e6c-f579-139b95162d94"
      },
      "source": [
        "#Show the third image\n",
        "print('Predicted: ' + className[pred[randList[2]]])\n",
        "print('True: ' + className[np.argmax(y_test[randList[2]])])\n",
        "plt.imshow(x_test[randList[2]])"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted: Automobile\n",
            "True: Automobile\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f70c33138d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 201
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "NrSRTT7FEmSa",
        "outputId": "e60b92ba-6eb5-4a28-c3f3-5a73d90bf290"
      },
      "source": [
        "#Show the fourth image\n",
        "print('Predicted: ' + className[pred[randList[3]]])\n",
        "print('True: ' + className[np.argmax(y_test[randList[3]])])\n",
        "plt.imshow(x_test[randList[3]])"
      ],
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted: Dog\n",
            "True: Dog\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f6e30bd41d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 202
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "V1x8YhHKErkO",
        "outputId": "ea060843-3e9f-41f4-8c60-d0fbfe2d095f"
      },
      "source": [
        "#Show the fifth image\n",
        "print('Predicted: ' + className[pred[randList[4]]])\n",
        "print('True: ' + className[np.argmax(y_test[randList[4]])])\n",
        "plt.imshow(x_test[randList[4]])"
      ],
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted: Airplane\n",
            "True: Airplane\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f6e31a2d410>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 203
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgBnw9dRfOgS"
      },
      "source": [
        "\n",
        "\n",
        "### Part II:   CNN model with Transfer Learning\n",
        "In this section of the report I will use transfer learning on VGG16 (required), ResNet50, and DenseNet201. To do this I will import each model, freeze their layers, and add some fully connected layers on top fit to my problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9rvtqrsfOgT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59e23d5e-2195-4e12-c82c-020dab267e0b"
      },
      "source": [
        "# We load data again. The data split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('y_train shape:', y_train.shape)\n",
        "print('x_test shape:', x_test.shape)\n",
        "print('y_test shape:', y_test.shape)\n",
        "\n",
        "# Print number of samples\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "y_train shape: (50000, 1)\n",
            "x_test shape: (10000, 32, 32, 3)\n",
            "y_test shape: (10000, 1)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGSxqVVypDiX"
      },
      "source": [
        "### Using VGG16 for Transfer Learning\n",
        "VGG16 supports down to 48x48 images as input. However, the resolution of our images is 32x32 which is too low. Thus, we need to increase the resolution (upsampling). We will accomplish this with ``skimage.transform.resize()`` which is provided by the <a href=\"https://scikit-image.org/\">scikit-image library</a>. Note, this function normalizes our data so we have no need to do this ourselves.<br>\n",
        "\n",
        "More information about VGG16 can be found <a href=\"https://neurohive.io/en/popular-networks/vgg16/\">here</a>.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWwBKsh-fOgX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5511f70-06d5-4c2e-9696-bd433f85170f"
      },
      "source": [
        "from skimage import transform\n",
        "\n",
        "#We will a skimage function to resize the images\n",
        "#Note: This function automatically normalizes the data... no need to apply after conversion\n",
        "new_x_train = []\n",
        "\n",
        "for img in x_train:\n",
        "  new_x_train.append(transform.resize(img, (64, 64)))\n",
        "\n",
        "#Convert list to numpy\n",
        "new_x_train = np.array(new_x_train)\n",
        "\n",
        "print('Old Shape: ' + str(x_train.shape))  \n",
        "print('New Shape: ' + str(new_x_train.shape)) \n",
        "  \n",
        "# This process may take about a few minutes..."
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Old Shape: (50000, 32, 32, 3)\n",
            "New Shape: (50000, 64, 64, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0s0-oaKDfOgf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85fbe431-08ea-441e-f810-bb5529413443"
      },
      "source": [
        "#We will a tensorflow function to resize the images\n",
        "new_x_test = []\n",
        "\n",
        "for img in x_test:\n",
        "  new_x_test.append(transform.resize(img, (64, 64)))\n",
        "\n",
        "#Convert list to numpy\n",
        "new_x_test = np.array(new_x_test)\n",
        "\n",
        "print('Old Shape: ' + str(x_test.shape))  \n",
        "print('New Shape: ' + str(new_x_test.shape))   \n",
        "  \n",
        "# This process may take about a few minutes..."
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Old Shape: (10000, 32, 32, 3)\n",
            "New Shape: (10000, 64, 64, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPjFo2oyqlGO"
      },
      "source": [
        "### Data Preprocessing\n",
        "Below we convert ``y_train`` and ``y_test`` from 2D to 1D by reshaping it. After this we apply One Hot Encoding (OHE) to both."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQuVaf2pkRdr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62c3acf4-553b-4f61-daa1-c0fffdc36e91"
      },
      "source": [
        "#Convert y_train and y_test to 1d using reshape\n",
        "print('Before y_train reshape: ' + str(y_train.shape))\n",
        "print('Before y_test reshape: ' + str(y_test.shape))\n",
        "\n",
        "new_y_train = y_train.reshape(y_train.shape[0])\n",
        "new_y_test = y_test.reshape(y_test.shape[0])\n",
        "\n",
        "print('After y_train reshape: ' + str(new_y_train.shape))\n",
        "print('After y_test reshape: ' + str(new_y_test.shape))\n",
        "\n",
        "#Apply 1hot encoding\n",
        "new_y_train = tf.keras.utils.to_categorical(new_y_train, num_classes)\n",
        "new_y_test = tf.keras.utils.to_categorical(new_y_test, num_classes)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before y_train reshape: (50000, 1)\n",
            "Before y_test reshape: (10000, 1)\n",
            "After y_train reshape: (50000,)\n",
            "After y_test reshape: (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_pLuCNjqvbf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "732e0964-b5a0-4fc6-a6a9-cbc4feac82d2"
      },
      "source": [
        "#Double check shape\n",
        "print(new_y_train.shape)\n",
        "print(new_y_test.shape)\n",
        "\n",
        "#Expected output:  (50000, 10)\n",
        "#Expected output:  (10000, 10)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 10)\n",
            "(10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-bzRNdjfOgy"
      },
      "source": [
        "### Loading VGG16\n",
        "Below we load VGG16 (included in Keras) into a new model. Excluding the top layers.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HLwE00VfOgz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "587e3472-9b10-4f09-ef16-3898a83caac2"
      },
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "\n",
        "#First hidden layer\n",
        "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n",
        "\n",
        "model = Sequential()\n",
        "  \n",
        "#Write your code here\n",
        "for layer in vgg_model.layers:\n",
        "  model.add(layer)\n",
        "\n",
        "#Print out the model summary\n",
        "model.summary()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "block1_conv1 (Conv2D)        (None, 64, 64, 64)        1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 64, 64, 64)        36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 32, 32, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 32, 32, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 16, 16, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 16, 16, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 16, 16, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 8, 8, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ki8D32hrl3E"
      },
      "source": [
        "### Freeze Weights\n",
        "Below I freeze (make non-trainable) the weights in the transferred layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_oqboGwfOg1"
      },
      "source": [
        "#Freeze weights on all layers\n",
        "for layer in model.layers:\n",
        "  layer.trainable = False"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YArrSsS4rt_t"
      },
      "source": [
        "###  Add New Dense Layers\n",
        "Below I add new top layers conformed to my data. I decided to use the Relu activation function on the layers before my ouput layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fphbz0FhfOg3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f3e0e91-2456-4a05-a9ff-15a5f08f0c95"
      },
      "source": [
        "model.add(Flatten())\n",
        "\n",
        "#Add some \"Dense\" layers here, including output layer\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "#Print model summary\n",
        "model.summary()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "block1_conv1 (Conv2D)        (None, 64, 64, 64)        1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 64, 64, 64)        36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 32, 32, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 32, 32, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 16, 16, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 16, 16, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 16, 16, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 8, 8, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 1024)              2098176   \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 17,404,618\n",
            "Trainable params: 2,689,930\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDOG92fcr1m8"
      },
      "source": [
        "### Compile and Fit VGG16\n",
        "After creating my model based off VGG16 I train it below. As required, earlystopping and checkpointing is used to help prevent overfitting. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWrWTc2JfOg6",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fae36b5-7cf2-491a-f9ba-706761c85ee2"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "#Define callbacks\n",
        "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=4, verbose=1, mode='auto')\n",
        "checkpointer = ModelCheckpoint(filepath='/content/drive/MyDrive/CSC180_Project3/vgg16/best_weights.hdf5', verbose=0, save_best_only=True)\n",
        "\n",
        "#Compile\n",
        "model.compile(loss=categorical_crossentropy, optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "#Fit\n",
        "print('Training VGG16')\n",
        "model.fit(new_x_train, new_y_train, validation_data=(new_x_test, new_y_test), callbacks=[monitor, checkpointer], verbose=1, epochs=100)\n",
        "\n",
        "#Print F1 score of best\n",
        "model.load_weights('/content/drive/MyDrive/CSC180_Project3/vgg16/best_weights.hdf5')\n",
        "pred = model.predict(new_x_test)\n",
        "pred = np.argmax(pred, axis=1)\n",
        "print('F1 Score: ' + str(metrics.f1_score(np.argmax(new_y_test, axis=1), pred, average='micro')))\n",
        "\n",
        "#Since we use a GPU, the training time for each epoch for the transferred model is about 60 seconds.  "
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training VGG16\n",
            "Epoch 1/100\n",
            "1563/1563 [==============================] - 14s 8ms/step - loss: 1.3099 - accuracy: 0.5384 - val_loss: 0.9525 - val_accuracy: 0.6684\n",
            "Epoch 2/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.9094 - accuracy: 0.6801 - val_loss: 0.9479 - val_accuracy: 0.6754\n",
            "Epoch 3/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.8101 - accuracy: 0.7141 - val_loss: 0.8934 - val_accuracy: 0.6889\n",
            "Epoch 4/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.7300 - accuracy: 0.7419 - val_loss: 0.8871 - val_accuracy: 0.6971\n",
            "Epoch 5/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.6629 - accuracy: 0.7675 - val_loss: 0.8840 - val_accuracy: 0.7002\n",
            "Epoch 6/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.5911 - accuracy: 0.7922 - val_loss: 0.9032 - val_accuracy: 0.7003\n",
            "Epoch 7/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.5306 - accuracy: 0.8116 - val_loss: 0.9342 - val_accuracy: 0.7063\n",
            "Epoch 8/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.4805 - accuracy: 0.8278 - val_loss: 0.9918 - val_accuracy: 0.7026\n",
            "Epoch 9/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.4311 - accuracy: 0.8475 - val_loss: 0.9642 - val_accuracy: 0.7108\n",
            "Epoch 00009: early stopping\n",
            "F1 Score: 0.7002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbiultTcfbUK"
      },
      "source": [
        "### Additional Transfer Learning\n",
        "As an experiment, I also performed transfer learning on DenseNet201 and ResNet50. Two other popular image classification models. Also, I decided to retrain VGG16 with a new upsampling layer to scale the images to 224x224. This is the resolution that VGG16 used when training on ImageNet. Please note, this was accomplished by adding an Upsampling2D input layer on the original 32x32 images (not the 64x64). Below you can find the code I used to create my models as well as the code used to train each model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoOhiP9Ff18F"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import UpSampling2D, GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.applications.densenet import DenseNet201\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "\n",
        "def getResNetModel():\n",
        "  res_model = ResNet50(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n",
        "\n",
        "  #Freeze layers\n",
        "  for layer in res_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "  #Add more top layers\n",
        "  newOut = res_model.output\n",
        "  newOut = GlobalAveragePooling2D()(newOut)\n",
        "  newOut = Dense(1024, activation='relu')(newOut)\n",
        "  newOut = Dropout(0.25)(newOut)\n",
        "  newOut = Dense(512, activation='relu')(newOut)\n",
        "  newOut = Dense(128, activation='relu')(newOut)\n",
        "  newOut = Dropout(0.25)(newOut)\n",
        "  newOut = Dense(10, activation='softmax')(newOut)\n",
        "\n",
        "  #Create model and return it\n",
        "  model = Model(inputs=res_model.input, outputs=newOut)\n",
        "  return model\n",
        "\n",
        "def getDenseNetModel():\n",
        "  dense_model = DenseNet201(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n",
        "\n",
        "  #Freeze layers\n",
        "  for layer in dense_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "  #Add more top layers\n",
        "  newOut = dense_model.output\n",
        "  newOut = GlobalAveragePooling2D()(newOut)\n",
        "  newOut = Dense(1024, activation='relu')(newOut)\n",
        "  newOut = Dropout(0.25)(newOut)\n",
        "  newOut = Dense(512, activation='relu')(newOut)\n",
        "  newOut = Dense(128, activation='relu')(newOut)\n",
        "  newOut = Dropout(0.25)(newOut)\n",
        "  newOut = Dense(10, activation='softmax')(newOut)\n",
        "\n",
        "  #Create model and return it\n",
        "  model = Model(inputs=dense_model.input, outputs=newOut)  \n",
        "  return model\n",
        "\n",
        "def getVGG16Upscaled():\n",
        "  vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "  #Freeze layers\n",
        "  for layer in vgg_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "  #Add an upsampling layer and some others...\n",
        "  newOut = vgg_model.output\n",
        "  newOut = GlobalAveragePooling2D()(newOut)\n",
        "  newOut = Dense(1024, activation='relu')(newOut)\n",
        "  newOut = Dropout(0.25)(newOut)\n",
        "  newOut = Dense(512, activation='relu')(newOut)\n",
        "  newOut = Dense(128, activation='relu')(newOut)\n",
        "  newOut = Dropout(0.25)(newOut)\n",
        "  newOut = Dense(10, activation='softmax')(newOut)\n",
        "\n",
        "  model = Model(inputs=vgg_model.input, outputs=newOut)\n",
        "\n",
        "  #Create model with upsampling\n",
        "  newModel = Sequential()\n",
        "  newModel.add(UpSampling2D(input_shape=(32, 32, 3), size=(7, 7)))\n",
        "\n",
        "  for layer in model.layers:\n",
        "    newModel.add(layer)\n",
        "\n",
        "  return newModel"
      ],
      "execution_count": 171,
      "outputs": []
    },
    {
      "source": [
        "### Training DenseNet201\n",
        "Below I train my model that incorporated transfer learning using DenseNet201."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mv5iw3HxoFzh",
        "outputId": "264e47ca-e174-4aeb-cf3b-1f75ca4b9bf7"
      },
      "source": [
        "#Define callbacks\n",
        "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=4, verbose=1, mode='auto')\n",
        "checkpointer = ModelCheckpoint(filepath='/content/drive/MyDrive/CSC180_Project3/denseNet/best_weights.hdf5', verbose=0, save_best_only=True)\n",
        "\n",
        "#Compile\n",
        "model = getDenseNetModel()\n",
        "model.compile(loss=categorical_crossentropy, optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "#Fit\n",
        "print('Training DenseNet210')\n",
        "model.fit(new_x_train, new_y_train, validation_data=(new_x_test, new_y_test), callbacks=[monitor, checkpointer], verbose=1, epochs=100)\n",
        "\n",
        "#Print F1 score of best\n",
        "model.load_weights('/content/drive/MyDrive/CSC180_Project3/denseNet/best_weights.hdf5')\n",
        "pred = model.predict(new_x_test)\n",
        "pred = np.argmax(pred, axis=1)\n",
        "print('F1 Score: ' + str(metrics.f1_score(np.argmax(new_y_test, axis=1), pred, average='micro')))"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training DenseNet210\n",
            "Epoch 1/100\n",
            "1563/1563 [==============================] - 49s 25ms/step - loss: 1.1223 - accuracy: 0.6164 - val_loss: 0.8652 - val_accuracy: 0.6978\n",
            "Epoch 2/100\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.7390 - accuracy: 0.7404 - val_loss: 0.8276 - val_accuracy: 0.7283\n",
            "Epoch 3/100\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.6171 - accuracy: 0.7826 - val_loss: 0.8211 - val_accuracy: 0.7185\n",
            "Epoch 4/100\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.5073 - accuracy: 0.8183 - val_loss: 0.8327 - val_accuracy: 0.7383\n",
            "Epoch 5/100\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.4138 - accuracy: 0.8538 - val_loss: 0.8363 - val_accuracy: 0.7406\n",
            "Epoch 6/100\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3192 - accuracy: 0.8857 - val_loss: 0.9718 - val_accuracy: 0.7299\n",
            "Epoch 7/100\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.2518 - accuracy: 0.9109 - val_loss: 1.0960 - val_accuracy: 0.7265\n",
            "Epoch 00007: early stopping\n",
            "F1 Score: 0.7185\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "source": [
        "### Training ResNet50\n",
        "Below I train my model that incorporated transfer learning using ResNet50."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apm4neYUokQi",
        "outputId": "01fad87f-1332-493b-fcee-3991c9065e76"
      },
      "source": [
        "#Define callbacks\n",
        "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=4, verbose=1, mode='auto')\n",
        "checkpointer = ModelCheckpoint(filepath='/content/drive/MyDrive/CSC180_Project3/resnet50/best_weights.hdf5', verbose=0, save_best_only=True)\n",
        "\n",
        "#Compile\n",
        "model = getResNetModel()\n",
        "model.compile(loss=categorical_crossentropy, optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "#Fit\n",
        "print('Training ResNet50')\n",
        "model.fit(new_x_train, new_y_train, validation_data=(new_x_test, new_y_test), callbacks=[monitor, checkpointer], verbose=1, epochs=100)\n",
        "\n",
        "#Print F1 score of best\n",
        "model.load_weights('/content/drive/MyDrive/CSC180_Project3/resnet50/best_weights.hdf5')\n",
        "pred = model.predict(new_x_test)\n",
        "pred = np.argmax(pred, axis=1)\n",
        "print('F1 Score: ' + str(metrics.f1_score(np.argmax(new_y_test, axis=1), pred, average='micro')))"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training ResNet50\n",
            "Epoch 1/100\n",
            "1563/1563 [==============================] - 21s 12ms/step - loss: 2.0958 - accuracy: 0.2056 - val_loss: 1.8779 - val_accuracy: 0.2988\n",
            "Epoch 2/100\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 1.8480 - accuracy: 0.3137 - val_loss: 1.7731 - val_accuracy: 0.3456\n",
            "Epoch 3/100\n",
            "1563/1563 [==============================] - 18s 12ms/step - loss: 1.7779 - accuracy: 0.3442 - val_loss: 1.7227 - val_accuracy: 0.3637\n",
            "Epoch 4/100\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 1.7458 - accuracy: 0.3587 - val_loss: 1.7228 - val_accuracy: 0.3642\n",
            "Epoch 5/100\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 1.7237 - accuracy: 0.3706 - val_loss: 1.6750 - val_accuracy: 0.3882\n",
            "Epoch 6/100\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 1.6970 - accuracy: 0.3817 - val_loss: 1.6833 - val_accuracy: 0.3896\n",
            "Epoch 7/100\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 1.6861 - accuracy: 0.3847 - val_loss: 1.6803 - val_accuracy: 0.3898\n",
            "Epoch 8/100\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 1.6686 - accuracy: 0.3915 - val_loss: 1.6760 - val_accuracy: 0.3867\n",
            "Epoch 9/100\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 1.6510 - accuracy: 0.4036 - val_loss: 1.6431 - val_accuracy: 0.3975\n",
            "Epoch 10/100\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 1.6460 - accuracy: 0.4047 - val_loss: 1.6283 - val_accuracy: 0.4075\n",
            "Epoch 11/100\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 1.6449 - accuracy: 0.4072 - val_loss: 1.6927 - val_accuracy: 0.3904\n",
            "Epoch 12/100\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 1.6250 - accuracy: 0.4103 - val_loss: 1.6342 - val_accuracy: 0.4093\n",
            "Epoch 13/100\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 1.6103 - accuracy: 0.4181 - val_loss: 1.6469 - val_accuracy: 0.3965\n",
            "Epoch 14/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 1.6025 - accuracy: 0.4243 - val_loss: 1.6594 - val_accuracy: 0.4011\n",
            "Epoch 00014: early stopping\n",
            "F1 Score: 0.4075\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "source": [
        "### Training VGG16 with Upsampling\n",
        "Below I train my model that incorporated transfer learning using VGG16 with an Upsampling layer. Note, I reset my data before training so I can train on 32x32 images upscaled using the Upsampling2D layer."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwBB4l_FzAjE",
        "outputId": "2ee6db9e-b886-44b6-8278-13d147ceed37"
      },
      "source": [
        "#Reset data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "y_train = y_train.reshape(50000)\n",
        "y_test = y_test.reshape(10000)\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "#Define callbacks\n",
        "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=4, verbose=1, mode='auto')\n",
        "checkpointer = ModelCheckpoint(filepath='/content/drive/MyDrive/CSC180_Project3/vgg16withUp/best_weights.hdf5', verbose=0, save_best_only=True)\n",
        "\n",
        "#Compile\n",
        "model = getVGG16Upscaled()\n",
        "model.compile(loss=categorical_crossentropy, optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "#Fit\n",
        "print('Training VGG16 with Upsampling')\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), callbacks=[monitor, checkpointer], verbose=1, epochs=100)\n",
        "\n",
        "#Print F1 score of best\n",
        "model.load_weights('/content/drive/MyDrive/CSC180_Project3/vgg16withUp/best_weights.hdf5')\n",
        "pred = model.predict(x_test)\n",
        "pred = np.argmax(pred, axis=1)\n",
        "print('F1 Score: ' + str(metrics.f1_score(np.argmax(y_test, axis=1), pred, average='micro')))"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training VGG16 with Upsampling\n",
            "Epoch 1/100\n",
            "1563/1563 [==============================] - 73s 45ms/step - loss: 1.4727 - accuracy: 0.4904 - val_loss: 0.9888 - val_accuracy: 0.6578\n",
            "Epoch 2/100\n",
            "1563/1563 [==============================] - 69s 44ms/step - loss: 0.9036 - accuracy: 0.6807 - val_loss: 0.9528 - val_accuracy: 0.6639\n",
            "Epoch 3/100\n",
            "1563/1563 [==============================] - 69s 44ms/step - loss: 0.7819 - accuracy: 0.7264 - val_loss: 0.8459 - val_accuracy: 0.7063\n",
            "Epoch 4/100\n",
            "1563/1563 [==============================] - 69s 44ms/step - loss: 0.7083 - accuracy: 0.7530 - val_loss: 0.8057 - val_accuracy: 0.7177\n",
            "Epoch 5/100\n",
            "1563/1563 [==============================] - 69s 44ms/step - loss: 0.6293 - accuracy: 0.7804 - val_loss: 0.8440 - val_accuracy: 0.7081\n",
            "Epoch 6/100\n",
            "1563/1563 [==============================] - 69s 44ms/step - loss: 0.5886 - accuracy: 0.7988 - val_loss: 0.8133 - val_accuracy: 0.7274\n",
            "Epoch 7/100\n",
            "1563/1563 [==============================] - 69s 44ms/step - loss: 0.5584 - accuracy: 0.8044 - val_loss: 0.8004 - val_accuracy: 0.7389\n",
            "Epoch 8/100\n",
            "1563/1563 [==============================] - 69s 44ms/step - loss: 0.5087 - accuracy: 0.8231 - val_loss: 0.9434 - val_accuracy: 0.7095\n",
            "Epoch 9/100\n",
            "1563/1563 [==============================] - 69s 44ms/step - loss: 0.4872 - accuracy: 0.8282 - val_loss: 0.8973 - val_accuracy: 0.7257\n",
            "Epoch 10/100\n",
            "1563/1563 [==============================] - 69s 44ms/step - loss: 0.4429 - accuracy: 0.8458 - val_loss: 0.9055 - val_accuracy: 0.7272\n",
            "Epoch 11/100\n",
            "1563/1563 [==============================] - 69s 44ms/step - loss: 0.4157 - accuracy: 0.8548 - val_loss: 0.8920 - val_accuracy: 0.7247\n",
            "Epoch 00011: early stopping\n",
            "F1 Score: 0.7389\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ps2CZ8Xwrz_a"
      },
      "source": [
        "### Training Results\n",
        "Below you will find the code I used to print out my results for my models trained using transfer learning. You will find each models scores for precision, recall, F1 score, and their classification report. In addition, I printed out the confusion matrix for each model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQzTS4ZlIJTq"
      },
      "source": [
        "vgg16_model = tf.keras.models.load_model('/content/drive/MyDrive/CSC180_Project3/vgg16/best_weights.hdf5')\n",
        "vgg16Up_model = tf.keras.models.load_model('/content/drive/MyDrive/CSC180_Project3/vgg16withUp/best_weights.hdf5')\n",
        "dense_model = tf.keras.models.load_model('/content/drive/MyDrive/CSC180_Project3/denseNet/best_weights.hdf5')\n",
        "res_model = tf.keras.models.load_model('/content/drive/MyDrive/CSC180_Project3/resnet50/best_weights.hdf5')"
      ],
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMRuLfS3fOg8",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0035435e-d7e4-46b3-b90d-c1b22c7e573d"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import metrics\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "print('Transfer Learning: VGG16 Model')\n",
        "print('==============================')\n",
        "pred = vgg16_model.predict(new_x_test)\n",
        "pred = np.argmax(pred, axis=1)\n",
        "cm = confusion_matrix(np.argmax(new_y_test, axis=1), pred)\n",
        "plot_confusion_matrix(cm, list(range(10)))\n",
        "print('Model Precision: ' + str(metrics.precision_score(np.argmax(new_y_test, axis=1), pred, average='micro')))\n",
        "print('Model Recall: ' + str(metrics.recall_score(np.argmax(new_y_test, axis=1), pred, average='micro')))\n",
        "print('Model F1 Score: ' + str(metrics.f1_score(np.argmax(new_y_test, axis=1), pred, average='micro')))\n",
        "print('\\nModel Classification Report:\\n' + str(metrics.classification_report(np.argmax(new_y_test, axis=1), pred)))\n",
        "\n",
        "print('\\nTransfer Learning: VGG16 Model with Upsampling')\n",
        "print('==============================================')\n",
        "pred = vgg16Up_model.predict(x_test)\n",
        "pred = np.argmax(pred, axis=1)\n",
        "cm = confusion_matrix(np.argmax(y_test, axis=1), pred)\n",
        "plot_confusion_matrix(cm, list(range(10)))\n",
        "print('Model Precision: ' + str(metrics.precision_score(np.argmax(y_test, axis=1), pred, average='micro')))\n",
        "print('Model Recall: ' + str(metrics.recall_score(np.argmax(y_test, axis=1), pred, average='micro')))\n",
        "print('Model F1 Score: ' + str(metrics.f1_score(np.argmax(y_test, axis=1), pred, average='micro')))\n",
        "print('\\nModel Classification Report:\\n' + str(metrics.classification_report(np.argmax(y_test, axis=1), pred)))\n",
        "\n",
        "print('\\nTransfer Learning: DenseNet201 Model')\n",
        "print('====================================')\n",
        "pred = dense_model.predict(new_x_test)\n",
        "pred = np.argmax(pred, axis=1)\n",
        "cm = confusion_matrix(np.argmax(new_y_test, axis=1), pred)\n",
        "plot_confusion_matrix(cm, list(range(10)))\n",
        "print('Model Precision: ' + str(metrics.precision_score(np.argmax(new_y_test, axis=1), pred, average='micro')))\n",
        "print('Model Recall: ' + str(metrics.recall_score(np.argmax(new_y_test, axis=1), pred, average='micro')))\n",
        "print('Model F1 Score: ' + str(metrics.f1_score(np.argmax(new_y_test, axis=1), pred, average='micro')))\n",
        "print('\\nModel Classification Report:\\n' + str(metrics.classification_report(np.argmax(new_y_test, axis=1), pred)))\n",
        "\n",
        "print('\\nTransfer Learning: ResNet50 Model')\n",
        "print('=================================')\n",
        "pred = res_model.predict(new_x_test)\n",
        "pred = np.argmax(pred, axis=1)\n",
        "cm = confusion_matrix(np.argmax(new_y_test, axis=1), pred)\n",
        "plot_confusion_matrix(cm, list(range(10)))\n",
        "print('Model Precision: ' + str(metrics.precision_score(np.argmax(new_y_test, axis=1), pred, average='micro')))\n",
        "print('Model Recall: ' + str(metrics.recall_score(np.argmax(new_y_test, axis=1), pred, average='micro')))\n",
        "print('Model F1 Score: ' + str(metrics.f1_score(np.argmax(new_y_test, axis=1), pred, average='micro')))\n",
        "print('\\nModel Classification Report:\\n' + str(metrics.classification_report(np.argmax(new_y_test, axis=1), pred)))"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Transfer Learning: VGG16 Model\n",
            "==============================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Model Precision: 0.7002\n",
            "Model Recall: 0.7002\n",
            "Model F1 Score: 0.7002\n",
            "\n",
            "Model Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.70      0.75      1000\n",
            "           1       0.80      0.82      0.81      1000\n",
            "           2       0.59      0.71      0.64      1000\n",
            "           3       0.54      0.53      0.54      1000\n",
            "           4       0.60      0.68      0.64      1000\n",
            "           5       0.69      0.52      0.60      1000\n",
            "           6       0.64      0.78      0.70      1000\n",
            "           7       0.74      0.76      0.75      1000\n",
            "           8       0.85      0.77      0.81      1000\n",
            "           9       0.83      0.73      0.78      1000\n",
            "\n",
            "    accuracy                           0.70     10000\n",
            "   macro avg       0.71      0.70      0.70     10000\n",
            "weighted avg       0.71      0.70      0.70     10000\n",
            "\n",
            "\n",
            "Transfer Learning: VGG16 Model with Upsampling\n",
            "==============================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Model Precision: 0.7389\n",
            "Model Recall: 0.7389\n",
            "Model F1 Score: 0.7389\n",
            "\n",
            "Model Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.76      0.79      1000\n",
            "           1       0.85      0.85      0.85      1000\n",
            "           2       0.58      0.73      0.65      1000\n",
            "           3       0.61      0.47      0.53      1000\n",
            "           4       0.65      0.73      0.69      1000\n",
            "           5       0.60      0.68      0.64      1000\n",
            "           6       0.82      0.73      0.77      1000\n",
            "           7       0.79      0.80      0.79      1000\n",
            "           8       0.85      0.85      0.85      1000\n",
            "           9       0.89      0.80      0.84      1000\n",
            "\n",
            "    accuracy                           0.74     10000\n",
            "   macro avg       0.75      0.74      0.74     10000\n",
            "weighted avg       0.75      0.74      0.74     10000\n",
            "\n",
            "\n",
            "Transfer Learning: DenseNet201 Model\n",
            "====================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Model Precision: 0.7185\n",
            "Model Recall: 0.7185\n",
            "Model F1 Score: 0.7185\n",
            "\n",
            "Model Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.73      0.77      1000\n",
            "           1       0.72      0.88      0.79      1000\n",
            "           2       0.63      0.71      0.67      1000\n",
            "           3       0.51      0.61      0.56      1000\n",
            "           4       0.70      0.64      0.67      1000\n",
            "           5       0.82      0.46      0.59      1000\n",
            "           6       0.63      0.88      0.74      1000\n",
            "           7       0.88      0.71      0.78      1000\n",
            "           8       0.89      0.79      0.83      1000\n",
            "           9       0.78      0.77      0.78      1000\n",
            "\n",
            "    accuracy                           0.72     10000\n",
            "   macro avg       0.74      0.72      0.72     10000\n",
            "weighted avg       0.74      0.72      0.72     10000\n",
            "\n",
            "\n",
            "Transfer Learning: ResNet50 Model\n",
            "=================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Model Precision: 0.4075\n",
            "Model Recall: 0.4075\n",
            "Model F1 Score: 0.4075\n",
            "\n",
            "Model Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.41      0.45      1000\n",
            "           1       0.41      0.57      0.47      1000\n",
            "           2       0.30      0.40      0.34      1000\n",
            "           3       0.29      0.10      0.15      1000\n",
            "           4       0.40      0.23      0.30      1000\n",
            "           5       0.44      0.35      0.39      1000\n",
            "           6       0.39      0.56      0.46      1000\n",
            "           7       0.42      0.44      0.43      1000\n",
            "           8       0.51      0.50      0.50      1000\n",
            "           9       0.41      0.51      0.45      1000\n",
            "\n",
            "    accuracy                           0.41     10000\n",
            "   macro avg       0.41      0.41      0.39     10000\n",
            "weighted avg       0.41      0.41      0.39     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkatwrTod_ii"
      },
      "source": [
        "### 3-5 Images with Predicted and True Labels\n",
        "Using all of the models produced with transfer learning, I choose 5 random images from my test set and print out the predicted label for each model along with its actual label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoRepUWbd_ii"
      },
      "source": [
        "import random\n",
        "\n",
        "#We will show predicted scores of all transfer learning models\n",
        "vgg16_pred = vgg16_model.predict(new_x_test)\n",
        "vgg16_pred = np.argmax(vgg16_pred, axis=1)\n",
        "\n",
        "vgg16Up_pred = vgg16Up_model.predict(x_test)\n",
        "vgg16Up_pred = np.argmax(vgg16Up_pred, axis=1)\n",
        "\n",
        "dense_pred = dense_model.predict(new_x_test)\n",
        "dense_pred = np.argmax(dense_pred, axis=1)\n",
        "\n",
        "res_pred = res_model.predict(new_x_test)\n",
        "res_pred = np.argmax(res_pred, axis=1)\n",
        "\n",
        "#Get a random 5 images to show\n",
        "randList = random.sample(range(0, x_test.shape[0]), 5)"
      ],
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "OEDfV5Q7L2Zv",
        "outputId": "7b723268-b68e-45d2-8c62-d52ad2aa54e7"
      },
      "source": [
        "#Show the first image\n",
        "print('VGG16 Predicted: ' + className[vgg16_pred[randList[0]]])\n",
        "print('VGG16 with Upsampling Predicted: ' + className[vgg16Up_pred[randList[0]]])\n",
        "print('DenseNet201 Predicted: ' + className[dense_pred[randList[0]]])\n",
        "print('ResNet50 Predicted: ' + className[res_pred[randList[0]]])\n",
        "print('True: ' + className[np.argmax(new_y_test[randList[0]])])\n",
        "plt.imshow(new_x_test[randList[0]])"
      ],
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VGG16 Predicted: Bird\n",
            "VGG16 with Upsampling Predicted: Bird\n",
            "DenseNet201 Predicted: Bird\n",
            "ResNet50 Predicted: Bird\n",
            "True: Bird\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f6e30ded650>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 218
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "EH8ONFXcL3fQ",
        "outputId": "00b2dfeb-efe7-44e7-c4df-66dcff6bdc54"
      },
      "source": [
        "#Show the second image\n",
        "print('VGG16 Predicted: ' + className[vgg16_pred[randList[1]]])\n",
        "print('VGG16 with Upsampling Predicted: ' + className[vgg16Up_pred[randList[1]]])\n",
        "print('DenseNet201 Predicted: ' + className[dense_pred[randList[1]]])\n",
        "print('ResNet50 Predicted: ' + className[res_pred[randList[1]]])\n",
        "print('True: ' + className[np.argmax(new_y_test[randList[1]])])\n",
        "plt.imshow(new_x_test[randList[1]])"
      ],
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VGG16 Predicted: Automobile\n",
            "VGG16 with Upsampling Predicted: Automobile\n",
            "DenseNet201 Predicted: Automobile\n",
            "ResNet50 Predicted: Automobile\n",
            "True: Automobile\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f7189865b90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 219
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "iffcF_ARMZ6R",
        "outputId": "7fb27912-317f-4821-927c-2ad5519d1072"
      },
      "source": [
        "#Show the third image\n",
        "print('VGG16 Predicted: ' + className[vgg16_pred[randList[2]]])\n",
        "print('VGG16 with Upsampling Predicted: ' + className[vgg16Up_pred[randList[2]]])\n",
        "print('DenseNet201 Predicted: ' + className[dense_pred[randList[2]]])\n",
        "print('ResNet50 Predicted: ' + className[res_pred[randList[2]]])\n",
        "print('True: ' + className[np.argmax(new_y_test[randList[2]])])\n",
        "plt.imshow(new_x_test[randList[2]])"
      ],
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VGG16 Predicted: Ship\n",
            "VGG16 with Upsampling Predicted: Truck\n",
            "DenseNet201 Predicted: Truck\n",
            "ResNet50 Predicted: Ship\n",
            "True: Truck\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f7098368610>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 220
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD7CAYAAACscuKmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO19a6wlWXXet6rqPO6jX2OgM2ZQwDGyxY94sEYYy5aDIVjEscwfC/mhaBKNNH+cCCuODCRSZEeJhP/4ISWyNAqOR4pjwK8MQpZtMgFFkSJME7ANjDFjDGYm0/Pquff2vfe8qmrnxzn37m+tql19prvvuWNqfVKrq86u2rVrV+1b6/ktCSHA4XB88yM77wE4HI7NwBe7w9ET+GJ3OHoCX+wOR0/gi93h6Al8sTscPcEdLXYReZeIfFlEnhSR99+tQTkcjrsPuV0/u4jkAP4SwDsBPAXgMwB+IoTwpbs3PIfDcbdQ3MG5bwHwZAjhqwAgIh8G8G4AycV+6fLlcPXeb21ty7IoZOSZFjjyPGs9LhNRxwnv3+YfMXWW6SPVY/NS617bjn/N05I9dLRKsuXMcXuz8bcD6Xei490xJwX+oX2zicRkPfU3f4MbL77Y2noni/21AL7B1wHwPV0nXL33W/EfH/2vrW3bW+PT7Qs726rt8sULp9u721un2+PBQB03oD8E0rHY+UHU5jjer+tat9V8Xt36O6Afnh2GqPWX/mNl/5CljrNHqbaO/rr6QMcYNULL1mo/hNbtBqj7rGM+1B9yc1zoWhaJv3dd99W4F96270vinajMO1FyW6Xfq7Kq2vuz4+A5yNo18B/5wX/Q+juwAQOdiDwsItdE5Nr+3ktnfTmHw5HAnSz2pwG8jvbvW/2mEEJ4JITwQAjhgUuXr9zB5c4G0vHvPMfyzYtg/r1CcFdehPRJa3fXcWDXENfp+04W+2cAvFFE3iAiQwA/DuBjd9Cfw+E4Q9y2zh5CKEXknwP4IwA5gF8PIXzxro3M4XDcVdyJgQ4hhD8A8Ad3aSwOh+MMcUeL/eUihID5dN4+ELI0LoyV3VrFTyDGwpx1WONT+kyXFdlOTsrCbK3BfOmGC0a5Vho+mNbzujwG9g7YyszbtdHYMupjXWt800EQfwhBP6OqrqgtXiszVmT2EohpS1vj7SjSLsbkcbZtPadD83lm3MandHh5ujxAyhukj6tot0I7urw4Hi7rcPQEvtgdjp5go2J8XQdM5+1ivNCfncFAD+t4Mj3dLiiaLlRamCmLeF5ho/DoAlo8bIykddMe2xXk0QUt4uu2OqEmiFFjOgNWJLmj+0j012hE+lo1ieplVaq2+SI+Zz5vYFS0gp9ZoZ+7UsuQFukz9WyhkQgeaqgFgdtsH7wpqSaEjrnP2y/V+IUldyvGlzSPZSJQqUvd8S+7w9ET+GJ3OHoCX+wOR0+wWZ091JjMZ8sdo1rUHPZv1Y4s/jAjnd8mwoyHcX9k2oZF3B8UUYPqdAU1dPb2tkYCR8bHpfu395mR0qf0YzPGTrdfYqfpAkwnsbCrk/tfLBbquOks2lIm04lqO54ctw5kvLWljhuNhqfbDX0+j68nz2OW5eq4nPZtxmQm7RmTzePSNoF1LTLdwb8drk76hUfF79GyC2UhaL1K11j9y+5w9AS+2B2OnmCzEXQAFqGKOwz23MzMeSSbzMilMzSumq3h6HT7ghEXt8YxX34UorhY5FoklJDaMSIWj08PV+eR26iwNUV8nW/eoSZ0uIJ4J2i/kBbjbd4+bVdlfDAstgPAwc2D0+2bhwe67fAmXSv2uG24Cra343PZ3hqpNnbBsuie5/q5F3l8nnlm3HcJ8b+wx2Vdql36m5h2dVl3JonxDfWw3S1sD+T3I09d111vDofDF7vD0RNsVIyHAMjbxYyShMdgrL5M6XNqzQcwMGL87jieZ0WxPM9bt620xdRCVrwVjnSitoWJHquVyGZEQrYI5+kxDnKOLNOqBqseuRg1JGPLLm03ZUcalG7jOSjLOKeTyZE6bv/m3un2jZduqLaX9iMrUUWRjjs7Wr26eCHuX76kxfitrWipzwt+ftpqn+fxvEx0WwYWzwe0rd+dPI/XKmh7eSzNsXmemvqLGhpRiXFO7QpQ7yarE1bFZP5FtEM6fAL+ZXc4egJf7A5HT+CL3eHoCTars8NmBkXwz7XROxTVLif3m+OGVUHHGcKLhEej4TqhTKOuqLMFjelopn2Fc9LhbR/sKuuyK7BbcWgps1V2n40mY179NMd+VyTfjFxsB+RSu2HYgV+48Xxsu/Giatvb3z/dDsoGsKuOq6sYaVdV+l62xu32jcJGRw6j3l/kWu/PlZ4+bP0dAPIinlcUuo+MdHir60tijhvuTLJ9WHVeRQDSO1AUdozkiszbl67NlGP4l93h6Al8sTscPcHGxfhUAH/WkczAoja35cYllVPE1WBoRD0S/Xi7kRCRpUUxlr8qug9LJDAh1+G81G5EdkNZeY5FwgG74YyLcVR0RACqKKv1Ej9svsV0GkXrG3vRpfYiie0A8Pzzz51u7+/vqbbj49gHR7xZlSSTqPJMjo51WxbnLs/jXHHyDADs7Oycbm+NtWtvOGTxnF15ug8lxltVgNryfKzatDgdJ7IqNbHKbDpLtrFum5ErdTDQYxwO47WHW1odOu27TrHT+Zfd4egNfLE7HD2BL3aHoyfYrM4eAuoqoVN0EDgmecG7KpM2ss3WI5yUjv5ZuZWKiC/NcRUTA1rSwIqrv6b1qwX1X5SGzDGP+02ecCZJaLd1ACaDz7gpj45ixtpzz18/3b5x4wV1HOvps6nOiOO7HpJdQYyNYTaP93LTuPZmk+j2q0PMdhwU+l52d2Mm3fa21tnH4xFtk8470nr5kLMih1bvJ9feQLcpOwDdm611MJtF+0O10M8zlMSrz3Yb43objuJ9jmqTGnpyXRO6zbjll11Efl1EnhORL9Bv94jIJ0TkK6v/X3kVGx0Oh8I6YvxvAHiX+e39AB4PIbwRwOOrfYfD8QrGLcX4EML/EpHXm5/fDeBtq+1HAXwKwPvW6OuUx6xBza2yzWxGEmcdsaiUztayIjK7JEpVmsiI4BW36TFyxFvoUBk40kkLYkBGkWCNaKdESaZGkB8JyZXlzi/bo/ca4j7NVWXcg/vkbnv6mf/X+jugxVEb1bZ78eLp9s7uhdPt7W1NXnFEBBgvvKCz6p6//mw8jlSLutai6ngUr7011u6qre0oru/sRhF896Iex8WLO7R9QbXxmNmVBwCjEasJ7SI9YMhCKvPcF+3u2Nq8V2UVxyHSLsaH+g7E+ASuhhCeWW1fB3D1NvtxOBwbwh1b48PyT1YyIFdEHhaRayJy7fDgIHWYw+E4Y9yuNf5ZEbk3hPCMiNwL4LnUgSGERwA8AgCv+3vfFqbGanuCkpNAGokOUTxicoZmOSK2gmtrKCfTMK+apWlelJx0Y8grSBSeUZRcacg2AvXRpJmO92mTghQtNKs1HQk5doyp6qnBiJWs5kxNIs/BURSnX9qLCS3HhzrCbWsrWrC3KIoNAC5evny6vbMbo72shZmt+CHoMc4XcYKOjuJ4Z2a8RR73hwPdx5gIMLZ24vh3bhoijoO4f+mipsUe0ftnq9UyLTmTbYyNOjFkymyTvDTg8lj0TgzNp3g4ivM9mOsxnqCu2surAbf/Zf8YgAdX2w8CeOw2+3E4HBvCOq633wLwfwB8h4g8JSIPAfgggHeKyFcA/MPVvsPheAVjHWv8TySa3nGXx+JwOM4Qmy3/VNU4NLrS6UDIXTU20U0qk4t0pEbZIs5EM5lFC9LTS9abM6Pb03EL69aq2vXcw6PD5HGDoSEvVG5EcwOkxNfUaO+TdX1LaJkrcsR4oM0CLMt43mSi9T+2W3CEWzDklhcvxViqe151j2q7dPnS6faIdE1rf9iiiLd7XvUtZozRFlLQPE6Ote2A7Q+Z4fofDtvJIo+O9XGzRXyex0f6wZTkYty7sWfa4nmjUXyHd3Z1dtzlK9EVeXFXR+FdIv1+hxT1LbM6t6j/rW0dbXiCatHukgM8Nt7h6A18sTscPcFmyz+FgCoRqM+CU2XIGmpOHqHt0iQUzCnZYDrQ4oxyd5CLrmhEKcU+G9FpdO05VZOtjOuNo6C04AsMmCPOuGBYsOQoP0tIUNVpDnKd5NNRhqqjTJCStEl0LwZavdqmyLgLFDEHANvkiuMyTjYRiqPaXvUaLcYXlPDCUXhW7WDXp8C4xgYUsUhuM+tu5GdbGRfgZBr73zvQ5x0fRhVOhMtc6bk6nMT36vJF7aa8SRGAI3pMeaWvNaRlwW4+xnTqYrzD0Xv4Ync4egJf7A5HT7BRnV1EMBhYLXaJIZMSmtBOztiq2S1k3GuhjDpTbv6OVZRpNBtGHWxgdNlU5hmgySj5rMKSaGTsPtFTrAkQjW2CtufkApyZrLSaylZ3hdIG5Yo0xJdlOruPa6mNiMDRzseIySCMi5FJModMDFroXgqhjDJ5tWq7RGG209fEe57PLYlnnCuxrjd63xZl7GP/4KY67ngSw3YXC63339yKerlNVDwgt+JkGm0JwbB4LiiT8+DY9H8Yrz0/jn3s39DutYqe+9aWzadc9X3oOrvD0Xv4Ync4eoINi/HMH2bEORanLX8XiVgTLpW80Bk+BakCLA4BwGQ7uju2Wfwc6ClgDrDClFRmjnbmlJ8bFyDzvZWlvpeioGw286dWlVtW/O96rnKaO8tZz25Anp/SuO8WNOb5TM8j3xvzsBeG+228RXzqhsM/sOtQcazp8RZUwvvCBR11trsdRVWObKwqm9FIrkija/AznJG7dDDSYvDhEYvxeq44ys/y0h9ejurAzcO4XRoXY8ERjJazcB6PnZMyd1jqd3M6ieM/mLe7sC0lPcO/7A5HT+CL3eHoCTZujbeW9hME4pNjcQsAZmTl5CSIyZG2qLK4e/HiJdV28UKM8NrdiVZetigDQDHgEkEdXHhk6ba8Xyzul4ahYk5egdHIiHp5IsnHWsvpb7TJ48Gc5mf/IBJPHBiWoDmJ+7khlODoOuZws1FbTNNsS0jxM5tR5Jol82DpdmdLf3sGQ4qcDEQqYkzizEVoeQkVHwj9zEkryzaKeBPddpmSev7OVe0xYBXoiEg/jqdajZySB8Gqdqy1To6jOrF7SUclHlF5rPm8naSi+NKXW38H/MvucPQGvtgdjp7AF7vD0RNsNuutDliY6KcT1ORCsq6gI8osOqKSQzf3XjSdROVnclPrqIc7MWuKCRDHxpWSD9M6OxNPsI4qsO6keB4TNwDAeMRlhrQOXJAbUJNQQIPmajbTuuHBQZwfLs+0Z0orcebc9o7mSR9vxTkZjaNSPTBuysU8RmstZppQgrPBONNtaOZ0h9xruWHZlzG57LCgbT3fGZjEU3+/mARkkEXbytbQ2kvI7ZkbWw3ZNAa5HiMTZ0wmcd6OjOv3gMg6Z8ZtxkSbC3LDXbqgs+NYZ7952E4CY58Rw7/sDkdP4Ivd4egJNirGV3WFg4PD1raQR/G2SUoRxcXZhNwbN/fVcYsZRdoZt9z+iERT5t82ojSL7lmeJnxgMojC+J1Y3M87RMLCuLy4hBK32VJCHIBly1wxJxq7v44nWszm+9SFkPT12B1YmWqyN16Ic3xo1Ka9G7FUFJdr2iUVCgCuXI5Xr0tN+HBhi0hGEO+ryLQYz3NsRXBOSsrJDbo9NO47phkxz501KpvHFcgNOCBVwEZfMlfgbGbGCOKlr2If1a6ej8lxfG/39ttd2IOi/XfAv+wOR2/gi93h6Al8sTscPcFmdfZFiRevt5eFy8fRzWDJEGvSxZlcsDQhg/MZZy5p/ZKJ+Fg3tjo16+ldpIw5HTfoCqs1riCuLdfgfKexDChsN+vQ2a3bj8kbOPOsNPr2kLj5be00vt6U59TM900igDg+1DaSyXHcz0mXFeO64qmTStsV9nNy0y5iWy7aTjGkmFvLj1+Qks33ZV10IBtJZog12X5SGpJQDv+tyZ2ZmRDqoRApZmHinynEV4jgMzNEHyNuq9vJK3iuLdYp//Q6EfmkiHxJRL4oIu9d/X6PiHxCRL6y+v/KrfpyOBznh3XE+BLAz4YQ3gTgrQB+WkTeBOD9AB4PIbwRwOOrfYfD8QrFOrXengHwzGr7pog8AeC1AN4N4G2rwx4F8CkA7+vqazGb4fpff7W1bYey1IYmqo1Fa854yoxImOdcWtdws9Xt3POA4WRn0gErbVH2FovqYWwi6CypG4+D2iwJA4v1yi1n1AkuG2zFeFYvmDPPaiQ8j3muRfBDivY6Oo6i+/FEi/uT47ifGXfYBSp/tH0hPs/tbe16Y9H3+nPalToh1+ohbdem9sCIiCjGY/1Kb42oFDiVVrJu1QGVVB6b8tOsJgyt249JRliEtqoob5vMPJb4hdyDtqZBQc99d9AeiZpL+t17WQY6EXk9gDcD+DSAq6s/BABwHcDVl9OXw+HYLNZe7CKyC+B3AfxMCEFFUITl56r1T4qIPCwi10TkmjUEORyOzWGtxS4iAywX+m+GEH5v9fOzInLvqv1eAK1m9hDCIyGEB0IID4xMdVaHw7E53FJnl6X/6UMAnggh/BI1fQzAgwA+uPr/sVv1VZUlDl54vr2NXDzjHa3XDbZjSCXrq1Y1DuQGsXXaOCOOjxOjNyvedUN8yZliNoRVHTdIs/6xjlp1sAMWBYXxWv1P8aTr89gNqLL2Mv2oSx6HaJfagso57+3HkNvDY60nzilDy7LYbF+KmXT5iJ5nobMAyzJKe5Op/vbcOIhjfP4FKpc91eMgLyXGhv1nexSf55BcXmJ07yHp/du7psYaZZJl5p3g0F22Cdiw1XzALlfjSqVvLrtfRwNtk+Ko7Mb7vUKHuWgtP/v3AfgnAP5cRD6/+u1fY7nIPyoiDwH4OoD3rNGXw+E4J6xjjf/faGZUn+Add3c4DofjrLDhks21inLTjcwHr8W0EUV/Sc6J/vo4jporTR8s3RTkdhJYEZmJDY0YT22cXRUsecUi3cZqgu2fOetZ1cgsIQNFxtkov5zESs6gKitDsEjliPJat82reL39aXSbHc+1zaVc0Dwad+k8u0LbUQ3Ljdspp2yzYqxJQgvqsiQ31FGtxWyh+T4yc3pIBBt5iNt1pVWXnKL1DN+IErsXhngiJ6ca0ejDJFOiGMT7HhnO+i2qaTDeinM1NmWfc5Ljq1k74WRp61MRPDbe4egJfLE7HD3BhsV4YGGs3yeoppTsYksaUfJBTpbR2iR3cFRYQ5gRjibL2n5edULjtSI4H0ZqR8Myqjq1YjxH8hkCBRLBM66ymneIZpawne6tCnGuppWWK8uSog1LbR2ekzX+iKTFmaluWlNZp8lc93HzmCzMJLVOC2PN5udiyCtmIYq3U5S0rVUGfo1zI8aXIUYDCqkr1cKQS9Bzys291HU8djo1xBMUsbZDZBujgR5Hzvx3Y/3MLtKz3mV+QZPUws+6nLa/E2X78lqen25yOBzfTPDF7nD0BL7YHY6eYLM6O4Aqa//7wtFptY0sU+4TcjsZ3Z5V5dySGFBE05AynKzOzlFtNsJNEUDQiYVhIWTdympWXNMuWDcJu+XIDiBGL+d7KUyUVU6Rd3WIOvB8YcgLy3heBT1+vu3Fgl15ej44km96rJXFF56PYz6mcsijob4WT10uuo/JJDYel1FPN+o2ciKbsK9XLVHvz8hlJ4V2ATPRx9y4Bxf0TZyZyElFYsJmkUy7fpmYIxjbx3ARTyzIXgLjXRMq7DeftivntevsDofDF7vD0RNstmRzlmFgSiSfgMXW3HJuK0KGtNtMiVRGvB1Q1NKISg3nRu5TYrxxE1oet3jdtGgnmY1+i2Jx2SgDRK63jEV1/ZhGYy5RZUK1qNxwOYv3vDjWY2QeikVlXZhEjlFHWbKutGhaUcRitdAPgznmJ4dE/jDU91IU9GwN8QK7aWeUdMPlkgAbBanHoSIHuXR0g5gk9r8odWNJEYWlKVHFfPMzctHVYsR4epWyYNQhLhGtykVb0hIeb5prLgX/sjscPYEvdoejJ/DF7nD0BBvV2fMix8UrF1vbWP+zmVwFl1Em/djq7Cn3GqD19BHZDXJDMkBqXSMrzdZVO0FmuMSZLNKOI5CuNTOZS3UilNhyoW9tx/GLIaWYzUjP3aMsQMNjPpvGay8W+r5CiPrmgFxIwej25ZzdlHrMc4muLXZXDYb6+8JeRTvfrDmz3aYwPP1FyVlw+qXg8sj8/Kx9gIlKShsWHFgXN8+IQnBnpL9XuSW5oGdoufNHXOI7bo9tYTmK5Q5F+3e6o9SBf9kdjr7AF7vD0RNsVIzPsgzbu7ZA8BIcNWd5tLKCRXdya1nSCHJRjbe0i29Mou+IiBZsBBqLgU2OO96mbK1gRFMWW03/ivO90CQMJc0BS2O2j9E2ZX0ZYouKSiPlgyhKC/S16iruV6UJ1SKRvy7idiOCjlKsrBgfaE5Kki3rhveSxWfdf0ZZX8xxl9t6AcynZ6Lfylm84ILEc7H86h0RnDU/jczUGSASk3JB7lJTumk4oHoBWybikvoYksq6NdZRj0JzJaFd5csSEaqAf9kdjt7AF7vD0RNsNoJOBCnu+ED0y438ECVaU6MRZTgBJTdRZwVlKbCFvCnGcwVWYw0li2qgv5OVJaEgkdBGp3EU3txE0FUJbrlgTKxC1VQzY42vVRReHMdAtBg/kEgRXYmJoFNVUhVlhx4HtVkuP0UWwr0Zj0YguT6UpqQRqQKsKmXmteVx2OQi9hjwfIuJYoMaR1qMD0aMDxTxxu9pPtDzUY/j+OfbJuqREpa4eu/Oli5DVajKwaaPk+tm1oIf4V92h6Mn8MXucPQEvtgdjp5gszo7gLy9/qMKpbLllpnYQrmuzHFDcqeMDeHDmNw4fJzla6zZtVdo+0I2iGWMKnYtTTURwmx6eLp9fLCn2qZHsTzydHKs2irS79mFYiPoxuR6G5kswmIY21SWWpio46SO+9alxnpvoPmwthSO+LMutUBzrEwOVmenMdaG65/19KqMryrXB1iOKx5nmpSNpCabgNgBs85u2pI2IwBB2NbEdgqT7cgRb7Vu4/c4p2sVxq06YDdfQmcXuQPXm4iMReRPRORPReSLIvILq9/fICKfFpEnReQjItJ+dYfD8YrAOmL8DMDbQwjfBeB+AO8SkbcC+EUAvxxC+HYALwF46OyG6XA47hTr1HoLAE7k0sHqXwDwdgA/ufr9UQA/D+DXujurUSfKP7HbzIrnObukSIzPjUtqi8S5HdHi4ph4x4uK3Vp6HHMuwWRIKaSg6D+K1FqU+p4O9mL5+mf/5muq7aVnr59uHx7sqzYuWcUVWG004M6FqE5cuueKarty9erpdkXiYjk/MteKKsRiZhM/OGIxqjJcTgrQVVxt8khQPP2kNln3HT3burJkHsT9NqWkHkOiEYiJwqoaTKIh4GQr4+aj94VdlquD6VrW9cZ8g1TfwHD9F9RnYeYgD3TfpGosptpdyupWnazieofln0QkX1VwfQ7AJwD8FYC9EE5H+RSA167Tl8PhOB+stdhDCFUI4X4A9wF4C4DvXPcCIvKwiFwTkWtT85fK4XBsDi/L9RZC2APwSQDfC+CyyGn40H0Ank6c80gI4YEQwgPjcXv0nMPhOHvcUmcXkVcDWIQQ9kRkC8A7sTTOfRLAjwH4MIAHATx2q77KssL+Czda2zImabTuOSYdoLbCkkWOKcvL6H/zY6r5xf62oc7CC1tRBy6gwxWzHaozR13M51piOdyP7rYXr19Xbc8//Q067kC1MdnlgEJ6t3b0GOckIdksp+1LRA5C4b02s62m/bq0+na8z4wIFmvr1qGQUxsG2/Bpxl7MfppQgnV9DkEOhvizIj3VaqzCujjbcUy4rCRDhAH1TRRLsKGKAyb7yKgPU8INg5yz5eJ2ZggqRK2RBEF8B3nFOn72ewE8Kssi1RmAj4YQPi4iXwLwYRH59wA+B+BDa/TlcDjOCetY4/8MwJtbfv8qlvq7w+H4W4CNRtAt5nN84+utqr12vdkEKj4O6ei3AWW6bRl3leUtO8Fw95La370a+7+YXdB9XKKIMXIBTo8P1XEcNXe0ryPoJjdjBN3culY4eopDlIz4rKKkGqI1uQ651JSRsgNn6hnut4z40wZFOstwzuWXTR9K5KTn1CjZRfs2c44z//KCo/qMq7DdC7U8j44VPs9GwilVwGQxcptxP6ppVPNj+6D326heQyJTGe9Gt+r40q46jsk8ZKIjIk+PSapPHhvvcPQGvtgdjp5go2J8WVa4ceOgtY2t8VYSEUWEwEQFhq6XrJqjsRZz8oQYvzM3f+92o0V/ONNRVrN5bONor9lEi/Es1s+MuLWYU+JHba3P7fx3NiiKxUobMZZCI7KKSyEZKzhX32KmbUt7pqLhrHWbulSP0xwXOkRfPR9pMZs9AY2quQnyDfvuqOQfc6NM/13BRhtSmyIOMeQVFM1YmWvPmdCE3qsFtNehEB6HiQA8GWsq0Qz+ZXc4egNf7A5HT+CL3eHoCTaqs9cBmCbcJKyPWH2H3TOs51YNnvHYtshMyWZ24zBPt+gpqMiVZUs0T46iLs4RaTNDQrFYxDZb9pnda5YsEuSSYRW7MgSIZUdZac7iUx46467KKFNsYDjO8wFFe2Wsa+rhVhR5x8SOAKBujRV4SwzBZCS6e54O5DwhxsZQKo+aaVOkmB2uwsCZldYtR6eZbMpUwapgaglwxtrMZH6+tBfds8MxlcEWbe8ZUumsat6ePZrKhgP8y+5w9Aa+2B2OnmCzHHRZhmw4bm0bjKPYXRRp7msWrctjLcrUXGbIlAgKeQxJC+SGs8dVJEwuDI/5jFxq5SJGv1n3WklEaNYRklOF12JoywAR+QFXpDXZggVx0mV2rkgWVkka0OJdTmJ8PtKvAffJGlXZcFe1cwMu99t3LN+d9ucZdxWNP+NrNyqpsvhsuucnoPgLjdrBYnyLAy9uGhdjYqehClA049xwFu69xAQbkWRkOtVrZTQiNa9qd73Zd5bhX3aHoyfwxe5w9AS+2B2OnmCzJZvzHNuXL7W2XbgQiSJGI61HM9nEbBbdWgf7OkyVXVSWT7iVT48AABf2SURBVJ0z4pjwISv0tTj8dGF4zOdTJmmMevrM6GALcgmKqb013CLOd5OZx4QVHN7LvwPA1nYks+BS1IDOMKsUgYfR2amE8HBodHayHVSK5NDWW06TNLLbTIU4G91eaMIb2Y6K3591dnMvfI4NpVV9spvP6OxMctFwqNHNWJcaX4/du+Y7KkQqOZ9qIpH9F8mNexj7u/G87qNQrBftYbEz0zfDv+wOR0/gi93h6Ak2LsZvXWoX4y9eib9v72jRlMXuKYnMtYmSY/FoYFxSXMqWI/Sy3ETQkdg6N5FOLOrNSYyfHmvXG6sTxUC7zQbDKJJfuHJRtY1JPOeS07asdEFtI0viGTjCkDPstAjOYjFHZgF6vmcsZhvRkae4NlF42Roi57JT5pQ3TaQaCJWVDiaCLqiaA7oPJcYr15tRO9jNZ1UB3rfuR+Vvo/eqMZB4XmXcY9Mqvj+LaWzLbqrDlFqT4ocvFx5B53D0Hr7YHY6eYPPW+IsJMf6ee063L1zQ1Mkc0TWhqLm5qYZ5fJNKHBnLMUtzBWVpZKLFfS7BNJvokkmo4rHzaRS9JsemtBKJ8VxxFQC2duL+Pfe+RrXtXoxiPUfJiTFTc7KDpXDmRCFFlFHayDUSzzMtErIIzqK6TZgZcgSgtaRnKpQvblqTu8pvMZZ6FoW5yq9VCziByAzEMMHFvg3rB4vudr51dpFNkqlbD2tQwamIQlsllkk1KOnLRhRSJhJHcKq+jJrB8C+7w9ET+GJ3OHoCX+wOR0+w8ay3wdZKHzc6zXCbIui2ddkldkMF0re3j7RrLJBOU5voN1a1iqI9Ug3QUVxWH2ayBtabLdnGcCv2Pyi0/WHnYuQCv3D5sm6jUsw5u66MHraYRxejLbc8p2wotj9Uhoij7tDt1LVHUS9v6sMUhWdtAir9jnVS831hl6BltGRwJKKxs9RIj1EhtNsRAEBUmeoGjUa8lo2goz5DB8GGigY0vPE5l9vikuFmFIpXvzHf8agU1v6yr8o2f05EPr7af4OIfFpEnhSRj4jI8FZ9OByO88PLEePfC+AJ2v9FAL8cQvh2AC8BeOhuDszhcNxdrCXGi8h9AP4xgP8A4F/KUs55O4CfXB3yKICfB/Brt+gJOE08MW4FrjgqVrQmEYvE+JGJLANFk9VDk0xDfXBUG5cpWl2dzjHuGRLXB5Sss3tJl4li94eNfhtT8gtH0wGa2KGaRdeKVUlKisCqKqtqUAQdc9VZMV5xzxuRk/xtY0rCGWkvIkbb9MwapBSJ5BdLcsEEGLVNtOFBkehukov0vlE1UuOw12JXpNhkFxbVrVuuParNusB0aSibNETEKqougnEccmTmqL38ueRp4pd1v+y/AuDnaJTfAmAvhFOH4VMAXrtmXw6H4xxwy8UuIj8C4LkQwmdv5wIi8rCIXBORa4tZOyOmw+E4e6wjxn8fgB8VkR8GMAZwEcCvArgsIsXq634fgNbyrCGERwA8AgC797xqzWJFDofjbmOd+uwfAPABABCRtwH4VyGEnxKR3wbwYwA+DOBBAI/dqi8RwcDq2afXiduL0uo7tE3utYHRTzLOALNljim7TYq046CuOPnfZorF7ZyIKnMzDl1qWLcVRUcYLOnVgbL7qoUmJKhI3ywr/fezJJ29pPOYBHN1cd5RTeyOZIINe59jCkluuPKUns512uxhpLNXNoyURpix3cYIpFaH5z6UTk1hxpZvX9ktrPuqPbOt0X+d7p9tGo2MtURNO1sToO6YqxNkDRsUtSVbbo33YWmsexJLHf5Dd9CXw+E4Y7ysoJoQwqcAfGq1/VUAb7n7Q3I4HGeBDUfQCcaj9ksGVQJZk0GwFJWRqJTbKDwS42VoXBMkdnMUVG2zxlh0MpIpu+I4mkmGplwViZlWVNcRevoCZcVZamXrNgBUJCKXpY2uo5K/xNdnVQEm7cjMGFnVGnW5CrvqSusjW7ZW+0o0TRMvKDXMivEdUWdKdK85AtKoDHVajBddR8v03y7G2zJM7Aa1pbqVGM/lzWwfdTrb8QTZXXC9ORyOv+Xwxe5w9AQbFePzTHBhq90SLiqhIG2FBIk2lhONo+QyY6FVpaG66JHrdivy6oJxk0zzubmWKDIFy0WWFtM4QorVCRvhxgQQlemf6a85YcZWpC20PqHHryqfMp0zNKTjW6Es8GkRnwPS7H3qS5Ha1EhU6VAT6Jc64SFY7nKbZeJop4tuXFFZ4+2zZT7AZopLS28NNY/JPewaWQf+ZXc4egJf7A5HT+CL3eHoCTaus1/ZSejsYJ3auJMo+ms+j7qQjbSbq2gy7WpSZZ3IJWV1Ky5jZIOR8oJ0cVLTK6vadxBDsKvGkkCy/UC1dNkESn1xtgOUcyavMKWGqQ9rt2A3XUnEmpbEU+uaZhJUGWXSNU0PbI+xLkaeK+1tSxM02Og0FZFGOrWNKKz4mXXo1GINF/w8qf/K9D+nd8665VKuvS6TSIp8xM4hw7/sDkdP4Ivd4egJNhtBFwBJiBnsThEj5gQmayB30nSmRXUVTZYbMZ45tzlCz0QiFcSFPmgQYLQn2kiw0Uxp8bZWYrYZP3PLqYg3U3aJElVKQ2wxm0TSi/k8bleWR38Rxzg3EYuTmwfxPCpzZbnTlEpiiRZovlWUnJ0ParOqBvev3IEd3q9G/2qMHHlo+fbZ9Wa6V8QWXRF0fC96vpnD35JScF0EnuOGGM/XbkzCElZFUNdJtjgcjm8q+GJ3OHoCX+wOR0+wUZ29LEvs3XiptY11Fav/cQgo6+nHE63zsiuuQRpIOlR1HGvh2vK8Q67NtqP56zOuv0a/W1eh1uMMuQTp4jNTI256FPcnR4exD6OHDYgE0rqJuKT1fEo6u+UZp/OOD/ZVUzU7Pt3O0K572z5t9l2VDP1Nz1VVpd1m0uVu6wrH5VBaRbJpyTZ4J82P3+XaU1l11oZBbWJcqQMij1RZa7V1l1KI9qCdcLJB/EnwL7vD0RP4Ync4eoKNivFVVWNv/7C1zWap6fOiaDKfsxivy9ZypF2wYW0lifzTKC7nlgGDg5kGenqyOfHS0+8NjnBSGTiKDTClng9vqjYW43nbivHMRW8F2MWiPWqu4dYitclWpl6QJy6UTIBh3Em0b11ZpSqVxdlaaTG4EbiWkM67aTI6WiWdOSedbq129x2gowOV6G764Pd7MBqrtmLELx2XmrJZb7HNlhqnoxK/+5fd4egNfLE7HD3BZsX4usb+4ay1jcWcJjlBBFMlLxZadJyTWG8LUnAUXkFpJgMjDjHHnZQmCm8SrdQ5icuWSKCk0k2TA622TA/j/vRIty3Iks6RUNaiz3tWrExRFluK4aLg+TaJR3QFFdVnVJLFjCmtbURayoKdvpemBN5RkbXrtATY42Or9/L8NC3/6yXe8D1nhkL8tHoxgO1dXS5s9/KV0+1iED0tVannm1WDYtieUJZ/Pb2k/cvucPQEvtgdjp7AF7vD0RNsVGcPAbCBXCfI2GvRYDaMqIgMsA420imiNq435f6hP3EN3j4mfBCdDZbT4Lv4uRcUuXa8r6PTZofRzzWfaLsCZ6bxX2HrrirpXhrc4tTGs2PLUOlSyelyy+w6tIQPi0U6Yiyl5nbp111RckjaAID6Fr2eIFfvmCEr7frsdZoO2httBGdO7tIh6e8AsHXhYmwbxwhOmzmnCE+L9qXbVbJ53frsXwNwE0sClTKE8ICI3APgIwBeD+BrAN4TQmiPhXU4HOeOlyPG/2AI4f4QwgOr/fcDeDyE8EYAj6/2HQ7HKxR3Isa/G8DbVtuPYlkD7n1dJ2RZhpGJHoptNBQjGSX5tkwygK5GpDspF7F/5lxbGBG2ouSabGZLJlEEkyrxpP9mVuSWmx0dqzYVUWdcjDmXOGI+dSMiS4jjN14zZKQCrVsRtDIeHhUVVnWI6uQutZGIiuiCOftbmN1PD7MPPsHX1+BwU+QYaaQdgEY1sLTxHX3yc+IyWo1Cs/SOZEYEH5DoPtrZbR8TNBGHpbY/HY+9MI8h2aIRAPyxiHxWRB5e/XY1hPDMavs6gKtr9uVwOM4B637Zvz+E8LSIvAbAJ0TkL7gxhBCEqx4SVn8cHgaahgmHw7E5rPVlDyE8vfr/OQC/j2Wp5mdF5F4AWP3/XOLcR0IID4QQHhjYyqoOh2NjuOWXXUR2AGQhhJur7R8C8O8AfAzAgwA+uPr/sVtfThphiidgfdWiZJdUzYR86dK9DRdExTzpzFFvuiDyyMzUbE6ooQ2dnbPeKhNiyi6vzPp7SO9VKplRzEURIVh9vl2ZsyG3rH/XtjZ1MhNNj1eVfTbznRft4c+NrDGls5thqPLZ7SQRgHkPuurFqfp2NmyXa9qlM+KahJO0TWNshHyrPvQ8CtmrJNckp4yMbTANktPTHpLnryPGXwXw+6vBFwD+WwjhD0XkMwA+KiIPAfg6gPes0ZfD4Tgn3HKxhxC+CuC7Wn5/EcA7zmJQDofj7mOjEXSQdHQci6MNSYylLyYSaESPMZmCFp85Gom3bfSYSg6z4haL7sxL1uC5p8w5661iVcNEtbF41yXespjZkNozFpn5d6MyhI75bu+uwZ3GLiSrnhUJdc3Ot4rkM+GMVZLL3YrZvJ0WY7mty0VniVRy5WbVxyoXJqsa1hymSCl0G0dELkrOWjTXUiWbU8we6Tvz2HiHoyfwxe5w9AS+2B2OnmCzOnswephqUoq5gnITqbpeXYwiNiOuXV9r6EWcHWdZVVgB5xOtHqrqnHVoh1bhltROR8Bmw00UtxU7jWHk0XPQwaHOIaBiXW9Uo8zYH9gtJ8rOosdbg+wnhns+JMo+W4jSqdMht51QXJFmTql/65bj90oydolae0zeeg6gyTmzOc2Hff+UnaX9vpK6PPzL7nD0Br7YHY6eYKNifB0CZtP2yJ9MRYKly+/UNYtNhjSwiCR8mZH6chKZWdIpa00gUbIYVdroNx47R8IZsY9FQitW8bGN7C2+t65oL3WW7p9FTo5wK3SoshYz0/23Zzys2rp42FVUW3skHAAEigRrcs+TuzSh/gGaQ73h2k2Ivl389RaaU95Gv5GaQ+wYNrNNVISoFeMpi9GU8dZjpO2E87DTjZpucjgc30zwxe5w9AQbt8bbap8nUBmyHVFQnZFfHJ1mraGcbJCR2GREKo6uY/53AKhZrKeLF4aTPaf93I6Dtm1Ch7pvxbVnRU4+rBFCR5tkLc+7xEoNXT014YGAtZabThTHXTsZht23STKKe57H3pFk0pJOg3XQ6aHpeDV5/pkXLjMJLfw+NjgFVbJUx710rYtE3wz/sjscPYEvdoejJ/DF7nD0BJvljUdIkkd2ZSupPjjzx0SuKX2wQWOeigQzEV3UR7nQrrdyHnV45VIzpZ2FpjXPbOZcx99XZY8gXbZBPMinpF1vTGRh5104cq3Jvkibip1BH1d3ZWGxu5SOqzQXOpN/Nrnn2RVJto8uk05DR5f2zUbkYZy3yroHmSzEDjFhF8mKNAlFbeaA3yt1ra53J/Ueuc7ucDh8sTscPcGGXW+hIcJEdESMhZQbR/dVkVhfm9I5ihduEaOUKhOxxGVybfkd3Weas0yVBs71vbCLsSlwsejLyT9dCRHp6D3N/27mveb5NqNIlFhuJKNofaJjjB2Ra5xIYnns8nW/RRzJt+YplgAjS4+DXZjW1cnHdnHyKeIMW2aby39z2WfbR3ZrMd5dbw6Hwxe7w9EX+GJ3OHqCDZdsDkontm2n2zZskt0zijjSkkrOW48DtF7Ex1VzHRJbzmMWXKh1HzovLx3OWnWUVO4K+1S12bp0dnSgZsJCJthIZ401cRuED6ZJJ4qp4tHmSN5fj8yjoZYr79qaIaYvgxs+WTAA2h3GZCE2XJvPa5BSsK2JjzPPXZF0pGq6uc7ucDh8sTscPcFmXW8IittdtSSypIC06M4uNLtfN0T8BbWRWpB0BTZdHyqrjo+zkU45u2p0m+ITt2K8tLu8mtGAvJMWR03IGNaFJOVzcy10iL6pMXWWRUpzCnYOXzpE/NQYO67VHGP7tWyf0lHGu6tNPV7l3myQ1NM5CfKKDhVsrS+7iFwWkd8Rkb8QkSdE5HtF5B4R+YSIfGX1/5V1+nI4HOeDdcX4XwXwhyGE78SyFNQTAN4P4PEQwhsBPL7adzgcr1CsU8X1EoAfAPBPASCEMAcwF5F3A3jb6rBHAXwKwPu6+gqhhbDhpK1OkxjoZIyEqAt05/0zN1uR5izjKKimSNTOk2fFT060aYj4Wfq81PDzNa3Uq05b++8SkdftvsvS3WhTh6Wv1TWOzoyX1LWaF6fNtArVOY41xfiud4Kv3fksOu55XW7AFNb5sr8BwPMA/ouIfE5E/vOqdPPVEMIzq2OuY1nt1eFwvEKxzmIvAHw3gF8LIbwZwBGMyB6Wn97WvzUi8rCIXBORa9Zo5nA4Nod1FvtTAJ4KIXx6tf87WC7+Z0XkXgBY/f9c28khhEdCCA+EEB7oyvF1OBxni3Xqs18XkW+IyHeEEL6MZU32L63+PQjgg6v/H1vngsmyNV0nqWisdJRSlqd7UeWQA53XUVbIIhX91tS9O/ThDv1Vn9fpa0r2kdbZje0gcU7jSrfZltQ9X74a/rJgbQcpd1sjerFLV+58LKk+13SJLi/e3tYxV7ehsq/tZ/8XAH5TRIYAvgrgn2EpFXxURB4C8HUA77mN6zscjg1hrcUeQvg8gAdamt5xd4fjcDjOChuOoANSAoj2bhgRK0EeYN1mdUXH1frWONlAu/9skkm6DFVK9G2IyGuKql0iYfeJXZ2sF9XWHZ22ZmTcmuNNSamN1q7aRV1yqxKzOyLcOvnl437dXWAr2b+eNxsl19FLlys1ec7LF+Q9Nt7h6Al8sTscPYEvdoejJzgHnX0NdKktt+Nz6Oq/0d/Z+oZuq/d11b3bxhn7w76JsGby3SsS/mV3OHoCX+wOR08gXTzTd/1iIs9jGYDzKgAvbOzC7XgljAHwcVj4ODRe7jj+bgjh1W0NG13spxcVuRZCaAvS6dUYfBw+jk2Ow8V4h6Mn8MXucPQE57XYHzmn6zJeCWMAfBwWPg6NuzaOc9HZHQ7H5uFivMPRE2x0sYvIu0TkyyLypIhsjI1WRH5dRJ4TkS/QbxunwhaR14nIJ0XkSyLyRRF573mMRUTGIvInIvKnq3H8wur3N4jIp1fP5yMr/oIzh4jkK37Dj5/XOETkayLy5yLyeRG5tvrtPN6RM6Nt39hiF5EcwH8C8I8AvAnAT4jImzZ0+d8A8C7z23lQYZcAfjaE8CYAbwXw06s52PRYZgDeHkL4LgD3A3iXiLwVwC8C+OUQwrcDeAnAQ2c8jhO8F0t68hOc1zh+MIRwP7m6zuMdOTva9hDCRv4B+F4Af0T7HwDwgQ1e//UAvkD7XwZw72r7XgBf3tRYaAyPAXjneY4FwDaA/wvge7AM3ijantcZXv++1Qv8dgAfxzL8/DzG8TUArzK/bfS5ALgE4K+xsqXd7XFsUox/LYBv0P5Tq9/OC+dKhS0irwfwZgCfPo+xrETnz2NJFPoJAH8FYC+EcFIPa1PP51cA/ByAE0aRbzmncQQAfywinxWRh1e/bfq5nCltuxvo0E2FfRYQkV0AvwvgZ0IIB+cxlhBCFUK4H8sv61sAfOdZX9NCRH4EwHMhhM9u+tot+P4QwndjqWb+tIj8ADdu6LncEW37rbDJxf40gNfR/n2r384La1Fh322IyADLhf6bIYTfO8+xAEAIYQ/AJ7EUly+LyEna8yaez/cB+FER+RqAD2Mpyv/qOYwDIYSnV/8/B+D3sfwDuOnncke07bfCJhf7ZwC8cWVpHQL4cQAf2+D1LT6GJQU28DKosO8EsiQs+xCAJ0IIv3ReYxGRV4vI5dX2FpZ2gyewXPQ/tqlxhBA+EEK4L4Tweizfh/8ZQvipTY9DRHZE5MLJNoAfAvAFbPi5hBCuA/iGiHzH6qcT2va7M46zNnwYQ8MPA/hLLPXDf7PB6/4WgGcALLD86/kQlrrh4wC+AuB/ALhnA+P4fixFsD8D8PnVvx/e9FgA/H0An1uN4wsA/u3q928D8CcAngTw2wBGG3xGbwPw8fMYx+p6f7r698WTd/Oc3pH7AVxbPZv/DuDK3RqHR9A5HD2BG+gcjp7AF7vD0RP4Ync4egJf7A5HT+CL3eHoCXyxOxw9gS92h6Mn8MXucPQE/x+sHi1N9BXjqgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "ls5vuMmZM1kl",
        "outputId": "251a3eb7-87a6-4a5c-cfa2-170c52ee239c"
      },
      "source": [
        "#Show the fourth image\n",
        "print('VGG16 Predicted: ' + className[vgg16_pred[randList[3]]])\n",
        "print('VGG16 with Upsampling Predicted: ' + className[vgg16Up_pred[randList[3]]])\n",
        "print('DenseNet201 Predicted: ' + className[dense_pred[randList[3]]])\n",
        "print('ResNet50 Predicted: ' + className[res_pred[randList[3]]])\n",
        "print('True: ' + className[np.argmax(new_y_test[randList[3]])])\n",
        "plt.imshow(new_x_test[randList[3]])"
      ],
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VGG16 Predicted: Cat\n",
            "VGG16 with Upsampling Predicted: Dog\n",
            "DenseNet201 Predicted: Cat\n",
            "ResNet50 Predicted: Deer\n",
            "True: Frog\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f6e30ab7b90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 221
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "XBnVXESuM-t-",
        "outputId": "1894d0a6-0f66-475e-e8ba-92f931d2c8f3"
      },
      "source": [
        "#Show the fifth image\n",
        "print('VGG16 Predicted: ' + className[vgg16_pred[randList[4]]])\n",
        "print('VGG16 with Upsampling Predicted: ' + className[vgg16Up_pred[randList[4]]])\n",
        "print('DenseNet201 Predicted: ' + className[dense_pred[randList[4]]])\n",
        "print('ResNet50 Predicted: ' + className[res_pred[randList[4]]])\n",
        "print('True: ' + className[np.argmax(new_y_test[randList[4]])])\n",
        "plt.imshow(new_x_test[randList[4]])"
      ],
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VGG16 Predicted: Ship\n",
            "VGG16 with Upsampling Predicted: Ship\n",
            "DenseNet201 Predicted: Ship\n",
            "ResNet50 Predicted: Automobile\n",
            "True: Ship\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f6e31c57550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 222
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}